{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "import lightgbm as lgb\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_null(df):\n",
    "    missing = df.isnull().sum()\n",
    "    print('Show #missing in the columns:')\n",
    "    for i in range(df.shape[1]):\n",
    "        if missing[i]:\n",
    "            print(missing.index[i], ':', missing[i])\n",
    "\n",
    "def metric(truth, pred):\n",
    "    truth = np.array(truth)\n",
    "    pred = np.array(pred)\n",
    "    diff = abs(pred - truth) / truth\n",
    "    print(list(diff <= 0.1).count(True) / len(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/dataset-0510/train.csv\")\n",
    "test = pd.read_csv(\"../input/dataset-0510/test.csv\")\n",
    "\n",
    "#train = train[train[\"total_price\"] < 1.5e8]\n",
    "price_sq = train[\"total_price\"] / train[\"building_area\"]\n",
    "train = train[(price_sq<12000000) & (price_sq>60000)]\n",
    "\n",
    "#Y_train = pd.DataFrame(np.log1p(train[\"total_price\"] / train[\"building_area\"]), columns=[\"total_price\"])\n",
    "Y_train = train[\"total_price\"] / train[\"building_area\"]\n",
    "#offset = Y_train.min()\n",
    "#Y_train = Y_train / offset\n",
    "Y_train = np.expand_dims(np.log1p(Y_train), -1)\n",
    "y_scale = StandardScaler()\n",
    "Y_train = pd.DataFrame(y_scale.fit_transform(Y_train), columns=['total_price'])\n",
    "\n",
    "offset = train[\"building_area\"].values\n",
    "train_greater_taipei_bool = train['city'].isin([7, 9, 13])\n",
    "test_greater_taipei_bool = test['city'].isin([7, 9, 13])\n",
    "\n",
    "train = train.drop('total_price', 1)\n",
    "data = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"parking_way\"] == 2, 'parking_area'] = data.loc[data[\"parking_way\"] == 2, 'parking_area'].fillna(0.0)\n",
    "data.loc[data[\"parking_way\"] != 2, 'parking_area'] = data.loc[data[\"parking_way\"] != 2, 'parking_area'].fillna(data.loc[data[\"parking_way\"] != 2, 'parking_area'].median())\n",
    "data.loc[data[\"parking_way\"] == 2, 'parking_price'] = data.loc[data[\"parking_way\"] == 2, 'parking_price'].fillna(0.0)\n",
    "data.loc[data[\"parking_way\"] != 2, 'parking_price'] = data.loc[data[\"parking_way\"] != 2, 'parking_price'].fillna(data.loc[data[\"parking_way\"] != 2, 'parking_price'].median())\n",
    "data['txn_floor'] = data['txn_floor'].fillna(1)\n",
    "data['village_income_median'] = data['village_income_median'].fillna(round(data.groupby(['city','town','village'])['village_income_median'].transform('mean')))\n",
    "data['village_income_median'] = data['village_income_median'].fillna(round(data.groupby(['city','town'])['village_income_median'].transform('mean')))\n",
    "data['village_income_median'] = data['village_income_median'].fillna(round(data.groupby(['city'])['village_income_median'].transform('mean')))\n",
    "data[\"floor_ratio\"] = data[\"txn_floor\"] / data[\"total_floor\"]\n",
    "data.loc[data['land_area']==0, 'land_area'] = data['land_area'].median()\n",
    "data[\"floor_area_ratio\"] = data[\"building_area\"] / data[\"land_area\"]\n",
    "data[\"have_parking\"] = (data[\"parking_way\"] != 2) * 1.0\n",
    "data[\"have_parking\"] = data[\"have_parking\"].astype(int)\n",
    "\n",
    "cat_data = data[[\"town\", \"village\", \"txn_floor\", \"building_material\", \"city\", \"building_type\", \"building_use\", \"parking_way\"]].astype(str)\n",
    "cat_data['village'] = cat_data[\"city\"] + \"_\" + cat_data[\"town\"] + \"_\" + cat_data[\"village\"]\n",
    "#cat_data[\"city_town\"] = cat_data[\"city\"] + \"_\" + cat_data[\"town\"]\n",
    "cat_data[\"city_town_building_type_use\"] = cat_data[\"city\"] + \"_\" + cat_data[\"town\"] + \"_\" + cat_data[\"building_type\"] + \"_\" + cat_data[\"building_use\"]\n",
    "#cat_data[\"parking_way_building_type\"] = cat_data[\"parking_way\"] + \"_\" + cat_data[\"building_type\"]\n",
    "cat_data[\"building_material_building_use\"] = cat_data[\"building_material\"] + \"_\" + cat_data[\"building_use\"]\n",
    "#cat_data[\"building_material_parking_way\"] = cat_data[\"building_material\"] + \"_\" + cat_data[\"parking_way\"]\n",
    "\n",
    "#cat_data[\"txn_dt\"] = data[\"txn_dt\"] // 365\n",
    "#cat_data[\"building_complete_dt\"] = data[\"building_complete_dt\"] // 365\n",
    "data[\"txn_duration\"] = (data[\"txn_dt\"] - data[\"building_complete_dt\"]) / 365\n",
    "#cat_data[\"building_type_txn_duration\"] = cat_data[\"building_type\"] + \"_\" + data[\"txn_duration\"].astype(str)\n",
    "#cat_data[\"building_use_txn_duration\"] = cat_data[\"building_use\"] + \"_\" + data[\"txn_duration\"].astype(str) \n",
    "\n",
    "cat_data = cat_data.apply(LabelEncoder().fit_transform)\n",
    "#cat_cols = [col for col in data.columns if data[col].dtype == np.object]\n",
    "#data = data.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show #missing in the columns:\n"
     ]
    }
   ],
   "source": [
    "num_null(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncorr_features = [\\'XIII_10000\\', \\'VII_10000\\', \\'V_10000\\', \\'XIII_5000\\',\\n       \\'IX_10000\\', \\'VIII_10000\\', \\'III_10000\\', \\'X_10000\\', \\'XII_10000\\',\\n       \\'II_10000\\', \\'VI_10000\\', \\'XI_10000\\', \\'jobschool_rate\\', \\'I_10000\\',\\n       \\'IV_10000\\', \\'V_5000\\', \\'bachelor_rate\\', \\'VII_5000\\', \\'VIII_5000\\',\\n       \\'XII_5000\\', \\'X_5000\\', \\'master_rate\\', \\'III_5000\\', \\'IX_5000\\', \\'II_5000\\']\\n\\npoly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\\ndata_poly = poly.fit_transform(data[corr_features])\\ndata_poly_df = pd.DataFrame(data_poly, columns=poly.get_feature_names(corr_features))\\ndata_poly_df.columns = data_poly_df.columns.str.replace(\" \", \"_\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "corr_features = ['XIII_10000', 'VII_10000', 'V_10000', 'XIII_5000',\n",
    "       'IX_10000', 'VIII_10000', 'III_10000', 'X_10000', 'XII_10000',\n",
    "       'II_10000', 'VI_10000', 'XI_10000', 'jobschool_rate', 'I_10000',\n",
    "       'IV_10000', 'V_5000', 'bachelor_rate', 'VII_5000', 'VIII_5000',\n",
    "       'XII_5000', 'X_5000', 'master_rate', 'III_5000', 'IX_5000', 'II_5000']\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "data_poly = poly.fit_transform(data[corr_features])\n",
    "data_poly_df = pd.DataFrame(data_poly, columns=poly.get_feature_names(corr_features))\n",
    "data_poly_df.columns = data_poly_df.columns.str.replace(\" \", \"_\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "town                               214\n",
       "village                           4314\n",
       "txn_floor                           28\n",
       "building_material                    9\n",
       "city                                11\n",
       "building_type                        5\n",
       "building_use                        10\n",
       "parking_way                          3\n",
       "city_town_building_type_use       2082\n",
       "building_material_building_use      48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 skewed numerical features to log transform\n"
     ]
    }
   ],
   "source": [
    "#dummy_columns = ['txn_floor', 'building_material', 'city', 'building_type', 'building_use', 'parking_way', 'building_material_building_use']\n",
    "#dummy = pd.get_dummies(cat_data[dummy_columns], columns=dummy_columns)\n",
    "#cat_data = cat_data.drop(dummy_columns, 1)\n",
    "\n",
    "cont_data = data.drop([\"building_id\", \n",
    "                       \"town\", \"village\", \"txn_floor\", \"building_material\", \"city\", \"building_type\", \"building_use\", \"parking_way\"], 1)\n",
    "\n",
    "#cont_data = pd.concat([cont_data, dummy], axis=1, join_axes=[cont_data.index])\n",
    "\n",
    "skewness = cont_data.apply(lambda x: skew(x))\n",
    "skewness = skewness[abs(skewness) > 1.5]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n",
    "\n",
    "skewed_features = skewness.index\n",
    "cont_data[skewed_features] = np.log1p(cont_data[skewed_features])\n",
    "\n",
    "train_data = pd.concat([cont_data, cat_data], axis=1, join_axes=[cont_data.index])\n",
    "#scale = StandardScaler()\n",
    "#cont_data = pd.DataFrame(scale.fit_transform(cont_data.values), columns=cont_data.columns, index=cont_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = data.drop([\"building_id\", \"parking_area\", \"txn_dt\", \"building_complete_dt\",\\n                  \"town\", \"village\", \"txn_floor\", \"building_material\", \"city\", \"building_type\", \"building_use\", \"parking_way\",\\n                  \\'XIII_10000\\', \\'VII_10000\\', \\'V_10000\\', \\'XIII_5000\\',\\n       \\'IX_10000\\', \\'VIII_10000\\', \\'III_10000\\', \\'X_10000\\', \\'XII_10000\\',\\n       \\'II_10000\\', \\'VI_10000\\', \\'XI_10000\\', \\'jobschool_rate\\', \\'I_10000\\',\\n       \\'IV_10000\\', \\'V_5000\\', \\'bachelor_rate\\', \\'VII_5000\\', \\'VIII_5000\\',\\n       \\'XII_5000\\', \\'X_5000\\', \\'master_rate\\', \\'III_5000\\', \\'IX_5000\\', \\'II_5000\\'], 1)\\ncont_data = pd.concat([data, data_poly_df], axis=1, join_axes=[data.index])\\nscale = StandardScaler()\\ncont_data = pd.DataFrame(scale.fit_transform(cont_data.values), columns=cont_data.columns, index=cont_data.index)\\ntrain_data = pd.concat([cont_data, cat_data], axis=1, join_axes=[cont_data.index])\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "data = data.drop([\"building_id\", \"parking_area\", \"txn_dt\", \"building_complete_dt\",\n",
    "                  \"town\", \"village\", \"txn_floor\", \"building_material\", \"city\", \"building_type\", \"building_use\", \"parking_way\",\n",
    "                  'XIII_10000', 'VII_10000', 'V_10000', 'XIII_5000',\n",
    "       'IX_10000', 'VIII_10000', 'III_10000', 'X_10000', 'XII_10000',\n",
    "       'II_10000', 'VI_10000', 'XI_10000', 'jobschool_rate', 'I_10000',\n",
    "       'IV_10000', 'V_5000', 'bachelor_rate', 'VII_5000', 'VIII_5000',\n",
    "       'XII_5000', 'X_5000', 'master_rate', 'III_5000', 'IX_5000', 'II_5000'], 1)\n",
    "cont_data = pd.concat([data, data_poly_df], axis=1, join_axes=[data.index])\n",
    "scale = StandardScaler()\n",
    "cont_data = pd.DataFrame(scale.fit_transform(cont_data.values), columns=cont_data.columns, index=cont_data.index)\n",
    "train_data = pd.concat([cont_data, cat_data], axis=1, join_axes=[cont_data.index])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_features = [col for col in train_data.columns if train_data[col].dtype == np.int] \n",
    "categorical_features = [\"town\", \"village\", \"txn_floor\", \"building_material\", \"city\", \"building_type\", \"building_use\", \"parking_way\", \n",
    "                        \"city_town_building_type_use\", \"building_material_building_use\"]\n",
    "#categorical_features = [\"town\", \"village\", \"city_town_building_type_use\"]\n",
    "\n",
    "for col in categorical_features:\n",
    "    train_data[col] = train_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.iloc[:-10000]\n",
    "X_test = train_data.iloc[-10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'objective': 'huber', \n",
    "    'learning_rate': 0.01, \n",
    "    'num_leaves': 200, \n",
    "    #'max_depth': 8, \n",
    "    'feature_fraction': 0.25, \n",
    "    #'max_bin': 500,  \n",
    "    'seed': 42, \n",
    "    'bagging_fraction': 0.95, \n",
    "    'bagging_freq': 5,\n",
    "    'save_binary': True,\n",
    "    'max_bin': 63,\n",
    "    'metric':'l1'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**in taipei**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_taipei_X_train = X_train[train_greater_taipei_bool.values]\n",
    "in_taipei_Y_train = Y_train[train_greater_taipei_bool.values]\n",
    "\n",
    "in_taipei_X_test = X_test[test_greater_taipei_bool.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Fold 1\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.280073\tvalid_1's l1: 0.285071\n",
      "[200]\ttraining's l1: 0.171406\tvalid_1's l1: 0.183112\n",
      "[300]\ttraining's l1: 0.131264\tvalid_1's l1: 0.150068\n",
      "[400]\ttraining's l1: 0.11144\tvalid_1's l1: 0.136173\n",
      "[500]\ttraining's l1: 0.0985768\tvalid_1's l1: 0.12799\n",
      "[600]\ttraining's l1: 0.08897\tvalid_1's l1: 0.122494\n",
      "[700]\ttraining's l1: 0.0818115\tvalid_1's l1: 0.118893\n",
      "[800]\ttraining's l1: 0.0758628\tvalid_1's l1: 0.116088\n",
      "[900]\ttraining's l1: 0.0709435\tvalid_1's l1: 0.114059\n",
      "[1000]\ttraining's l1: 0.0667478\tvalid_1's l1: 0.112515\n",
      "[1100]\ttraining's l1: 0.0630511\tvalid_1's l1: 0.111333\n",
      "[1200]\ttraining's l1: 0.0597163\tvalid_1's l1: 0.110351\n",
      "[1300]\ttraining's l1: 0.0567269\tvalid_1's l1: 0.109504\n",
      "[1400]\ttraining's l1: 0.0540992\tvalid_1's l1: 0.10885\n",
      "[1500]\ttraining's l1: 0.0516019\tvalid_1's l1: 0.108222\n",
      "[1600]\ttraining's l1: 0.0493381\tvalid_1's l1: 0.107704\n",
      "[1700]\ttraining's l1: 0.0472227\tvalid_1's l1: 0.107247\n",
      "[1800]\ttraining's l1: 0.0452795\tvalid_1's l1: 0.106827\n",
      "[1900]\ttraining's l1: 0.0434329\tvalid_1's l1: 0.106467\n",
      "[2000]\ttraining's l1: 0.041746\tvalid_1's l1: 0.106139\n",
      "[2100]\ttraining's l1: 0.0401295\tvalid_1's l1: 0.105867\n",
      "[2200]\ttraining's l1: 0.0386612\tvalid_1's l1: 0.105614\n",
      "[2300]\ttraining's l1: 0.0372308\tvalid_1's l1: 0.105361\n",
      "[2400]\ttraining's l1: 0.0358941\tvalid_1's l1: 0.105132\n",
      "[2500]\ttraining's l1: 0.0346384\tvalid_1's l1: 0.104913\n",
      "[2600]\ttraining's l1: 0.0334647\tvalid_1's l1: 0.104712\n",
      "[2700]\ttraining's l1: 0.0323569\tvalid_1's l1: 0.10455\n",
      "[2800]\ttraining's l1: 0.0312914\tvalid_1's l1: 0.10438\n",
      "[2900]\ttraining's l1: 0.0302709\tvalid_1's l1: 0.104214\n",
      "[3000]\ttraining's l1: 0.0293211\tvalid_1's l1: 0.104086\n",
      "[3100]\ttraining's l1: 0.0283897\tvalid_1's l1: 0.103936\n",
      "[3200]\ttraining's l1: 0.0275216\tvalid_1's l1: 0.103815\n",
      "[3300]\ttraining's l1: 0.0266839\tvalid_1's l1: 0.103699\n",
      "[3400]\ttraining's l1: 0.0258738\tvalid_1's l1: 0.103593\n",
      "[3500]\ttraining's l1: 0.0251027\tvalid_1's l1: 0.103474\n",
      "[3600]\ttraining's l1: 0.0243717\tvalid_1's l1: 0.103367\n",
      "[3700]\ttraining's l1: 0.0236807\tvalid_1's l1: 0.103266\n",
      "[3800]\ttraining's l1: 0.0229991\tvalid_1's l1: 0.103201\n",
      "[3900]\ttraining's l1: 0.0223556\tvalid_1's l1: 0.103115\n",
      "[4000]\ttraining's l1: 0.021726\tvalid_1's l1: 0.103037\n",
      "[4100]\ttraining's l1: 0.0211353\tvalid_1's l1: 0.102976\n",
      "[4200]\ttraining's l1: 0.020581\tvalid_1's l1: 0.102921\n",
      "[4300]\ttraining's l1: 0.020025\tvalid_1's l1: 0.102837\n",
      "[4400]\ttraining's l1: 0.0194988\tvalid_1's l1: 0.102779\n",
      "[4500]\ttraining's l1: 0.0189914\tvalid_1's l1: 0.102719\n",
      "[4600]\ttraining's l1: 0.0185078\tvalid_1's l1: 0.102668\n",
      "[4700]\ttraining's l1: 0.018038\tvalid_1's l1: 0.102623\n",
      "[4800]\ttraining's l1: 0.0175834\tvalid_1's l1: 0.102574\n",
      "[4900]\ttraining's l1: 0.0171335\tvalid_1's l1: 0.102528\n",
      "[5000]\ttraining's l1: 0.0166881\tvalid_1's l1: 0.102499\n",
      "[5100]\ttraining's l1: 0.0162773\tvalid_1's l1: 0.102457\n",
      "[5200]\ttraining's l1: 0.0158872\tvalid_1's l1: 0.102421\n",
      "[5300]\ttraining's l1: 0.0154815\tvalid_1's l1: 0.102386\n",
      "[5400]\ttraining's l1: 0.0151127\tvalid_1's l1: 0.102338\n",
      "[5500]\ttraining's l1: 0.0147695\tvalid_1's l1: 0.102297\n",
      "[5600]\ttraining's l1: 0.0144364\tvalid_1's l1: 0.102258\n",
      "[5700]\ttraining's l1: 0.0141163\tvalid_1's l1: 0.102222\n",
      "[5800]\ttraining's l1: 0.0137849\tvalid_1's l1: 0.102185\n",
      "[5900]\ttraining's l1: 0.0134753\tvalid_1's l1: 0.102159\n",
      "[6000]\ttraining's l1: 0.0131854\tvalid_1's l1: 0.102135\n",
      "[6100]\ttraining's l1: 0.0128875\tvalid_1's l1: 0.102116\n",
      "[6200]\ttraining's l1: 0.0125851\tvalid_1's l1: 0.102086\n",
      "[6300]\ttraining's l1: 0.0123036\tvalid_1's l1: 0.102065\n",
      "[6400]\ttraining's l1: 0.0120448\tvalid_1's l1: 0.102041\n",
      "[6500]\ttraining's l1: 0.0117977\tvalid_1's l1: 0.102017\n",
      "[6600]\ttraining's l1: 0.0115425\tvalid_1's l1: 0.101991\n",
      "[6700]\ttraining's l1: 0.0112965\tvalid_1's l1: 0.101967\n",
      "[6800]\ttraining's l1: 0.0110483\tvalid_1's l1: 0.101953\n",
      "[6900]\ttraining's l1: 0.0108221\tvalid_1's l1: 0.101943\n",
      "[7000]\ttraining's l1: 0.0105854\tvalid_1's l1: 0.101924\n",
      "[7100]\ttraining's l1: 0.0103687\tvalid_1's l1: 0.1019\n",
      "[7200]\ttraining's l1: 0.0101565\tvalid_1's l1: 0.101877\n",
      "[7300]\ttraining's l1: 0.00995557\tvalid_1's l1: 0.101855\n",
      "[7400]\ttraining's l1: 0.0097496\tvalid_1's l1: 0.101836\n",
      "[7500]\ttraining's l1: 0.00956033\tvalid_1's l1: 0.101824\n",
      "[7600]\ttraining's l1: 0.0093797\tvalid_1's l1: 0.101808\n",
      "[7700]\ttraining's l1: 0.0091858\tvalid_1's l1: 0.101794\n",
      "[7800]\ttraining's l1: 0.00900248\tvalid_1's l1: 0.101777\n",
      "[7900]\ttraining's l1: 0.00882803\tvalid_1's l1: 0.10176\n",
      "[8000]\ttraining's l1: 0.00865789\tvalid_1's l1: 0.101751\n",
      "[8100]\ttraining's l1: 0.00848426\tvalid_1's l1: 0.101739\n",
      "[8200]\ttraining's l1: 0.00831263\tvalid_1's l1: 0.101729\n",
      "[8300]\ttraining's l1: 0.0081541\tvalid_1's l1: 0.10171\n",
      "[8400]\ttraining's l1: 0.00800135\tvalid_1's l1: 0.101697\n",
      "[8500]\ttraining's l1: 0.00785147\tvalid_1's l1: 0.101688\n",
      "[8600]\ttraining's l1: 0.00771046\tvalid_1's l1: 0.101672\n",
      "[8700]\ttraining's l1: 0.00756423\tvalid_1's l1: 0.101662\n",
      "[8800]\ttraining's l1: 0.00742704\tvalid_1's l1: 0.101652\n",
      "[8900]\ttraining's l1: 0.00728515\tvalid_1's l1: 0.101643\n",
      "[9000]\ttraining's l1: 0.00715091\tvalid_1's l1: 0.101632\n",
      "[9100]\ttraining's l1: 0.00702416\tvalid_1's l1: 0.101624\n",
      "[9200]\ttraining's l1: 0.00690138\tvalid_1's l1: 0.101613\n",
      "[9300]\ttraining's l1: 0.0067783\tvalid_1's l1: 0.101604\n",
      "[9400]\ttraining's l1: 0.00665381\tvalid_1's l1: 0.101595\n",
      "[9500]\ttraining's l1: 0.00653589\tvalid_1's l1: 0.101588\n",
      "[9600]\ttraining's l1: 0.00642914\tvalid_1's l1: 0.101581\n",
      "[9700]\ttraining's l1: 0.00631392\tvalid_1's l1: 0.10157\n",
      "[9800]\ttraining's l1: 0.00620048\tvalid_1's l1: 0.101568\n",
      "[9900]\ttraining's l1: 0.00610264\tvalid_1's l1: 0.101563\n",
      "[10000]\ttraining's l1: 0.00600127\tvalid_1's l1: 0.101562\n",
      "[10100]\ttraining's l1: 0.00590261\tvalid_1's l1: 0.101555\n",
      "[10200]\ttraining's l1: 0.00580524\tvalid_1's l1: 0.101548\n",
      "[10300]\ttraining's l1: 0.00571099\tvalid_1's l1: 0.101538\n",
      "[10400]\ttraining's l1: 0.00560987\tvalid_1's l1: 0.101526\n",
      "[10500]\ttraining's l1: 0.00551672\tvalid_1's l1: 0.101523\n",
      "[10600]\ttraining's l1: 0.00542793\tvalid_1's l1: 0.101519\n",
      "[10700]\ttraining's l1: 0.00534345\tvalid_1's l1: 0.101512\n",
      "[10800]\ttraining's l1: 0.00525971\tvalid_1's l1: 0.101507\n",
      "[10900]\ttraining's l1: 0.00517601\tvalid_1's l1: 0.101504\n",
      "[11000]\ttraining's l1: 0.005093\tvalid_1's l1: 0.1015\n",
      "[11100]\ttraining's l1: 0.00501083\tvalid_1's l1: 0.101488\n",
      "[11200]\ttraining's l1: 0.00493189\tvalid_1's l1: 0.101483\n",
      "[11300]\ttraining's l1: 0.00485741\tvalid_1's l1: 0.101479\n",
      "[11400]\ttraining's l1: 0.00478428\tvalid_1's l1: 0.101476\n",
      "[11500]\ttraining's l1: 0.00471264\tvalid_1's l1: 0.101473\n",
      "[11600]\ttraining's l1: 0.00463741\tvalid_1's l1: 0.10147\n",
      "[11700]\ttraining's l1: 0.00456777\tvalid_1's l1: 0.101467\n",
      "[11800]\ttraining's l1: 0.00450143\tvalid_1's l1: 0.101466\n",
      "[11900]\ttraining's l1: 0.00443492\tvalid_1's l1: 0.101464\n",
      "[12000]\ttraining's l1: 0.00436814\tvalid_1's l1: 0.101461\n",
      "[12100]\ttraining's l1: 0.0043041\tvalid_1's l1: 0.101461\n",
      "[12200]\ttraining's l1: 0.00424171\tvalid_1's l1: 0.101451\n",
      "[12300]\ttraining's l1: 0.00418161\tvalid_1's l1: 0.101446\n",
      "[12400]\ttraining's l1: 0.00411871\tvalid_1's l1: 0.101444\n",
      "[12500]\ttraining's l1: 0.00405789\tvalid_1's l1: 0.10144\n",
      "[12600]\ttraining's l1: 0.00399886\tvalid_1's l1: 0.101437\n",
      "[12700]\ttraining's l1: 0.00394473\tvalid_1's l1: 0.101433\n",
      "[12800]\ttraining's l1: 0.00388908\tvalid_1's l1: 0.101432\n",
      "[12900]\ttraining's l1: 0.00383398\tvalid_1's l1: 0.101433\n",
      "[13000]\ttraining's l1: 0.00378232\tvalid_1's l1: 0.101429\n",
      "[13100]\ttraining's l1: 0.00373065\tvalid_1's l1: 0.101426\n",
      "[13200]\ttraining's l1: 0.00367869\tvalid_1's l1: 0.101422\n",
      "[13300]\ttraining's l1: 0.00362536\tvalid_1's l1: 0.101414\n",
      "[13400]\ttraining's l1: 0.00357434\tvalid_1's l1: 0.101412\n",
      "[13500]\ttraining's l1: 0.00352572\tvalid_1's l1: 0.101407\n",
      "[13600]\ttraining's l1: 0.00347475\tvalid_1's l1: 0.101405\n",
      "[13700]\ttraining's l1: 0.00342736\tvalid_1's l1: 0.101403\n",
      "[13800]\ttraining's l1: 0.003379\tvalid_1's l1: 0.101398\n",
      "[13900]\ttraining's l1: 0.00333361\tvalid_1's l1: 0.101398\n",
      "Early stopping, best iteration is:\n",
      "[13877]\ttraining's l1: 0.00334321\tvalid_1's l1: 0.101397\n",
      "--------------------\n",
      "Fold 2\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.279707\tvalid_1's l1: 0.288132\n",
      "[200]\ttraining's l1: 0.17116\tvalid_1's l1: 0.186212\n",
      "[300]\ttraining's l1: 0.131146\tvalid_1's l1: 0.152552\n",
      "[400]\ttraining's l1: 0.11145\tvalid_1's l1: 0.138009\n",
      "[500]\ttraining's l1: 0.0985698\tvalid_1's l1: 0.12948\n",
      "[600]\ttraining's l1: 0.089091\tvalid_1's l1: 0.123772\n",
      "[700]\ttraining's l1: 0.0819261\tvalid_1's l1: 0.120032\n",
      "[800]\ttraining's l1: 0.0759821\tvalid_1's l1: 0.117191\n",
      "[900]\ttraining's l1: 0.0710529\tvalid_1's l1: 0.115177\n",
      "[1000]\ttraining's l1: 0.0668764\tvalid_1's l1: 0.11366\n",
      "[1100]\ttraining's l1: 0.0631376\tvalid_1's l1: 0.112431\n",
      "[1200]\ttraining's l1: 0.0597682\tvalid_1's l1: 0.111405\n",
      "[1300]\ttraining's l1: 0.0567425\tvalid_1's l1: 0.110643\n",
      "[1400]\ttraining's l1: 0.0540724\tvalid_1's l1: 0.11001\n",
      "[1500]\ttraining's l1: 0.0515668\tvalid_1's l1: 0.109469\n",
      "[1600]\ttraining's l1: 0.0492853\tvalid_1's l1: 0.108987\n",
      "[1700]\ttraining's l1: 0.0471598\tvalid_1's l1: 0.108572\n",
      "[1800]\ttraining's l1: 0.0452157\tvalid_1's l1: 0.108196\n",
      "[1900]\ttraining's l1: 0.0433578\tvalid_1's l1: 0.107877\n",
      "[2000]\ttraining's l1: 0.0416389\tvalid_1's l1: 0.107582\n",
      "[2100]\ttraining's l1: 0.0400353\tvalid_1's l1: 0.10733\n",
      "[2200]\ttraining's l1: 0.038586\tvalid_1's l1: 0.107111\n",
      "[2300]\ttraining's l1: 0.0371897\tvalid_1's l1: 0.106915\n",
      "[2400]\ttraining's l1: 0.0358584\tvalid_1's l1: 0.106718\n",
      "[2500]\ttraining's l1: 0.0346184\tvalid_1's l1: 0.106528\n",
      "[2600]\ttraining's l1: 0.0334462\tvalid_1's l1: 0.106371\n",
      "[2700]\ttraining's l1: 0.0323344\tvalid_1's l1: 0.106241\n",
      "[2800]\ttraining's l1: 0.0312976\tvalid_1's l1: 0.106119\n",
      "[2900]\ttraining's l1: 0.0302663\tvalid_1's l1: 0.10597\n",
      "[3000]\ttraining's l1: 0.0293318\tvalid_1's l1: 0.10586\n",
      "[3100]\ttraining's l1: 0.0284116\tvalid_1's l1: 0.105748\n",
      "[3200]\ttraining's l1: 0.0275466\tvalid_1's l1: 0.105655\n",
      "[3300]\ttraining's l1: 0.026719\tvalid_1's l1: 0.105571\n",
      "[3400]\ttraining's l1: 0.0259265\tvalid_1's l1: 0.105502\n",
      "[3500]\ttraining's l1: 0.0251727\tvalid_1's l1: 0.105428\n",
      "[3600]\ttraining's l1: 0.0244659\tvalid_1's l1: 0.105368\n",
      "[3700]\ttraining's l1: 0.0237829\tvalid_1's l1: 0.105303\n",
      "[3800]\ttraining's l1: 0.0231103\tvalid_1's l1: 0.105233\n",
      "[3900]\ttraining's l1: 0.0224713\tvalid_1's l1: 0.105174\n",
      "[4000]\ttraining's l1: 0.0218506\tvalid_1's l1: 0.105114\n",
      "[4100]\ttraining's l1: 0.021269\tvalid_1's l1: 0.105065\n",
      "[4200]\ttraining's l1: 0.0206995\tvalid_1's l1: 0.105004\n",
      "[4300]\ttraining's l1: 0.0201353\tvalid_1's l1: 0.104958\n",
      "[4400]\ttraining's l1: 0.0196065\tvalid_1's l1: 0.104917\n",
      "[4500]\ttraining's l1: 0.0190989\tvalid_1's l1: 0.104881\n",
      "[4600]\ttraining's l1: 0.0186174\tvalid_1's l1: 0.104844\n",
      "[4700]\ttraining's l1: 0.0181504\tvalid_1's l1: 0.104801\n",
      "[4800]\ttraining's l1: 0.0176975\tvalid_1's l1: 0.104777\n",
      "[4900]\ttraining's l1: 0.017237\tvalid_1's l1: 0.104749\n",
      "[5000]\ttraining's l1: 0.0168025\tvalid_1's l1: 0.104717\n",
      "[5100]\ttraining's l1: 0.016389\tvalid_1's l1: 0.104691\n",
      "[5200]\ttraining's l1: 0.015993\tvalid_1's l1: 0.10465\n",
      "[5300]\ttraining's l1: 0.0155855\tvalid_1's l1: 0.104628\n",
      "[5400]\ttraining's l1: 0.0152024\tvalid_1's l1: 0.104602\n",
      "[5500]\ttraining's l1: 0.0148563\tvalid_1's l1: 0.104585\n",
      "[5600]\ttraining's l1: 0.0145188\tvalid_1's l1: 0.10456\n",
      "[5700]\ttraining's l1: 0.0142064\tvalid_1's l1: 0.104544\n",
      "[5800]\ttraining's l1: 0.0138766\tvalid_1's l1: 0.104521\n",
      "[5900]\ttraining's l1: 0.0135627\tvalid_1's l1: 0.104501\n",
      "[6000]\ttraining's l1: 0.0132576\tvalid_1's l1: 0.104477\n",
      "[6100]\ttraining's l1: 0.0129509\tvalid_1's l1: 0.104449\n",
      "[6200]\ttraining's l1: 0.0126477\tvalid_1's l1: 0.104425\n",
      "[6300]\ttraining's l1: 0.0123781\tvalid_1's l1: 0.104404\n",
      "[6400]\ttraining's l1: 0.0121134\tvalid_1's l1: 0.104391\n",
      "[6500]\ttraining's l1: 0.0118594\tvalid_1's l1: 0.104373\n",
      "[6600]\ttraining's l1: 0.0115968\tvalid_1's l1: 0.104356\n",
      "[6700]\ttraining's l1: 0.0113568\tvalid_1's l1: 0.10434\n",
      "[6800]\ttraining's l1: 0.0111053\tvalid_1's l1: 0.104328\n",
      "[6900]\ttraining's l1: 0.0108718\tvalid_1's l1: 0.104312\n",
      "[7000]\ttraining's l1: 0.0106301\tvalid_1's l1: 0.104295\n",
      "[7100]\ttraining's l1: 0.0104117\tvalid_1's l1: 0.104286\n",
      "[7200]\ttraining's l1: 0.0102002\tvalid_1's l1: 0.104267\n",
      "[7300]\ttraining's l1: 0.00999483\tvalid_1's l1: 0.104252\n",
      "[7400]\ttraining's l1: 0.00978552\tvalid_1's l1: 0.104239\n",
      "[7500]\ttraining's l1: 0.00959479\tvalid_1's l1: 0.104235\n",
      "[7600]\ttraining's l1: 0.00941006\tvalid_1's l1: 0.104226\n",
      "[7700]\ttraining's l1: 0.00921069\tvalid_1's l1: 0.104215\n",
      "[7800]\ttraining's l1: 0.00902641\tvalid_1's l1: 0.104202\n",
      "[7900]\ttraining's l1: 0.00885143\tvalid_1's l1: 0.104186\n",
      "[8000]\ttraining's l1: 0.0086873\tvalid_1's l1: 0.104173\n",
      "[8100]\ttraining's l1: 0.00851172\tvalid_1's l1: 0.104169\n",
      "[8200]\ttraining's l1: 0.0083367\tvalid_1's l1: 0.104161\n",
      "[8300]\ttraining's l1: 0.00817888\tvalid_1's l1: 0.104154\n",
      "[8400]\ttraining's l1: 0.00802544\tvalid_1's l1: 0.104141\n",
      "[8500]\ttraining's l1: 0.00787485\tvalid_1's l1: 0.104132\n",
      "[8600]\ttraining's l1: 0.00773321\tvalid_1's l1: 0.104125\n",
      "[8700]\ttraining's l1: 0.00758804\tvalid_1's l1: 0.104112\n",
      "[8800]\ttraining's l1: 0.00744803\tvalid_1's l1: 0.104106\n",
      "[8900]\ttraining's l1: 0.00730322\tvalid_1's l1: 0.104096\n",
      "[9000]\ttraining's l1: 0.00717052\tvalid_1's l1: 0.104083\n",
      "[9100]\ttraining's l1: 0.00703809\tvalid_1's l1: 0.104079\n",
      "[9200]\ttraining's l1: 0.00691241\tvalid_1's l1: 0.104069\n",
      "[9300]\ttraining's l1: 0.00678479\tvalid_1's l1: 0.104061\n",
      "[9400]\ttraining's l1: 0.00665684\tvalid_1's l1: 0.104054\n",
      "[9500]\ttraining's l1: 0.00653676\tvalid_1's l1: 0.104046\n",
      "[9600]\ttraining's l1: 0.00642814\tvalid_1's l1: 0.104041\n",
      "[9700]\ttraining's l1: 0.00631165\tvalid_1's l1: 0.104035\n",
      "[9800]\ttraining's l1: 0.00619938\tvalid_1's l1: 0.104031\n",
      "[9900]\ttraining's l1: 0.00610337\tvalid_1's l1: 0.104025\n",
      "[10000]\ttraining's l1: 0.00599916\tvalid_1's l1: 0.104021\n",
      "Early stopping, best iteration is:\n",
      "[9955]\ttraining's l1: 0.0060446\tvalid_1's l1: 0.104019\n",
      "--------------------\n",
      "Fold 3\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.280056\tvalid_1's l1: 0.284642\n",
      "[200]\ttraining's l1: 0.171026\tvalid_1's l1: 0.184777\n",
      "[300]\ttraining's l1: 0.13097\tvalid_1's l1: 0.152021\n",
      "[400]\ttraining's l1: 0.111104\tvalid_1's l1: 0.138281\n",
      "[500]\ttraining's l1: 0.0982122\tvalid_1's l1: 0.130397\n",
      "[600]\ttraining's l1: 0.0886902\tvalid_1's l1: 0.124919\n",
      "[700]\ttraining's l1: 0.0815386\tvalid_1's l1: 0.12136\n",
      "[800]\ttraining's l1: 0.0755578\tvalid_1's l1: 0.118581\n",
      "[900]\ttraining's l1: 0.0705952\tvalid_1's l1: 0.116616\n",
      "[1000]\ttraining's l1: 0.0663626\tvalid_1's l1: 0.115121\n",
      "[1100]\ttraining's l1: 0.0626859\tvalid_1's l1: 0.113961\n",
      "[1200]\ttraining's l1: 0.0593329\tvalid_1's l1: 0.113051\n",
      "[1300]\ttraining's l1: 0.0563305\tvalid_1's l1: 0.112267\n",
      "[1400]\ttraining's l1: 0.0536768\tvalid_1's l1: 0.111625\n",
      "[1500]\ttraining's l1: 0.0511969\tvalid_1's l1: 0.111124\n",
      "[1600]\ttraining's l1: 0.048906\tvalid_1's l1: 0.110681\n",
      "[1700]\ttraining's l1: 0.0468068\tvalid_1's l1: 0.110249\n",
      "[1800]\ttraining's l1: 0.0448826\tvalid_1's l1: 0.10987\n",
      "[1900]\ttraining's l1: 0.0430501\tvalid_1's l1: 0.109503\n",
      "[2000]\ttraining's l1: 0.0413656\tvalid_1's l1: 0.109205\n",
      "[2100]\ttraining's l1: 0.0397834\tvalid_1's l1: 0.108926\n",
      "[2200]\ttraining's l1: 0.0383065\tvalid_1's l1: 0.108657\n",
      "[2300]\ttraining's l1: 0.0369207\tvalid_1's l1: 0.108411\n",
      "[2400]\ttraining's l1: 0.0356016\tvalid_1's l1: 0.108213\n",
      "[2500]\ttraining's l1: 0.0343979\tvalid_1's l1: 0.108052\n",
      "[2600]\ttraining's l1: 0.0332311\tvalid_1's l1: 0.107896\n",
      "[2700]\ttraining's l1: 0.0321214\tvalid_1's l1: 0.107758\n",
      "[2800]\ttraining's l1: 0.0310634\tvalid_1's l1: 0.107618\n",
      "[2900]\ttraining's l1: 0.0300472\tvalid_1's l1: 0.107495\n",
      "[3000]\ttraining's l1: 0.0291309\tvalid_1's l1: 0.107419\n",
      "[3100]\ttraining's l1: 0.0282105\tvalid_1's l1: 0.107316\n",
      "[3200]\ttraining's l1: 0.0273442\tvalid_1's l1: 0.107219\n",
      "[3300]\ttraining's l1: 0.0265302\tvalid_1's l1: 0.107136\n",
      "[3400]\ttraining's l1: 0.0257278\tvalid_1's l1: 0.107045\n",
      "[3500]\ttraining's l1: 0.0249836\tvalid_1's l1: 0.106983\n",
      "[3600]\ttraining's l1: 0.0242798\tvalid_1's l1: 0.106915\n",
      "[3700]\ttraining's l1: 0.0235832\tvalid_1's l1: 0.106848\n",
      "[3800]\ttraining's l1: 0.0229148\tvalid_1's l1: 0.106775\n",
      "[3900]\ttraining's l1: 0.0222742\tvalid_1's l1: 0.106726\n",
      "[4000]\ttraining's l1: 0.0216553\tvalid_1's l1: 0.106654\n",
      "[4100]\ttraining's l1: 0.0210775\tvalid_1's l1: 0.106615\n",
      "[4200]\ttraining's l1: 0.0205242\tvalid_1's l1: 0.106565\n",
      "[4300]\ttraining's l1: 0.0199614\tvalid_1's l1: 0.106503\n",
      "[4400]\ttraining's l1: 0.0194424\tvalid_1's l1: 0.106466\n",
      "[4500]\ttraining's l1: 0.0189419\tvalid_1's l1: 0.106431\n",
      "[4600]\ttraining's l1: 0.0184517\tvalid_1's l1: 0.106377\n",
      "[4700]\ttraining's l1: 0.0179806\tvalid_1's l1: 0.106329\n",
      "[4800]\ttraining's l1: 0.0175285\tvalid_1's l1: 0.106296\n",
      "[4900]\ttraining's l1: 0.0170816\tvalid_1's l1: 0.106258\n",
      "[5000]\ttraining's l1: 0.0166523\tvalid_1's l1: 0.106225\n",
      "[5100]\ttraining's l1: 0.0162368\tvalid_1's l1: 0.1062\n",
      "[5200]\ttraining's l1: 0.0158527\tvalid_1's l1: 0.106164\n",
      "[5300]\ttraining's l1: 0.0154523\tvalid_1's l1: 0.106131\n",
      "[5400]\ttraining's l1: 0.0150695\tvalid_1's l1: 0.106099\n",
      "[5500]\ttraining's l1: 0.0147277\tvalid_1's l1: 0.106078\n",
      "[5600]\ttraining's l1: 0.0143854\tvalid_1's l1: 0.106051\n",
      "[5700]\ttraining's l1: 0.0140687\tvalid_1's l1: 0.106029\n",
      "[5800]\ttraining's l1: 0.0137471\tvalid_1's l1: 0.106016\n",
      "[5900]\ttraining's l1: 0.0134384\tvalid_1's l1: 0.105988\n",
      "[6000]\ttraining's l1: 0.0131461\tvalid_1's l1: 0.105966\n",
      "[6100]\ttraining's l1: 0.0128483\tvalid_1's l1: 0.105941\n",
      "[6200]\ttraining's l1: 0.012551\tvalid_1's l1: 0.105921\n",
      "[6300]\ttraining's l1: 0.0122819\tvalid_1's l1: 0.105908\n",
      "[6400]\ttraining's l1: 0.012018\tvalid_1's l1: 0.105889\n",
      "[6500]\ttraining's l1: 0.0117709\tvalid_1's l1: 0.105868\n",
      "[6600]\ttraining's l1: 0.0115167\tvalid_1's l1: 0.105849\n",
      "[6700]\ttraining's l1: 0.0112715\tvalid_1's l1: 0.105835\n",
      "[6800]\ttraining's l1: 0.0110264\tvalid_1's l1: 0.105809\n",
      "[6900]\ttraining's l1: 0.0107973\tvalid_1's l1: 0.105797\n",
      "[7000]\ttraining's l1: 0.0105656\tvalid_1's l1: 0.105789\n",
      "[7100]\ttraining's l1: 0.0103506\tvalid_1's l1: 0.10578\n",
      "[7200]\ttraining's l1: 0.0101402\tvalid_1's l1: 0.105769\n",
      "[7300]\ttraining's l1: 0.00993435\tvalid_1's l1: 0.105748\n",
      "[7400]\ttraining's l1: 0.0097318\tvalid_1's l1: 0.10573\n",
      "[7500]\ttraining's l1: 0.0095446\tvalid_1's l1: 0.105723\n",
      "[7600]\ttraining's l1: 0.00935796\tvalid_1's l1: 0.105715\n",
      "[7700]\ttraining's l1: 0.00916589\tvalid_1's l1: 0.105704\n",
      "[7800]\ttraining's l1: 0.00898282\tvalid_1's l1: 0.105685\n",
      "[7900]\ttraining's l1: 0.00880682\tvalid_1's l1: 0.105675\n",
      "[8000]\ttraining's l1: 0.00863952\tvalid_1's l1: 0.105663\n",
      "[8100]\ttraining's l1: 0.00846951\tvalid_1's l1: 0.105653\n",
      "[8200]\ttraining's l1: 0.00830204\tvalid_1's l1: 0.105642\n",
      "[8300]\ttraining's l1: 0.00814824\tvalid_1's l1: 0.105634\n",
      "[8400]\ttraining's l1: 0.00799036\tvalid_1's l1: 0.105623\n",
      "[8500]\ttraining's l1: 0.00783944\tvalid_1's l1: 0.105616\n",
      "[8600]\ttraining's l1: 0.00769915\tvalid_1's l1: 0.105608\n",
      "[8700]\ttraining's l1: 0.0075529\tvalid_1's l1: 0.105594\n",
      "[8800]\ttraining's l1: 0.0074152\tvalid_1's l1: 0.105586\n",
      "[8900]\ttraining's l1: 0.00727336\tvalid_1's l1: 0.105572\n",
      "[9000]\ttraining's l1: 0.00714294\tvalid_1's l1: 0.105564\n",
      "[9100]\ttraining's l1: 0.00701307\tvalid_1's l1: 0.105556\n",
      "[9200]\ttraining's l1: 0.00689059\tvalid_1's l1: 0.105549\n",
      "[9300]\ttraining's l1: 0.00677002\tvalid_1's l1: 0.105541\n",
      "[9400]\ttraining's l1: 0.0066491\tvalid_1's l1: 0.105532\n",
      "[9500]\ttraining's l1: 0.00652848\tvalid_1's l1: 0.10552\n",
      "[9600]\ttraining's l1: 0.00642052\tvalid_1's l1: 0.105514\n",
      "[9700]\ttraining's l1: 0.00630734\tvalid_1's l1: 0.105505\n",
      "[9800]\ttraining's l1: 0.00619611\tvalid_1's l1: 0.105497\n",
      "[9900]\ttraining's l1: 0.00610152\tvalid_1's l1: 0.105491\n",
      "[10000]\ttraining's l1: 0.00599848\tvalid_1's l1: 0.105484\n",
      "[10100]\ttraining's l1: 0.0058973\tvalid_1's l1: 0.105479\n",
      "[10200]\ttraining's l1: 0.00579782\tvalid_1's l1: 0.105475\n",
      "[10300]\ttraining's l1: 0.00570175\tvalid_1's l1: 0.105471\n",
      "[10400]\ttraining's l1: 0.00560083\tvalid_1's l1: 0.105459\n",
      "[10500]\ttraining's l1: 0.00550814\tvalid_1's l1: 0.105453\n",
      "[10600]\ttraining's l1: 0.00542043\tvalid_1's l1: 0.105444\n",
      "[10700]\ttraining's l1: 0.00533397\tvalid_1's l1: 0.105438\n",
      "[10800]\ttraining's l1: 0.00524789\tvalid_1's l1: 0.105431\n",
      "[10900]\ttraining's l1: 0.00516444\tvalid_1's l1: 0.105427\n",
      "[11000]\ttraining's l1: 0.00507903\tvalid_1's l1: 0.105421\n",
      "[11100]\ttraining's l1: 0.00499758\tvalid_1's l1: 0.105411\n",
      "[11200]\ttraining's l1: 0.00491934\tvalid_1's l1: 0.105407\n",
      "[11300]\ttraining's l1: 0.00484665\tvalid_1's l1: 0.105398\n",
      "[11400]\ttraining's l1: 0.00477175\tvalid_1's l1: 0.105389\n",
      "[11500]\ttraining's l1: 0.00470079\tvalid_1's l1: 0.10538\n",
      "[11600]\ttraining's l1: 0.00462799\tvalid_1's l1: 0.105376\n",
      "[11700]\ttraining's l1: 0.00455651\tvalid_1's l1: 0.105372\n",
      "[11800]\ttraining's l1: 0.0044915\tvalid_1's l1: 0.105366\n",
      "[11900]\ttraining's l1: 0.00442553\tvalid_1's l1: 0.105362\n",
      "[12000]\ttraining's l1: 0.00435947\tvalid_1's l1: 0.105357\n",
      "[12100]\ttraining's l1: 0.00429804\tvalid_1's l1: 0.105355\n",
      "[12200]\ttraining's l1: 0.00423466\tvalid_1's l1: 0.10535\n",
      "[12300]\ttraining's l1: 0.00417655\tvalid_1's l1: 0.105346\n",
      "[12400]\ttraining's l1: 0.00411216\tvalid_1's l1: 0.105341\n",
      "[12500]\ttraining's l1: 0.00404797\tvalid_1's l1: 0.105334\n",
      "[12600]\ttraining's l1: 0.00398881\tvalid_1's l1: 0.105328\n",
      "[12700]\ttraining's l1: 0.00393274\tvalid_1's l1: 0.105323\n",
      "[12800]\ttraining's l1: 0.00387705\tvalid_1's l1: 0.105318\n",
      "[12900]\ttraining's l1: 0.00382323\tvalid_1's l1: 0.105315\n",
      "[13000]\ttraining's l1: 0.00377104\tvalid_1's l1: 0.105312\n",
      "[13100]\ttraining's l1: 0.00371987\tvalid_1's l1: 0.105305\n",
      "[13200]\ttraining's l1: 0.00367117\tvalid_1's l1: 0.1053\n",
      "[13300]\ttraining's l1: 0.00361616\tvalid_1's l1: 0.105298\n",
      "[13400]\ttraining's l1: 0.00356381\tvalid_1's l1: 0.105294\n",
      "[13500]\ttraining's l1: 0.00351498\tvalid_1's l1: 0.10529\n",
      "[13600]\ttraining's l1: 0.00346499\tvalid_1's l1: 0.105286\n",
      "[13700]\ttraining's l1: 0.0034187\tvalid_1's l1: 0.105287\n",
      "[13800]\ttraining's l1: 0.00336964\tvalid_1's l1: 0.105284\n",
      "[13900]\ttraining's l1: 0.00332513\tvalid_1's l1: 0.105278\n",
      "[14000]\ttraining's l1: 0.00327846\tvalid_1's l1: 0.105275\n",
      "[14100]\ttraining's l1: 0.00323398\tvalid_1's l1: 0.105269\n",
      "[14200]\ttraining's l1: 0.0031897\tvalid_1's l1: 0.105265\n",
      "[14300]\ttraining's l1: 0.00314444\tvalid_1's l1: 0.10526\n",
      "[14400]\ttraining's l1: 0.00310574\tvalid_1's l1: 0.105257\n",
      "[14500]\ttraining's l1: 0.0030631\tvalid_1's l1: 0.105256\n",
      "[14600]\ttraining's l1: 0.00302964\tvalid_1's l1: 0.105254\n",
      "[14700]\ttraining's l1: 0.00299483\tvalid_1's l1: 0.105249\n",
      "[14800]\ttraining's l1: 0.00295378\tvalid_1's l1: 0.105247\n",
      "[14900]\ttraining's l1: 0.00291554\tvalid_1's l1: 0.105243\n",
      "[15000]\ttraining's l1: 0.00287909\tvalid_1's l1: 0.105241\n",
      "[15100]\ttraining's l1: 0.00284642\tvalid_1's l1: 0.105239\n",
      "[15200]\ttraining's l1: 0.00281451\tvalid_1's l1: 0.105235\n",
      "[15300]\ttraining's l1: 0.00277824\tvalid_1's l1: 0.105233\n",
      "[15400]\ttraining's l1: 0.00274292\tvalid_1's l1: 0.105231\n",
      "[15500]\ttraining's l1: 0.00271149\tvalid_1's l1: 0.105228\n",
      "[15600]\ttraining's l1: 0.00267619\tvalid_1's l1: 0.105225\n",
      "[15700]\ttraining's l1: 0.00264395\tvalid_1's l1: 0.105224\n",
      "[15800]\ttraining's l1: 0.00260945\tvalid_1's l1: 0.10522\n",
      "[15900]\ttraining's l1: 0.00257677\tvalid_1's l1: 0.105216\n",
      "[16000]\ttraining's l1: 0.00254694\tvalid_1's l1: 0.105214\n",
      "[16100]\ttraining's l1: 0.00251997\tvalid_1's l1: 0.105212\n",
      "[16200]\ttraining's l1: 0.00248712\tvalid_1's l1: 0.10521\n",
      "[16300]\ttraining's l1: 0.00245665\tvalid_1's l1: 0.105208\n",
      "[16400]\ttraining's l1: 0.00242821\tvalid_1's l1: 0.105203\n",
      "[16500]\ttraining's l1: 0.00240075\tvalid_1's l1: 0.1052\n",
      "[16600]\ttraining's l1: 0.00237132\tvalid_1's l1: 0.105199\n",
      "[16700]\ttraining's l1: 0.00234393\tvalid_1's l1: 0.105197\n",
      "[16800]\ttraining's l1: 0.00231666\tvalid_1's l1: 0.105195\n",
      "[16900]\ttraining's l1: 0.00229142\tvalid_1's l1: 0.105193\n",
      "[17000]\ttraining's l1: 0.0022678\tvalid_1's l1: 0.10519\n",
      "[17100]\ttraining's l1: 0.00224384\tvalid_1's l1: 0.105188\n",
      "[17200]\ttraining's l1: 0.00221854\tvalid_1's l1: 0.105186\n",
      "[17300]\ttraining's l1: 0.00219221\tvalid_1's l1: 0.105183\n",
      "[17400]\ttraining's l1: 0.0021688\tvalid_1's l1: 0.105178\n",
      "[17500]\ttraining's l1: 0.00214662\tvalid_1's l1: 0.105176\n",
      "[17600]\ttraining's l1: 0.00212396\tvalid_1's l1: 0.105172\n",
      "[17700]\ttraining's l1: 0.00209856\tvalid_1's l1: 0.105172\n",
      "[17800]\ttraining's l1: 0.00207632\tvalid_1's l1: 0.10517\n",
      "[17900]\ttraining's l1: 0.00205481\tvalid_1's l1: 0.105169\n",
      "[18000]\ttraining's l1: 0.00203373\tvalid_1's l1: 0.105166\n",
      "[18100]\ttraining's l1: 0.00201173\tvalid_1's l1: 0.105163\n",
      "[18200]\ttraining's l1: 0.00199049\tvalid_1's l1: 0.105161\n",
      "[18300]\ttraining's l1: 0.00196919\tvalid_1's l1: 0.105159\n",
      "[18400]\ttraining's l1: 0.00194794\tvalid_1's l1: 0.105158\n",
      "[18500]\ttraining's l1: 0.00192665\tvalid_1's l1: 0.105156\n",
      "[18600]\ttraining's l1: 0.00190661\tvalid_1's l1: 0.105156\n",
      "[18700]\ttraining's l1: 0.00188723\tvalid_1's l1: 0.105155\n",
      "[18800]\ttraining's l1: 0.00186784\tvalid_1's l1: 0.105152\n",
      "[18900]\ttraining's l1: 0.00184897\tvalid_1's l1: 0.105151\n",
      "[19000]\ttraining's l1: 0.00182995\tvalid_1's l1: 0.105148\n",
      "[19100]\ttraining's l1: 0.00180868\tvalid_1's l1: 0.105146\n",
      "[19200]\ttraining's l1: 0.00178899\tvalid_1's l1: 0.105145\n",
      "[19300]\ttraining's l1: 0.00177017\tvalid_1's l1: 0.105144\n",
      "[19400]\ttraining's l1: 0.00175281\tvalid_1's l1: 0.105143\n",
      "[19500]\ttraining's l1: 0.0017354\tvalid_1's l1: 0.105142\n",
      "[19600]\ttraining's l1: 0.00171868\tvalid_1's l1: 0.10514\n",
      "[19700]\ttraining's l1: 0.00170051\tvalid_1's l1: 0.10514\n",
      "[19800]\ttraining's l1: 0.00168137\tvalid_1's l1: 0.105137\n",
      "[19900]\ttraining's l1: 0.00166501\tvalid_1's l1: 0.105135\n",
      "[20000]\ttraining's l1: 0.00164958\tvalid_1's l1: 0.105134\n",
      "[20100]\ttraining's l1: 0.00163278\tvalid_1's l1: 0.105131\n",
      "[20200]\ttraining's l1: 0.00161713\tvalid_1's l1: 0.105131\n",
      "[20300]\ttraining's l1: 0.00160041\tvalid_1's l1: 0.105129\n",
      "[20400]\ttraining's l1: 0.00158493\tvalid_1's l1: 0.105127\n",
      "[20500]\ttraining's l1: 0.00156915\tvalid_1's l1: 0.105127\n",
      "[20600]\ttraining's l1: 0.00155367\tvalid_1's l1: 0.105127\n",
      "[20700]\ttraining's l1: 0.00153886\tvalid_1's l1: 0.105126\n",
      "Early stopping, best iteration is:\n",
      "[20666]\ttraining's l1: 0.00154367\tvalid_1's l1: 0.105125\n",
      "--------------------\n",
      "Fold 4\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.279907\tvalid_1's l1: 0.285357\n",
      "[200]\ttraining's l1: 0.171472\tvalid_1's l1: 0.183275\n",
      "[300]\ttraining's l1: 0.131471\tvalid_1's l1: 0.149304\n",
      "[400]\ttraining's l1: 0.111636\tvalid_1's l1: 0.134964\n",
      "[500]\ttraining's l1: 0.0986405\tvalid_1's l1: 0.127196\n",
      "[600]\ttraining's l1: 0.089035\tvalid_1's l1: 0.122068\n",
      "[700]\ttraining's l1: 0.0818596\tvalid_1's l1: 0.118463\n",
      "[800]\ttraining's l1: 0.0759012\tvalid_1's l1: 0.11583\n",
      "[900]\ttraining's l1: 0.0709866\tvalid_1's l1: 0.113851\n",
      "[1000]\ttraining's l1: 0.0667676\tvalid_1's l1: 0.112375\n",
      "[1100]\ttraining's l1: 0.0630514\tvalid_1's l1: 0.11113\n",
      "[1200]\ttraining's l1: 0.0596719\tvalid_1's l1: 0.11011\n",
      "[1300]\ttraining's l1: 0.0566451\tvalid_1's l1: 0.109211\n",
      "[1400]\ttraining's l1: 0.0540239\tvalid_1's l1: 0.10852\n",
      "[1500]\ttraining's l1: 0.05156\tvalid_1's l1: 0.107924\n",
      "[1600]\ttraining's l1: 0.0492848\tvalid_1's l1: 0.107396\n",
      "[1700]\ttraining's l1: 0.0471893\tvalid_1's l1: 0.106934\n",
      "[1800]\ttraining's l1: 0.0452466\tvalid_1's l1: 0.106511\n",
      "[1900]\ttraining's l1: 0.0434119\tvalid_1's l1: 0.106111\n",
      "[2000]\ttraining's l1: 0.0416964\tvalid_1's l1: 0.105761\n",
      "[2100]\ttraining's l1: 0.0401251\tvalid_1's l1: 0.105456\n",
      "[2200]\ttraining's l1: 0.0386779\tvalid_1's l1: 0.105202\n",
      "[2300]\ttraining's l1: 0.0372865\tvalid_1's l1: 0.105009\n",
      "[2400]\ttraining's l1: 0.0359576\tvalid_1's l1: 0.104814\n",
      "[2500]\ttraining's l1: 0.0347209\tvalid_1's l1: 0.104644\n",
      "[2600]\ttraining's l1: 0.033539\tvalid_1's l1: 0.104458\n",
      "[2700]\ttraining's l1: 0.0324295\tvalid_1's l1: 0.104314\n",
      "[2800]\ttraining's l1: 0.0313567\tvalid_1's l1: 0.104168\n",
      "[2900]\ttraining's l1: 0.0303307\tvalid_1's l1: 0.104022\n",
      "[3000]\ttraining's l1: 0.0294085\tvalid_1's l1: 0.103901\n",
      "[3100]\ttraining's l1: 0.0284982\tvalid_1's l1: 0.103781\n",
      "[3200]\ttraining's l1: 0.027629\tvalid_1's l1: 0.103676\n",
      "[3300]\ttraining's l1: 0.0268118\tvalid_1's l1: 0.103586\n",
      "[3400]\ttraining's l1: 0.0260127\tvalid_1's l1: 0.103507\n",
      "[3500]\ttraining's l1: 0.0252559\tvalid_1's l1: 0.103422\n",
      "[3600]\ttraining's l1: 0.0245492\tvalid_1's l1: 0.103355\n",
      "[3700]\ttraining's l1: 0.0238402\tvalid_1's l1: 0.103289\n",
      "[3800]\ttraining's l1: 0.0231611\tvalid_1's l1: 0.103228\n",
      "[3900]\ttraining's l1: 0.0225086\tvalid_1's l1: 0.103192\n",
      "[4000]\ttraining's l1: 0.0218681\tvalid_1's l1: 0.103128\n",
      "[4100]\ttraining's l1: 0.0212902\tvalid_1's l1: 0.103088\n",
      "[4200]\ttraining's l1: 0.0207245\tvalid_1's l1: 0.103059\n",
      "[4300]\ttraining's l1: 0.0201681\tvalid_1's l1: 0.103002\n",
      "[4400]\ttraining's l1: 0.0196496\tvalid_1's l1: 0.102971\n",
      "[4500]\ttraining's l1: 0.0191418\tvalid_1's l1: 0.10294\n",
      "[4600]\ttraining's l1: 0.018658\tvalid_1's l1: 0.102907\n",
      "[4700]\ttraining's l1: 0.0181828\tvalid_1's l1: 0.102871\n",
      "[4800]\ttraining's l1: 0.0177303\tvalid_1's l1: 0.102832\n",
      "[4900]\ttraining's l1: 0.0172759\tvalid_1's l1: 0.102812\n",
      "[5000]\ttraining's l1: 0.0168302\tvalid_1's l1: 0.102781\n",
      "[5100]\ttraining's l1: 0.0164134\tvalid_1's l1: 0.102754\n",
      "[5200]\ttraining's l1: 0.0160188\tvalid_1's l1: 0.102734\n",
      "[5300]\ttraining's l1: 0.0156083\tvalid_1's l1: 0.102713\n",
      "[5400]\ttraining's l1: 0.0152281\tvalid_1's l1: 0.102695\n",
      "[5500]\ttraining's l1: 0.0148841\tvalid_1's l1: 0.102678\n",
      "[5600]\ttraining's l1: 0.0145441\tvalid_1's l1: 0.102661\n",
      "[5700]\ttraining's l1: 0.0142248\tvalid_1's l1: 0.102649\n",
      "[5800]\ttraining's l1: 0.0138939\tvalid_1's l1: 0.102636\n",
      "[5900]\ttraining's l1: 0.0135684\tvalid_1's l1: 0.102616\n",
      "[6000]\ttraining's l1: 0.0132667\tvalid_1's l1: 0.102597\n",
      "[6100]\ttraining's l1: 0.0129588\tvalid_1's l1: 0.102578\n",
      "[6200]\ttraining's l1: 0.01266\tvalid_1's l1: 0.102562\n",
      "[6300]\ttraining's l1: 0.0123804\tvalid_1's l1: 0.102545\n",
      "[6400]\ttraining's l1: 0.0121191\tvalid_1's l1: 0.102533\n",
      "[6500]\ttraining's l1: 0.0118714\tvalid_1's l1: 0.10252\n",
      "[6600]\ttraining's l1: 0.011614\tvalid_1's l1: 0.102509\n",
      "[6700]\ttraining's l1: 0.0113686\tvalid_1's l1: 0.1025\n",
      "[6800]\ttraining's l1: 0.01112\tvalid_1's l1: 0.102493\n",
      "[6900]\ttraining's l1: 0.0108886\tvalid_1's l1: 0.102478\n",
      "[7000]\ttraining's l1: 0.0106555\tvalid_1's l1: 0.102468\n",
      "[7100]\ttraining's l1: 0.0104368\tvalid_1's l1: 0.102453\n",
      "[7200]\ttraining's l1: 0.0102247\tvalid_1's l1: 0.102441\n",
      "[7300]\ttraining's l1: 0.0100233\tvalid_1's l1: 0.102437\n",
      "[7400]\ttraining's l1: 0.00981768\tvalid_1's l1: 0.102431\n",
      "[7500]\ttraining's l1: 0.00963122\tvalid_1's l1: 0.10242\n",
      "[7600]\ttraining's l1: 0.00944524\tvalid_1's l1: 0.102414\n",
      "[7700]\ttraining's l1: 0.00924825\tvalid_1's l1: 0.102411\n",
      "[7800]\ttraining's l1: 0.00906423\tvalid_1's l1: 0.102401\n",
      "[7900]\ttraining's l1: 0.00889124\tvalid_1's l1: 0.102385\n",
      "[8000]\ttraining's l1: 0.00872054\tvalid_1's l1: 0.102382\n",
      "[8100]\ttraining's l1: 0.00854502\tvalid_1's l1: 0.102374\n",
      "[8200]\ttraining's l1: 0.00837386\tvalid_1's l1: 0.102365\n",
      "[8300]\ttraining's l1: 0.00821451\tvalid_1's l1: 0.102353\n",
      "[8400]\ttraining's l1: 0.00805553\tvalid_1's l1: 0.102346\n",
      "[8500]\ttraining's l1: 0.00790765\tvalid_1's l1: 0.102346\n",
      "[8600]\ttraining's l1: 0.00776874\tvalid_1's l1: 0.10234\n",
      "[8700]\ttraining's l1: 0.00761693\tvalid_1's l1: 0.102331\n",
      "[8800]\ttraining's l1: 0.00747772\tvalid_1's l1: 0.102324\n",
      "[8900]\ttraining's l1: 0.00733476\tvalid_1's l1: 0.102316\n",
      "[9000]\ttraining's l1: 0.00720183\tvalid_1's l1: 0.102311\n",
      "[9100]\ttraining's l1: 0.00707365\tvalid_1's l1: 0.102304\n",
      "[9200]\ttraining's l1: 0.00695062\tvalid_1's l1: 0.102299\n",
      "[9300]\ttraining's l1: 0.00682547\tvalid_1's l1: 0.102292\n",
      "[9400]\ttraining's l1: 0.00669955\tvalid_1's l1: 0.102289\n",
      "[9500]\ttraining's l1: 0.00657863\tvalid_1's l1: 0.102286\n",
      "[9600]\ttraining's l1: 0.00647128\tvalid_1's l1: 0.10228\n",
      "[9700]\ttraining's l1: 0.00635348\tvalid_1's l1: 0.102268\n",
      "[9800]\ttraining's l1: 0.0062402\tvalid_1's l1: 0.102264\n",
      "Early stopping, best iteration is:\n",
      "[9763]\ttraining's l1: 0.00628524\tvalid_1's l1: 0.102262\n",
      "--------------------\n",
      "Fold 5\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.280893\tvalid_1's l1: 0.289703\n",
      "[200]\ttraining's l1: 0.171084\tvalid_1's l1: 0.189152\n",
      "[300]\ttraining's l1: 0.129955\tvalid_1's l1: 0.154592\n",
      "[400]\ttraining's l1: 0.110052\tvalid_1's l1: 0.13959\n",
      "[500]\ttraining's l1: 0.0970607\tvalid_1's l1: 0.130798\n",
      "[600]\ttraining's l1: 0.0880336\tvalid_1's l1: 0.125583\n",
      "[700]\ttraining's l1: 0.08099\tvalid_1's l1: 0.121934\n",
      "[800]\ttraining's l1: 0.075481\tvalid_1's l1: 0.11946\n",
      "[900]\ttraining's l1: 0.0706131\tvalid_1's l1: 0.11744\n",
      "[1000]\ttraining's l1: 0.0664102\tvalid_1's l1: 0.115922\n",
      "[1100]\ttraining's l1: 0.0628073\tvalid_1's l1: 0.114628\n",
      "[1200]\ttraining's l1: 0.0595454\tvalid_1's l1: 0.113603\n",
      "[1300]\ttraining's l1: 0.0566749\tvalid_1's l1: 0.112765\n",
      "[1400]\ttraining's l1: 0.0540804\tvalid_1's l1: 0.112075\n",
      "[1500]\ttraining's l1: 0.0516195\tvalid_1's l1: 0.11153\n",
      "[1600]\ttraining's l1: 0.0493703\tvalid_1's l1: 0.111004\n",
      "[1700]\ttraining's l1: 0.0472685\tvalid_1's l1: 0.110598\n",
      "[1800]\ttraining's l1: 0.0453724\tvalid_1's l1: 0.110196\n",
      "[1900]\ttraining's l1: 0.04358\tvalid_1's l1: 0.109843\n",
      "[2000]\ttraining's l1: 0.0418972\tvalid_1's l1: 0.109556\n",
      "[2100]\ttraining's l1: 0.0403056\tvalid_1's l1: 0.10928\n",
      "[2200]\ttraining's l1: 0.038765\tvalid_1's l1: 0.109008\n",
      "[2300]\ttraining's l1: 0.0373605\tvalid_1's l1: 0.108808\n",
      "[2400]\ttraining's l1: 0.0360223\tvalid_1's l1: 0.108604\n",
      "[2500]\ttraining's l1: 0.0347894\tvalid_1's l1: 0.108453\n",
      "[2600]\ttraining's l1: 0.0335975\tvalid_1's l1: 0.108298\n",
      "[2700]\ttraining's l1: 0.0324893\tvalid_1's l1: 0.108124\n",
      "[2800]\ttraining's l1: 0.0314209\tvalid_1's l1: 0.107975\n",
      "[2900]\ttraining's l1: 0.0304353\tvalid_1's l1: 0.107827\n",
      "[3000]\ttraining's l1: 0.0294824\tvalid_1's l1: 0.107705\n",
      "[3100]\ttraining's l1: 0.0285753\tvalid_1's l1: 0.107612\n",
      "[3200]\ttraining's l1: 0.0277058\tvalid_1's l1: 0.107491\n",
      "[3300]\ttraining's l1: 0.0268622\tvalid_1's l1: 0.107383\n",
      "[3400]\ttraining's l1: 0.0260605\tvalid_1's l1: 0.107279\n",
      "[3500]\ttraining's l1: 0.0252994\tvalid_1's l1: 0.107222\n",
      "[3600]\ttraining's l1: 0.024573\tvalid_1's l1: 0.107157\n",
      "[3700]\ttraining's l1: 0.0238676\tvalid_1's l1: 0.10709\n",
      "[3800]\ttraining's l1: 0.0232214\tvalid_1's l1: 0.107019\n",
      "[3900]\ttraining's l1: 0.0225701\tvalid_1's l1: 0.10695\n",
      "[4000]\ttraining's l1: 0.0219442\tvalid_1's l1: 0.106883\n",
      "[4100]\ttraining's l1: 0.0213412\tvalid_1's l1: 0.10683\n",
      "[4200]\ttraining's l1: 0.0207759\tvalid_1's l1: 0.106778\n",
      "[4300]\ttraining's l1: 0.0202384\tvalid_1's l1: 0.106728\n",
      "[4400]\ttraining's l1: 0.0197088\tvalid_1's l1: 0.106662\n",
      "[4500]\ttraining's l1: 0.0192061\tvalid_1's l1: 0.106618\n",
      "[4600]\ttraining's l1: 0.0187303\tvalid_1's l1: 0.106573\n",
      "[4700]\ttraining's l1: 0.0182648\tvalid_1's l1: 0.106536\n",
      "[4800]\ttraining's l1: 0.0178085\tvalid_1's l1: 0.106505\n",
      "[4900]\ttraining's l1: 0.0173695\tvalid_1's l1: 0.106479\n",
      "[5000]\ttraining's l1: 0.0169544\tvalid_1's l1: 0.106455\n",
      "[5100]\ttraining's l1: 0.0165429\tvalid_1's l1: 0.10642\n",
      "[5200]\ttraining's l1: 0.016148\tvalid_1's l1: 0.106393\n",
      "[5300]\ttraining's l1: 0.0157545\tvalid_1's l1: 0.10638\n",
      "[5400]\ttraining's l1: 0.0153958\tvalid_1's l1: 0.106342\n",
      "[5500]\ttraining's l1: 0.0150364\tvalid_1's l1: 0.10632\n",
      "[5600]\ttraining's l1: 0.0146841\tvalid_1's l1: 0.106294\n",
      "[5700]\ttraining's l1: 0.0143349\tvalid_1's l1: 0.106288\n",
      "[5800]\ttraining's l1: 0.0140138\tvalid_1's l1: 0.106271\n",
      "[5900]\ttraining's l1: 0.0136918\tvalid_1's l1: 0.106269\n",
      "[6000]\ttraining's l1: 0.013377\tvalid_1's l1: 0.10625\n",
      "[6100]\ttraining's l1: 0.0130711\tvalid_1's l1: 0.106224\n",
      "[6200]\ttraining's l1: 0.0127794\tvalid_1's l1: 0.106209\n",
      "[6300]\ttraining's l1: 0.012493\tvalid_1's l1: 0.106198\n",
      "[6400]\ttraining's l1: 0.0122278\tvalid_1's l1: 0.106178\n",
      "[6500]\ttraining's l1: 0.0119586\tvalid_1's l1: 0.106167\n",
      "[6600]\ttraining's l1: 0.0116977\tvalid_1's l1: 0.106153\n",
      "[6700]\ttraining's l1: 0.011463\tvalid_1's l1: 0.106144\n",
      "[6800]\ttraining's l1: 0.011233\tvalid_1's l1: 0.106137\n",
      "[6900]\ttraining's l1: 0.011004\tvalid_1's l1: 0.106127\n",
      "[7000]\ttraining's l1: 0.0107723\tvalid_1's l1: 0.10612\n",
      "[7100]\ttraining's l1: 0.0105491\tvalid_1's l1: 0.106107\n",
      "[7200]\ttraining's l1: 0.0103298\tvalid_1's l1: 0.106098\n",
      "[7300]\ttraining's l1: 0.0101172\tvalid_1's l1: 0.106091\n",
      "[7400]\ttraining's l1: 0.00990401\tvalid_1's l1: 0.106081\n",
      "[7500]\ttraining's l1: 0.00970934\tvalid_1's l1: 0.10607\n",
      "[7600]\ttraining's l1: 0.00951631\tvalid_1's l1: 0.106059\n",
      "[7700]\ttraining's l1: 0.00931984\tvalid_1's l1: 0.106044\n",
      "[7800]\ttraining's l1: 0.00914535\tvalid_1's l1: 0.106041\n",
      "Early stopping, best iteration is:\n",
      "[7742]\ttraining's l1: 0.0092494\tvalid_1's l1: 0.106038\n",
      "--------------------\n",
      "Fold 6\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.28084\tvalid_1's l1: 0.287199\n",
      "[200]\ttraining's l1: 0.171151\tvalid_1's l1: 0.185932\n",
      "[300]\ttraining's l1: 0.130231\tvalid_1's l1: 0.151622\n",
      "[400]\ttraining's l1: 0.110454\tvalid_1's l1: 0.137041\n",
      "[500]\ttraining's l1: 0.0974553\tvalid_1's l1: 0.128562\n",
      "[600]\ttraining's l1: 0.088484\tvalid_1's l1: 0.123391\n",
      "[700]\ttraining's l1: 0.0814477\tvalid_1's l1: 0.119804\n",
      "[800]\ttraining's l1: 0.0759053\tvalid_1's l1: 0.117281\n",
      "[900]\ttraining's l1: 0.0710223\tvalid_1's l1: 0.115119\n",
      "[1000]\ttraining's l1: 0.0668556\tvalid_1's l1: 0.113533\n",
      "[1100]\ttraining's l1: 0.0632042\tvalid_1's l1: 0.112346\n",
      "[1200]\ttraining's l1: 0.0598591\tvalid_1's l1: 0.111321\n",
      "[1300]\ttraining's l1: 0.0569358\tvalid_1's l1: 0.110477\n",
      "[1400]\ttraining's l1: 0.0543295\tvalid_1's l1: 0.109792\n",
      "[1500]\ttraining's l1: 0.0518174\tvalid_1's l1: 0.10919\n",
      "[1600]\ttraining's l1: 0.049535\tvalid_1's l1: 0.10872\n",
      "[1700]\ttraining's l1: 0.0474411\tvalid_1's l1: 0.108267\n",
      "[1800]\ttraining's l1: 0.0455251\tvalid_1's l1: 0.107921\n",
      "[1900]\ttraining's l1: 0.0436983\tvalid_1's l1: 0.107553\n",
      "[2000]\ttraining's l1: 0.042006\tvalid_1's l1: 0.107264\n",
      "[2100]\ttraining's l1: 0.0403812\tvalid_1's l1: 0.106985\n",
      "[2200]\ttraining's l1: 0.0388449\tvalid_1's l1: 0.106728\n",
      "[2300]\ttraining's l1: 0.0374576\tvalid_1's l1: 0.106527\n",
      "[2400]\ttraining's l1: 0.0361022\tvalid_1's l1: 0.106334\n",
      "[2500]\ttraining's l1: 0.0348654\tvalid_1's l1: 0.106158\n",
      "[2600]\ttraining's l1: 0.0336738\tvalid_1's l1: 0.10602\n",
      "[2700]\ttraining's l1: 0.0325413\tvalid_1's l1: 0.105878\n",
      "[2800]\ttraining's l1: 0.0314888\tvalid_1's l1: 0.10573\n",
      "[2900]\ttraining's l1: 0.0305\tvalid_1's l1: 0.105627\n",
      "[3000]\ttraining's l1: 0.0295384\tvalid_1's l1: 0.10552\n",
      "[3100]\ttraining's l1: 0.0286312\tvalid_1's l1: 0.105414\n",
      "[3200]\ttraining's l1: 0.02777\tvalid_1's l1: 0.105309\n",
      "[3300]\ttraining's l1: 0.0269245\tvalid_1's l1: 0.105216\n",
      "[3400]\ttraining's l1: 0.0261153\tvalid_1's l1: 0.105126\n",
      "[3500]\ttraining's l1: 0.0253332\tvalid_1's l1: 0.105041\n",
      "[3600]\ttraining's l1: 0.0246116\tvalid_1's l1: 0.104959\n",
      "[3700]\ttraining's l1: 0.0239153\tvalid_1's l1: 0.104891\n",
      "[3800]\ttraining's l1: 0.0232754\tvalid_1's l1: 0.104817\n",
      "[3900]\ttraining's l1: 0.0226219\tvalid_1's l1: 0.104771\n",
      "[4000]\ttraining's l1: 0.0219827\tvalid_1's l1: 0.104719\n",
      "[4100]\ttraining's l1: 0.0213632\tvalid_1's l1: 0.104679\n",
      "[4200]\ttraining's l1: 0.020795\tvalid_1's l1: 0.104636\n",
      "[4300]\ttraining's l1: 0.0202532\tvalid_1's l1: 0.104589\n",
      "[4400]\ttraining's l1: 0.0197134\tvalid_1's l1: 0.104536\n",
      "[4500]\ttraining's l1: 0.0192116\tvalid_1's l1: 0.104499\n",
      "[4600]\ttraining's l1: 0.018731\tvalid_1's l1: 0.10446\n",
      "[4700]\ttraining's l1: 0.0182725\tvalid_1's l1: 0.10443\n",
      "[4800]\ttraining's l1: 0.0178139\tvalid_1's l1: 0.104389\n",
      "[4900]\ttraining's l1: 0.0173766\tvalid_1's l1: 0.104354\n",
      "[5000]\ttraining's l1: 0.0169627\tvalid_1's l1: 0.104333\n",
      "[5100]\ttraining's l1: 0.0165556\tvalid_1's l1: 0.104295\n",
      "[5200]\ttraining's l1: 0.0161575\tvalid_1's l1: 0.104263\n",
      "[5300]\ttraining's l1: 0.0157771\tvalid_1's l1: 0.104243\n",
      "[5400]\ttraining's l1: 0.0154229\tvalid_1's l1: 0.104215\n",
      "[5500]\ttraining's l1: 0.0150628\tvalid_1's l1: 0.104188\n",
      "[5600]\ttraining's l1: 0.0147045\tvalid_1's l1: 0.104153\n",
      "[5700]\ttraining's l1: 0.0143633\tvalid_1's l1: 0.104134\n",
      "[5800]\ttraining's l1: 0.0140438\tvalid_1's l1: 0.104115\n",
      "[5900]\ttraining's l1: 0.0137245\tvalid_1's l1: 0.1041\n",
      "[6000]\ttraining's l1: 0.0134079\tvalid_1's l1: 0.104079\n",
      "[6100]\ttraining's l1: 0.0131059\tvalid_1's l1: 0.104068\n",
      "[6200]\ttraining's l1: 0.0128051\tvalid_1's l1: 0.104046\n",
      "[6300]\ttraining's l1: 0.012517\tvalid_1's l1: 0.104033\n",
      "[6400]\ttraining's l1: 0.0122432\tvalid_1's l1: 0.104012\n",
      "[6500]\ttraining's l1: 0.0119688\tvalid_1's l1: 0.103998\n",
      "[6600]\ttraining's l1: 0.0117073\tvalid_1's l1: 0.103977\n",
      "[6700]\ttraining's l1: 0.0114702\tvalid_1's l1: 0.103967\n",
      "[6800]\ttraining's l1: 0.0112386\tvalid_1's l1: 0.103953\n",
      "[6900]\ttraining's l1: 0.0110103\tvalid_1's l1: 0.103936\n",
      "[7000]\ttraining's l1: 0.0107764\tvalid_1's l1: 0.103933\n",
      "[7100]\ttraining's l1: 0.0105537\tvalid_1's l1: 0.103923\n",
      "[7200]\ttraining's l1: 0.0103319\tvalid_1's l1: 0.103917\n",
      "[7300]\ttraining's l1: 0.0101235\tvalid_1's l1: 0.103911\n",
      "[7400]\ttraining's l1: 0.00991193\tvalid_1's l1: 0.103899\n",
      "[7500]\ttraining's l1: 0.00971639\tvalid_1's l1: 0.103883\n",
      "[7600]\ttraining's l1: 0.00951663\tvalid_1's l1: 0.10387\n",
      "[7700]\ttraining's l1: 0.00932098\tvalid_1's l1: 0.103858\n",
      "[7800]\ttraining's l1: 0.00914392\tvalid_1's l1: 0.103851\n",
      "[7900]\ttraining's l1: 0.00896693\tvalid_1's l1: 0.103845\n",
      "[8000]\ttraining's l1: 0.00879303\tvalid_1's l1: 0.103833\n",
      "[8100]\ttraining's l1: 0.00863555\tvalid_1's l1: 0.103822\n",
      "[8200]\ttraining's l1: 0.00846523\tvalid_1's l1: 0.103811\n",
      "[8300]\ttraining's l1: 0.00830681\tvalid_1's l1: 0.103809\n",
      "[8400]\ttraining's l1: 0.00815352\tvalid_1's l1: 0.103796\n",
      "[8500]\ttraining's l1: 0.00799921\tvalid_1's l1: 0.103788\n",
      "[8600]\ttraining's l1: 0.00784841\tvalid_1's l1: 0.10378\n",
      "[8700]\ttraining's l1: 0.00770932\tvalid_1's l1: 0.103773\n",
      "[8800]\ttraining's l1: 0.00756866\tvalid_1's l1: 0.103765\n",
      "[8900]\ttraining's l1: 0.00742739\tvalid_1's l1: 0.103763\n",
      "[9000]\ttraining's l1: 0.00729069\tvalid_1's l1: 0.103757\n",
      "Early stopping, best iteration is:\n",
      "[8962]\ttraining's l1: 0.00734309\tvalid_1's l1: 0.103755\n",
      "--------------------\n",
      "Fold 7\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.279471\tvalid_1's l1: 0.286444\n",
      "[200]\ttraining's l1: 0.170833\tvalid_1's l1: 0.18648\n",
      "[300]\ttraining's l1: 0.130747\tvalid_1's l1: 0.153954\n",
      "[400]\ttraining's l1: 0.111042\tvalid_1's l1: 0.139519\n",
      "[500]\ttraining's l1: 0.0982874\tvalid_1's l1: 0.130967\n",
      "[600]\ttraining's l1: 0.0888235\tvalid_1's l1: 0.125126\n",
      "[700]\ttraining's l1: 0.081709\tvalid_1's l1: 0.121509\n",
      "[800]\ttraining's l1: 0.0757941\tvalid_1's l1: 0.118693\n",
      "[900]\ttraining's l1: 0.070901\tvalid_1's l1: 0.116695\n",
      "[1000]\ttraining's l1: 0.0666906\tvalid_1's l1: 0.115161\n",
      "[1100]\ttraining's l1: 0.0629676\tvalid_1's l1: 0.113947\n",
      "[1200]\ttraining's l1: 0.0595763\tvalid_1's l1: 0.112941\n",
      "[1300]\ttraining's l1: 0.0565842\tvalid_1's l1: 0.11218\n",
      "[1400]\ttraining's l1: 0.0539533\tvalid_1's l1: 0.111524\n",
      "[1500]\ttraining's l1: 0.0514558\tvalid_1's l1: 0.110919\n",
      "[1600]\ttraining's l1: 0.04916\tvalid_1's l1: 0.110437\n",
      "[1700]\ttraining's l1: 0.0470485\tvalid_1's l1: 0.109994\n",
      "[1800]\ttraining's l1: 0.0451248\tvalid_1's l1: 0.109649\n",
      "[1900]\ttraining's l1: 0.0432739\tvalid_1's l1: 0.109317\n",
      "[2000]\ttraining's l1: 0.0415859\tvalid_1's l1: 0.109036\n",
      "[2100]\ttraining's l1: 0.0400247\tvalid_1's l1: 0.108763\n",
      "[2200]\ttraining's l1: 0.0385411\tvalid_1's l1: 0.108519\n",
      "[2300]\ttraining's l1: 0.0371338\tvalid_1's l1: 0.108349\n",
      "[2400]\ttraining's l1: 0.0358169\tvalid_1's l1: 0.108143\n",
      "[2500]\ttraining's l1: 0.0345708\tvalid_1's l1: 0.107979\n",
      "[2600]\ttraining's l1: 0.0333946\tvalid_1's l1: 0.107814\n",
      "[2700]\ttraining's l1: 0.0322739\tvalid_1's l1: 0.107665\n",
      "[2800]\ttraining's l1: 0.0312453\tvalid_1's l1: 0.107558\n",
      "[2900]\ttraining's l1: 0.0302117\tvalid_1's l1: 0.107434\n",
      "[3000]\ttraining's l1: 0.0292664\tvalid_1's l1: 0.107318\n",
      "[3100]\ttraining's l1: 0.0283485\tvalid_1's l1: 0.107211\n",
      "[3200]\ttraining's l1: 0.0274766\tvalid_1's l1: 0.107102\n",
      "[3300]\ttraining's l1: 0.0266582\tvalid_1's l1: 0.107045\n",
      "[3400]\ttraining's l1: 0.0258445\tvalid_1's l1: 0.106942\n",
      "[3500]\ttraining's l1: 0.0250846\tvalid_1's l1: 0.106884\n",
      "[3600]\ttraining's l1: 0.024398\tvalid_1's l1: 0.106833\n",
      "[3700]\ttraining's l1: 0.0237118\tvalid_1's l1: 0.106753\n",
      "[3800]\ttraining's l1: 0.0230366\tvalid_1's l1: 0.106703\n",
      "[3900]\ttraining's l1: 0.0223975\tvalid_1's l1: 0.106647\n",
      "[4000]\ttraining's l1: 0.0217778\tvalid_1's l1: 0.10659\n",
      "[4100]\ttraining's l1: 0.0211933\tvalid_1's l1: 0.106524\n",
      "[4200]\ttraining's l1: 0.0206233\tvalid_1's l1: 0.106465\n",
      "[4300]\ttraining's l1: 0.0200639\tvalid_1's l1: 0.10643\n",
      "[4400]\ttraining's l1: 0.0195443\tvalid_1's l1: 0.10639\n",
      "[4500]\ttraining's l1: 0.0190479\tvalid_1's l1: 0.106352\n",
      "[4600]\ttraining's l1: 0.0185576\tvalid_1's l1: 0.106325\n",
      "[4700]\ttraining's l1: 0.0180822\tvalid_1's l1: 0.106273\n",
      "[4800]\ttraining's l1: 0.017622\tvalid_1's l1: 0.106233\n",
      "[4900]\ttraining's l1: 0.0171776\tvalid_1's l1: 0.106206\n",
      "[5000]\ttraining's l1: 0.0167393\tvalid_1's l1: 0.106167\n",
      "[5100]\ttraining's l1: 0.0163271\tvalid_1's l1: 0.106138\n",
      "[5200]\ttraining's l1: 0.0159377\tvalid_1's l1: 0.106114\n",
      "[5300]\ttraining's l1: 0.0155456\tvalid_1's l1: 0.10608\n",
      "[5400]\ttraining's l1: 0.0151624\tvalid_1's l1: 0.106043\n",
      "[5500]\ttraining's l1: 0.0148079\tvalid_1's l1: 0.106013\n",
      "[5600]\ttraining's l1: 0.0144735\tvalid_1's l1: 0.105995\n",
      "[5700]\ttraining's l1: 0.0141533\tvalid_1's l1: 0.105966\n",
      "[5800]\ttraining's l1: 0.0138181\tvalid_1's l1: 0.105934\n",
      "[5900]\ttraining's l1: 0.0135083\tvalid_1's l1: 0.105908\n",
      "[6000]\ttraining's l1: 0.0132062\tvalid_1's l1: 0.1059\n",
      "[6100]\ttraining's l1: 0.0129037\tvalid_1's l1: 0.105877\n",
      "[6200]\ttraining's l1: 0.0126064\tvalid_1's l1: 0.105855\n",
      "[6300]\ttraining's l1: 0.0123366\tvalid_1's l1: 0.105831\n",
      "[6400]\ttraining's l1: 0.0120777\tvalid_1's l1: 0.105824\n",
      "[6500]\ttraining's l1: 0.0118303\tvalid_1's l1: 0.105802\n",
      "[6600]\ttraining's l1: 0.0115718\tvalid_1's l1: 0.105789\n",
      "[6700]\ttraining's l1: 0.0113276\tvalid_1's l1: 0.105764\n",
      "[6800]\ttraining's l1: 0.0110786\tvalid_1's l1: 0.105742\n",
      "[6900]\ttraining's l1: 0.0108472\tvalid_1's l1: 0.10572\n",
      "[7000]\ttraining's l1: 0.010613\tvalid_1's l1: 0.105697\n",
      "[7100]\ttraining's l1: 0.0103922\tvalid_1's l1: 0.105685\n",
      "[7200]\ttraining's l1: 0.0101781\tvalid_1's l1: 0.105672\n",
      "[7300]\ttraining's l1: 0.00997164\tvalid_1's l1: 0.105657\n",
      "[7400]\ttraining's l1: 0.00976924\tvalid_1's l1: 0.105636\n",
      "[7500]\ttraining's l1: 0.00957761\tvalid_1's l1: 0.105624\n",
      "[7600]\ttraining's l1: 0.00938895\tvalid_1's l1: 0.10561\n",
      "[7700]\ttraining's l1: 0.00918805\tvalid_1's l1: 0.105591\n",
      "[7800]\ttraining's l1: 0.00900537\tvalid_1's l1: 0.105582\n",
      "[7900]\ttraining's l1: 0.00883159\tvalid_1's l1: 0.105566\n",
      "[8000]\ttraining's l1: 0.00866468\tvalid_1's l1: 0.105549\n",
      "[8100]\ttraining's l1: 0.00849176\tvalid_1's l1: 0.105536\n",
      "[8200]\ttraining's l1: 0.00831992\tvalid_1's l1: 0.105521\n",
      "[8300]\ttraining's l1: 0.00815874\tvalid_1's l1: 0.10551\n",
      "[8400]\ttraining's l1: 0.00800098\tvalid_1's l1: 0.1055\n",
      "[8500]\ttraining's l1: 0.00784904\tvalid_1's l1: 0.105491\n",
      "[8600]\ttraining's l1: 0.0077088\tvalid_1's l1: 0.105492\n",
      "[8700]\ttraining's l1: 0.00755848\tvalid_1's l1: 0.105481\n",
      "[8800]\ttraining's l1: 0.0074191\tvalid_1's l1: 0.105467\n",
      "[8900]\ttraining's l1: 0.00727903\tvalid_1's l1: 0.105453\n",
      "[9000]\ttraining's l1: 0.00714538\tvalid_1's l1: 0.105445\n",
      "[9100]\ttraining's l1: 0.00701265\tvalid_1's l1: 0.105443\n",
      "[9200]\ttraining's l1: 0.00688863\tvalid_1's l1: 0.105433\n",
      "[9300]\ttraining's l1: 0.00676473\tvalid_1's l1: 0.105425\n",
      "[9400]\ttraining's l1: 0.00663819\tvalid_1's l1: 0.105415\n",
      "[9500]\ttraining's l1: 0.00651895\tvalid_1's l1: 0.105406\n",
      "[9600]\ttraining's l1: 0.0064129\tvalid_1's l1: 0.105397\n",
      "[9700]\ttraining's l1: 0.00629344\tvalid_1's l1: 0.105387\n",
      "[9800]\ttraining's l1: 0.00618059\tvalid_1's l1: 0.10538\n",
      "[9900]\ttraining's l1: 0.00608312\tvalid_1's l1: 0.105373\n",
      "[10000]\ttraining's l1: 0.00597723\tvalid_1's l1: 0.105363\n",
      "[10100]\ttraining's l1: 0.00587552\tvalid_1's l1: 0.105361\n",
      "[10200]\ttraining's l1: 0.00577767\tvalid_1's l1: 0.105359\n",
      "[10300]\ttraining's l1: 0.00568149\tvalid_1's l1: 0.105349\n",
      "[10400]\ttraining's l1: 0.00558111\tvalid_1's l1: 0.105344\n",
      "[10500]\ttraining's l1: 0.00548727\tvalid_1's l1: 0.105335\n",
      "[10600]\ttraining's l1: 0.0053975\tvalid_1's l1: 0.105326\n",
      "[10700]\ttraining's l1: 0.00531265\tvalid_1's l1: 0.105323\n",
      "[10800]\ttraining's l1: 0.00522422\tvalid_1's l1: 0.105319\n",
      "[10900]\ttraining's l1: 0.00513957\tvalid_1's l1: 0.105312\n",
      "[11000]\ttraining's l1: 0.00505621\tvalid_1's l1: 0.105306\n",
      "[11100]\ttraining's l1: 0.00497554\tvalid_1's l1: 0.105299\n",
      "[11200]\ttraining's l1: 0.00489621\tvalid_1's l1: 0.105296\n",
      "[11300]\ttraining's l1: 0.00481977\tvalid_1's l1: 0.105293\n",
      "[11400]\ttraining's l1: 0.00474729\tvalid_1's l1: 0.105289\n",
      "[11500]\ttraining's l1: 0.00467372\tvalid_1's l1: 0.105285\n",
      "[11600]\ttraining's l1: 0.00460046\tvalid_1's l1: 0.105284\n",
      "[11700]\ttraining's l1: 0.00452888\tvalid_1's l1: 0.105277\n",
      "[11800]\ttraining's l1: 0.00446249\tvalid_1's l1: 0.105272\n",
      "[11900]\ttraining's l1: 0.00439708\tvalid_1's l1: 0.105264\n",
      "[12000]\ttraining's l1: 0.004329\tvalid_1's l1: 0.10526\n",
      "[12100]\ttraining's l1: 0.0042647\tvalid_1's l1: 0.105253\n",
      "[12200]\ttraining's l1: 0.0042005\tvalid_1's l1: 0.105249\n",
      "[12300]\ttraining's l1: 0.00414037\tvalid_1's l1: 0.105244\n",
      "[12400]\ttraining's l1: 0.00407556\tvalid_1's l1: 0.105241\n",
      "[12500]\ttraining's l1: 0.00401306\tvalid_1's l1: 0.105237\n",
      "[12600]\ttraining's l1: 0.00395465\tvalid_1's l1: 0.105233\n",
      "[12700]\ttraining's l1: 0.00389984\tvalid_1's l1: 0.105229\n",
      "[12800]\ttraining's l1: 0.00384271\tvalid_1's l1: 0.105228\n",
      "[12900]\ttraining's l1: 0.00378957\tvalid_1's l1: 0.105225\n",
      "[13000]\ttraining's l1: 0.00373742\tvalid_1's l1: 0.105221\n",
      "[13100]\ttraining's l1: 0.00368488\tvalid_1's l1: 0.105217\n",
      "[13200]\ttraining's l1: 0.0036341\tvalid_1's l1: 0.105214\n",
      "[13300]\ttraining's l1: 0.0035764\tvalid_1's l1: 0.105208\n",
      "[13400]\ttraining's l1: 0.00352331\tvalid_1's l1: 0.105203\n",
      "[13500]\ttraining's l1: 0.0034736\tvalid_1's l1: 0.1052\n",
      "[13600]\ttraining's l1: 0.00342337\tvalid_1's l1: 0.105196\n",
      "[13700]\ttraining's l1: 0.00337679\tvalid_1's l1: 0.105195\n",
      "[13800]\ttraining's l1: 0.00332757\tvalid_1's l1: 0.105194\n",
      "[13900]\ttraining's l1: 0.00328262\tvalid_1's l1: 0.105193\n",
      "[14000]\ttraining's l1: 0.00323681\tvalid_1's l1: 0.105191\n",
      "[14100]\ttraining's l1: 0.00319244\tvalid_1's l1: 0.105185\n",
      "[14200]\ttraining's l1: 0.00314951\tvalid_1's l1: 0.105184\n",
      "[14300]\ttraining's l1: 0.0031057\tvalid_1's l1: 0.105183\n",
      "[14400]\ttraining's l1: 0.00306412\tvalid_1's l1: 0.10518\n",
      "[14500]\ttraining's l1: 0.00302222\tvalid_1's l1: 0.105177\n",
      "[14600]\ttraining's l1: 0.00298791\tvalid_1's l1: 0.105176\n",
      "[14700]\ttraining's l1: 0.00295046\tvalid_1's l1: 0.105173\n",
      "[14800]\ttraining's l1: 0.00290852\tvalid_1's l1: 0.105168\n",
      "[14900]\ttraining's l1: 0.00287225\tvalid_1's l1: 0.105163\n",
      "[15000]\ttraining's l1: 0.00283435\tvalid_1's l1: 0.105159\n",
      "[15100]\ttraining's l1: 0.00279976\tvalid_1's l1: 0.105157\n",
      "Early stopping, best iteration is:\n",
      "[15094]\ttraining's l1: 0.0028018\tvalid_1's l1: 0.105156\n"
     ]
    }
   ],
   "source": [
    "in_taipei_valid_preds = []\n",
    "in_taipei_test_preds = []\n",
    "kf = KFold(n_splits=7, shuffle=False)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kf.split(in_taipei_X_train)):\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Fold {i+1}\")\n",
    "    print(\"-\" * 20)\n",
    "    train_data = lgb.Dataset(\n",
    "        in_taipei_X_train.iloc[train_index],\n",
    "        label=in_taipei_Y_train.iloc[train_index]\n",
    "    )\n",
    "    valid_data = lgb.Dataset(\n",
    "        in_taipei_X_train.iloc[val_index],\n",
    "        label=in_taipei_Y_train.iloc[val_index],\n",
    "        reference=train_data\n",
    "    )\n",
    "    model = lgb.train(\n",
    "        param_,\n",
    "        train_data,\n",
    "        3000000,\n",
    "        valid_sets=[train_data, valid_data],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    \n",
    "    # Predict valid\n",
    "    valid_pred = np.expand_dims(model.predict(in_taipei_X_train.iloc[val_index], num_iteration=model.best_iteration), -1)\n",
    "    valid_pred = y_scale.inverse_transform(valid_pred)\n",
    "    in_taipei_valid_preds.append(np.expm1(valid_pred))\n",
    "    # Predict test\n",
    "    pred = np.expand_dims(model.predict(in_taipei_X_test, num_iteration=model.best_iteration), -1)\n",
    "    pred = y_scale.inverse_transform(pred)\n",
    "    in_taipei_test_preds.append(np.expm1(pred))\n",
    "        \n",
    "    #Y_valid_predict = model.predict(in_taipei_X_train.iloc[val_index], num_iteration=model.best_iteration)\n",
    "    #Y_valid_predict = np.expm1(y_scale.inverse_transform(np.expand_dims(Y_valid_predict, -1)))\n",
    "    #Y_valid = np.expm1(y_scale.inverse_transform(in_taipei_Y_train.iloc[val_index]))\n",
    "    #metric(Y_valid, Y_valid_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_taipei_y_valid = np.squeeze(np.concatenate(in_taipei_valid_preds, axis=0)) * offset[train_greater_taipei_bool]\n",
    "in_taipei_y_test = np.squeeze(np.mean(in_taipei_test_preds, axis=0)) * test.loc[test_greater_taipei_bool, 'building_area'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**out taipei**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_taipei_X_train = X_train[~train_greater_taipei_bool.values]\n",
    "out_taipei_Y_train = Y_train[~train_greater_taipei_bool.values]\n",
    "\n",
    "out_taipei_X_test = X_test[~test_greater_taipei_bool.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Fold 1\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.311838\tvalid_1's l1: 0.330341\n",
      "[200]\ttraining's l1: 0.222975\tvalid_1's l1: 0.252175\n",
      "[300]\ttraining's l1: 0.178606\tvalid_1's l1: 0.217103\n",
      "[400]\ttraining's l1: 0.152508\tvalid_1's l1: 0.199671\n",
      "[500]\ttraining's l1: 0.134727\tvalid_1's l1: 0.189005\n",
      "[600]\ttraining's l1: 0.121343\tvalid_1's l1: 0.181868\n",
      "[700]\ttraining's l1: 0.111073\tvalid_1's l1: 0.177207\n",
      "[800]\ttraining's l1: 0.102623\tvalid_1's l1: 0.173716\n",
      "[900]\ttraining's l1: 0.0955819\tvalid_1's l1: 0.171159\n",
      "[1000]\ttraining's l1: 0.089402\tvalid_1's l1: 0.169095\n",
      "[1100]\ttraining's l1: 0.0838408\tvalid_1's l1: 0.167361\n",
      "[1200]\ttraining's l1: 0.0788819\tvalid_1's l1: 0.165916\n",
      "[1300]\ttraining's l1: 0.0745151\tvalid_1's l1: 0.164819\n",
      "[1400]\ttraining's l1: 0.0704019\tvalid_1's l1: 0.163795\n",
      "[1500]\ttraining's l1: 0.0668148\tvalid_1's l1: 0.162974\n",
      "[1600]\ttraining's l1: 0.0634802\tvalid_1's l1: 0.162198\n",
      "[1700]\ttraining's l1: 0.0604979\tvalid_1's l1: 0.161623\n",
      "[1800]\ttraining's l1: 0.0577796\tvalid_1's l1: 0.161104\n",
      "[1900]\ttraining's l1: 0.0552073\tvalid_1's l1: 0.160683\n",
      "[2000]\ttraining's l1: 0.0528154\tvalid_1's l1: 0.160215\n",
      "[2100]\ttraining's l1: 0.0505211\tvalid_1's l1: 0.159876\n",
      "[2200]\ttraining's l1: 0.0483987\tvalid_1's l1: 0.159523\n",
      "[2300]\ttraining's l1: 0.0463776\tvalid_1's l1: 0.159206\n",
      "[2400]\ttraining's l1: 0.0445222\tvalid_1's l1: 0.158935\n",
      "[2500]\ttraining's l1: 0.0427743\tvalid_1's l1: 0.158667\n",
      "[2600]\ttraining's l1: 0.0411472\tvalid_1's l1: 0.158441\n",
      "[2700]\ttraining's l1: 0.0396433\tvalid_1's l1: 0.158249\n",
      "[2800]\ttraining's l1: 0.0382275\tvalid_1's l1: 0.158088\n",
      "[2900]\ttraining's l1: 0.0368286\tvalid_1's l1: 0.15792\n",
      "[3000]\ttraining's l1: 0.0355612\tvalid_1's l1: 0.157757\n",
      "[3100]\ttraining's l1: 0.0343124\tvalid_1's l1: 0.157599\n",
      "[3200]\ttraining's l1: 0.0331606\tvalid_1's l1: 0.157457\n",
      "[3300]\ttraining's l1: 0.0320696\tvalid_1's l1: 0.157366\n",
      "[3400]\ttraining's l1: 0.0310332\tvalid_1's l1: 0.157253\n",
      "[3500]\ttraining's l1: 0.0300102\tvalid_1's l1: 0.157155\n",
      "[3600]\ttraining's l1: 0.0290407\tvalid_1's l1: 0.15707\n",
      "[3700]\ttraining's l1: 0.0281121\tvalid_1's l1: 0.156972\n",
      "[3800]\ttraining's l1: 0.0272333\tvalid_1's l1: 0.15687\n",
      "[3900]\ttraining's l1: 0.026389\tvalid_1's l1: 0.156785\n",
      "[4000]\ttraining's l1: 0.0255379\tvalid_1's l1: 0.156711\n",
      "[4100]\ttraining's l1: 0.02476\tvalid_1's l1: 0.156632\n",
      "[4200]\ttraining's l1: 0.0240109\tvalid_1's l1: 0.15657\n",
      "[4300]\ttraining's l1: 0.0232939\tvalid_1's l1: 0.156508\n",
      "[4400]\ttraining's l1: 0.0225943\tvalid_1's l1: 0.156445\n",
      "[4500]\ttraining's l1: 0.021929\tvalid_1's l1: 0.156394\n",
      "[4600]\ttraining's l1: 0.0212957\tvalid_1's l1: 0.156345\n",
      "[4700]\ttraining's l1: 0.0207094\tvalid_1's l1: 0.156288\n",
      "[4800]\ttraining's l1: 0.0201155\tvalid_1's l1: 0.156229\n",
      "[4900]\ttraining's l1: 0.0195596\tvalid_1's l1: 0.15618\n",
      "[5000]\ttraining's l1: 0.0190249\tvalid_1's l1: 0.156139\n",
      "[5100]\ttraining's l1: 0.0185164\tvalid_1's l1: 0.1561\n",
      "[5200]\ttraining's l1: 0.0180327\tvalid_1's l1: 0.156047\n",
      "[5300]\ttraining's l1: 0.0175506\tvalid_1's l1: 0.156006\n",
      "[5400]\ttraining's l1: 0.017076\tvalid_1's l1: 0.155974\n",
      "[5500]\ttraining's l1: 0.0166291\tvalid_1's l1: 0.155938\n",
      "[5600]\ttraining's l1: 0.0162075\tvalid_1's l1: 0.155894\n",
      "[5700]\ttraining's l1: 0.015799\tvalid_1's l1: 0.155858\n",
      "[5800]\ttraining's l1: 0.0153787\tvalid_1's l1: 0.15581\n",
      "[5900]\ttraining's l1: 0.0149806\tvalid_1's l1: 0.155784\n",
      "[6000]\ttraining's l1: 0.0146055\tvalid_1's l1: 0.15575\n",
      "[6100]\ttraining's l1: 0.0142414\tvalid_1's l1: 0.155719\n",
      "[6200]\ttraining's l1: 0.0138863\tvalid_1's l1: 0.155696\n",
      "[6300]\ttraining's l1: 0.0135384\tvalid_1's l1: 0.155668\n",
      "[6400]\ttraining's l1: 0.0132112\tvalid_1's l1: 0.155641\n",
      "[6500]\ttraining's l1: 0.0128752\tvalid_1's l1: 0.155616\n",
      "[6600]\ttraining's l1: 0.0125766\tvalid_1's l1: 0.155605\n",
      "[6700]\ttraining's l1: 0.012277\tvalid_1's l1: 0.155583\n",
      "[6800]\ttraining's l1: 0.0119845\tvalid_1's l1: 0.155566\n",
      "[6900]\ttraining's l1: 0.0117223\tvalid_1's l1: 0.155541\n",
      "[7000]\ttraining's l1: 0.0114424\tvalid_1's l1: 0.15552\n",
      "[7100]\ttraining's l1: 0.0111842\tvalid_1's l1: 0.155505\n",
      "[7200]\ttraining's l1: 0.010933\tvalid_1's l1: 0.155497\n",
      "[7300]\ttraining's l1: 0.0106815\tvalid_1's l1: 0.155479\n",
      "[7400]\ttraining's l1: 0.0104435\tvalid_1's l1: 0.155466\n",
      "[7500]\ttraining's l1: 0.0102125\tvalid_1's l1: 0.155447\n",
      "[7600]\ttraining's l1: 0.00998234\tvalid_1's l1: 0.15543\n",
      "[7700]\ttraining's l1: 0.00975937\tvalid_1's l1: 0.155412\n",
      "[7800]\ttraining's l1: 0.00954875\tvalid_1's l1: 0.155394\n",
      "[7900]\ttraining's l1: 0.00934278\tvalid_1's l1: 0.155377\n",
      "[8000]\ttraining's l1: 0.0091268\tvalid_1's l1: 0.155358\n",
      "[8100]\ttraining's l1: 0.0089198\tvalid_1's l1: 0.155343\n",
      "[8200]\ttraining's l1: 0.00873164\tvalid_1's l1: 0.155326\n",
      "[8300]\ttraining's l1: 0.00854672\tvalid_1's l1: 0.155315\n",
      "[8400]\ttraining's l1: 0.00836472\tvalid_1's l1: 0.155308\n",
      "[8500]\ttraining's l1: 0.00818772\tvalid_1's l1: 0.155297\n",
      "[8600]\ttraining's l1: 0.00801844\tvalid_1's l1: 0.155287\n",
      "[8700]\ttraining's l1: 0.00784757\tvalid_1's l1: 0.155275\n",
      "[8800]\ttraining's l1: 0.00769217\tvalid_1's l1: 0.15527\n",
      "[8900]\ttraining's l1: 0.00752636\tvalid_1's l1: 0.155256\n",
      "[9000]\ttraining's l1: 0.00736575\tvalid_1's l1: 0.155241\n",
      "[9100]\ttraining's l1: 0.00722702\tvalid_1's l1: 0.155232\n",
      "[9200]\ttraining's l1: 0.00708727\tvalid_1's l1: 0.155225\n",
      "[9300]\ttraining's l1: 0.00694948\tvalid_1's l1: 0.155215\n",
      "[9400]\ttraining's l1: 0.00681351\tvalid_1's l1: 0.155209\n",
      "[9500]\ttraining's l1: 0.00667885\tvalid_1's l1: 0.155197\n",
      "[9600]\ttraining's l1: 0.00655378\tvalid_1's l1: 0.15519\n",
      "[9700]\ttraining's l1: 0.00642493\tvalid_1's l1: 0.155179\n",
      "[9800]\ttraining's l1: 0.00630538\tvalid_1's l1: 0.155171\n",
      "[9900]\ttraining's l1: 0.00618657\tvalid_1's l1: 0.155161\n",
      "[10000]\ttraining's l1: 0.00607269\tvalid_1's l1: 0.155154\n",
      "[10100]\ttraining's l1: 0.00595596\tvalid_1's l1: 0.155147\n",
      "[10200]\ttraining's l1: 0.00585073\tvalid_1's l1: 0.155139\n",
      "[10300]\ttraining's l1: 0.00574009\tvalid_1's l1: 0.155133\n",
      "[10400]\ttraining's l1: 0.00563212\tvalid_1's l1: 0.155124\n",
      "[10500]\ttraining's l1: 0.00553033\tvalid_1's l1: 0.155116\n",
      "[10600]\ttraining's l1: 0.00543222\tvalid_1's l1: 0.155109\n",
      "[10700]\ttraining's l1: 0.00533681\tvalid_1's l1: 0.155099\n",
      "[10800]\ttraining's l1: 0.00523755\tvalid_1's l1: 0.155091\n",
      "[10900]\ttraining's l1: 0.00514319\tvalid_1's l1: 0.155083\n",
      "[11000]\ttraining's l1: 0.00505709\tvalid_1's l1: 0.155076\n",
      "[11100]\ttraining's l1: 0.00496683\tvalid_1's l1: 0.155068\n",
      "[11200]\ttraining's l1: 0.00488194\tvalid_1's l1: 0.155065\n",
      "[11300]\ttraining's l1: 0.0047983\tvalid_1's l1: 0.15506\n",
      "[11400]\ttraining's l1: 0.0047199\tvalid_1's l1: 0.155055\n",
      "[11500]\ttraining's l1: 0.00463865\tvalid_1's l1: 0.15505\n",
      "[11600]\ttraining's l1: 0.00456273\tvalid_1's l1: 0.155047\n",
      "[11700]\ttraining's l1: 0.00448661\tvalid_1's l1: 0.15504\n",
      "[11800]\ttraining's l1: 0.00441057\tvalid_1's l1: 0.155037\n",
      "[11900]\ttraining's l1: 0.00433882\tvalid_1's l1: 0.155033\n",
      "[12000]\ttraining's l1: 0.00427095\tvalid_1's l1: 0.155029\n",
      "[12100]\ttraining's l1: 0.00419924\tvalid_1's l1: 0.155028\n",
      "[12200]\ttraining's l1: 0.00413062\tvalid_1's l1: 0.155022\n",
      "[12300]\ttraining's l1: 0.00406267\tvalid_1's l1: 0.155015\n",
      "[12400]\ttraining's l1: 0.00399747\tvalid_1's l1: 0.15501\n",
      "[12500]\ttraining's l1: 0.00393714\tvalid_1's l1: 0.155005\n",
      "[12600]\ttraining's l1: 0.00387559\tvalid_1's l1: 0.155002\n",
      "[12700]\ttraining's l1: 0.00381444\tvalid_1's l1: 0.154996\n",
      "[12800]\ttraining's l1: 0.0037582\tvalid_1's l1: 0.154993\n",
      "[12900]\ttraining's l1: 0.00369936\tvalid_1's l1: 0.154989\n",
      "Early stopping, best iteration is:\n",
      "[12894]\ttraining's l1: 0.00370311\tvalid_1's l1: 0.154989\n",
      "--------------------\n",
      "Fold 2\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.31336\tvalid_1's l1: 0.323843\n",
      "[200]\ttraining's l1: 0.224129\tvalid_1's l1: 0.247129\n",
      "[300]\ttraining's l1: 0.179597\tvalid_1's l1: 0.212769\n",
      "[400]\ttraining's l1: 0.153478\tvalid_1's l1: 0.195012\n",
      "[500]\ttraining's l1: 0.135676\tvalid_1's l1: 0.184591\n",
      "[600]\ttraining's l1: 0.122308\tvalid_1's l1: 0.177762\n",
      "[700]\ttraining's l1: 0.112011\tvalid_1's l1: 0.173162\n",
      "[800]\ttraining's l1: 0.103515\tvalid_1's l1: 0.169611\n",
      "[900]\ttraining's l1: 0.0964103\tvalid_1's l1: 0.166865\n",
      "[1000]\ttraining's l1: 0.0902155\tvalid_1's l1: 0.164736\n",
      "[1100]\ttraining's l1: 0.0845805\tvalid_1's l1: 0.16299\n",
      "[1200]\ttraining's l1: 0.0795676\tvalid_1's l1: 0.161347\n",
      "[1300]\ttraining's l1: 0.0752394\tvalid_1's l1: 0.160058\n",
      "[1400]\ttraining's l1: 0.0711243\tvalid_1's l1: 0.158899\n",
      "[1500]\ttraining's l1: 0.0675279\tvalid_1's l1: 0.157961\n",
      "[1600]\ttraining's l1: 0.0641424\tvalid_1's l1: 0.157129\n",
      "[1700]\ttraining's l1: 0.0611702\tvalid_1's l1: 0.156411\n",
      "[1800]\ttraining's l1: 0.0583964\tvalid_1's l1: 0.155805\n",
      "[1900]\ttraining's l1: 0.055771\tvalid_1's l1: 0.155314\n",
      "[2000]\ttraining's l1: 0.0533199\tvalid_1's l1: 0.154823\n",
      "[2100]\ttraining's l1: 0.0510143\tvalid_1's l1: 0.154362\n",
      "[2200]\ttraining's l1: 0.0488599\tvalid_1's l1: 0.153985\n",
      "[2300]\ttraining's l1: 0.0468647\tvalid_1's l1: 0.153605\n",
      "[2400]\ttraining's l1: 0.0449665\tvalid_1's l1: 0.153296\n",
      "[2500]\ttraining's l1: 0.0432113\tvalid_1's l1: 0.153013\n",
      "[2600]\ttraining's l1: 0.0415528\tvalid_1's l1: 0.152779\n",
      "[2700]\ttraining's l1: 0.0400296\tvalid_1's l1: 0.152535\n",
      "[2800]\ttraining's l1: 0.03858\tvalid_1's l1: 0.152322\n",
      "[2900]\ttraining's l1: 0.0371655\tvalid_1's l1: 0.152162\n",
      "[3000]\ttraining's l1: 0.0358609\tvalid_1's l1: 0.151983\n",
      "[3100]\ttraining's l1: 0.0345865\tvalid_1's l1: 0.151805\n",
      "[3200]\ttraining's l1: 0.0333963\tvalid_1's l1: 0.151659\n",
      "[3300]\ttraining's l1: 0.0322699\tvalid_1's l1: 0.151497\n",
      "[3400]\ttraining's l1: 0.0312356\tvalid_1's l1: 0.15134\n",
      "[3500]\ttraining's l1: 0.0302285\tvalid_1's l1: 0.151228\n",
      "[3600]\ttraining's l1: 0.0292518\tvalid_1's l1: 0.151121\n",
      "[3700]\ttraining's l1: 0.0283051\tvalid_1's l1: 0.151004\n",
      "[3800]\ttraining's l1: 0.0274155\tvalid_1's l1: 0.150893\n",
      "[3900]\ttraining's l1: 0.0265308\tvalid_1's l1: 0.150773\n",
      "[4000]\ttraining's l1: 0.0256898\tvalid_1's l1: 0.150688\n",
      "[4100]\ttraining's l1: 0.0249007\tvalid_1's l1: 0.150607\n",
      "[4200]\ttraining's l1: 0.0241622\tvalid_1's l1: 0.150521\n",
      "[4300]\ttraining's l1: 0.0234364\tvalid_1's l1: 0.150427\n",
      "[4400]\ttraining's l1: 0.0227252\tvalid_1's l1: 0.150349\n",
      "[4500]\ttraining's l1: 0.0220426\tvalid_1's l1: 0.15028\n",
      "[4600]\ttraining's l1: 0.0214103\tvalid_1's l1: 0.150217\n",
      "[4700]\ttraining's l1: 0.0208099\tvalid_1's l1: 0.15013\n",
      "[4800]\ttraining's l1: 0.0201986\tvalid_1's l1: 0.150063\n",
      "[4900]\ttraining's l1: 0.0196271\tvalid_1's l1: 0.150009\n",
      "[5000]\ttraining's l1: 0.0190787\tvalid_1's l1: 0.149952\n",
      "[5100]\ttraining's l1: 0.0185674\tvalid_1's l1: 0.149887\n",
      "[5200]\ttraining's l1: 0.0180691\tvalid_1's l1: 0.14984\n",
      "[5300]\ttraining's l1: 0.0175831\tvalid_1's l1: 0.149797\n",
      "[5400]\ttraining's l1: 0.017111\tvalid_1's l1: 0.149754\n",
      "[5500]\ttraining's l1: 0.0166625\tvalid_1's l1: 0.149716\n",
      "[5600]\ttraining's l1: 0.0162435\tvalid_1's l1: 0.149692\n",
      "[5700]\ttraining's l1: 0.0158362\tvalid_1's l1: 0.14965\n",
      "[5800]\ttraining's l1: 0.0154163\tvalid_1's l1: 0.149614\n",
      "[5900]\ttraining's l1: 0.0150221\tvalid_1's l1: 0.149578\n",
      "[6000]\ttraining's l1: 0.0146461\tvalid_1's l1: 0.149552\n",
      "[6100]\ttraining's l1: 0.0142787\tvalid_1's l1: 0.149524\n",
      "[6200]\ttraining's l1: 0.0139174\tvalid_1's l1: 0.149495\n",
      "[6300]\ttraining's l1: 0.0135685\tvalid_1's l1: 0.149464\n",
      "[6400]\ttraining's l1: 0.0132383\tvalid_1's l1: 0.14944\n",
      "[6500]\ttraining's l1: 0.0128978\tvalid_1's l1: 0.149421\n",
      "[6600]\ttraining's l1: 0.0125898\tvalid_1's l1: 0.149396\n",
      "[6700]\ttraining's l1: 0.0122859\tvalid_1's l1: 0.149376\n",
      "[6800]\ttraining's l1: 0.0119923\tvalid_1's l1: 0.149349\n",
      "[6900]\ttraining's l1: 0.0117294\tvalid_1's l1: 0.149325\n",
      "[7000]\ttraining's l1: 0.0114434\tvalid_1's l1: 0.149301\n",
      "[7100]\ttraining's l1: 0.011184\tvalid_1's l1: 0.149277\n",
      "[7200]\ttraining's l1: 0.0109318\tvalid_1's l1: 0.149267\n",
      "[7300]\ttraining's l1: 0.0106787\tvalid_1's l1: 0.14926\n",
      "[7400]\ttraining's l1: 0.0104353\tvalid_1's l1: 0.14925\n",
      "[7500]\ttraining's l1: 0.0102002\tvalid_1's l1: 0.149232\n",
      "[7600]\ttraining's l1: 0.00996736\tvalid_1's l1: 0.149215\n",
      "[7700]\ttraining's l1: 0.00973546\tvalid_1's l1: 0.149203\n",
      "[7800]\ttraining's l1: 0.00952384\tvalid_1's l1: 0.149185\n",
      "[7900]\ttraining's l1: 0.00931494\tvalid_1's l1: 0.149171\n",
      "[8000]\ttraining's l1: 0.00909758\tvalid_1's l1: 0.14916\n",
      "[8100]\ttraining's l1: 0.00889766\tvalid_1's l1: 0.149146\n",
      "[8200]\ttraining's l1: 0.00871125\tvalid_1's l1: 0.149135\n",
      "[8300]\ttraining's l1: 0.00852134\tvalid_1's l1: 0.149127\n",
      "[8400]\ttraining's l1: 0.00834123\tvalid_1's l1: 0.149115\n",
      "[8500]\ttraining's l1: 0.00816469\tvalid_1's l1: 0.149105\n",
      "[8600]\ttraining's l1: 0.00799577\tvalid_1's l1: 0.149098\n",
      "[8700]\ttraining's l1: 0.00782585\tvalid_1's l1: 0.14909\n",
      "[8800]\ttraining's l1: 0.00766811\tvalid_1's l1: 0.149077\n",
      "[8900]\ttraining's l1: 0.00750254\tvalid_1's l1: 0.149064\n",
      "[9000]\ttraining's l1: 0.00734447\tvalid_1's l1: 0.149052\n",
      "[9100]\ttraining's l1: 0.00720686\tvalid_1's l1: 0.149043\n",
      "[9200]\ttraining's l1: 0.007064\tvalid_1's l1: 0.149032\n",
      "[9300]\ttraining's l1: 0.00692419\tvalid_1's l1: 0.149021\n",
      "[9400]\ttraining's l1: 0.00678794\tvalid_1's l1: 0.149012\n",
      "[9500]\ttraining's l1: 0.00665147\tvalid_1's l1: 0.149\n",
      "[9600]\ttraining's l1: 0.00652415\tvalid_1's l1: 0.148991\n",
      "[9700]\ttraining's l1: 0.00639701\tvalid_1's l1: 0.148984\n",
      "[9800]\ttraining's l1: 0.00627639\tvalid_1's l1: 0.148976\n",
      "[9900]\ttraining's l1: 0.00615768\tvalid_1's l1: 0.148968\n",
      "[10000]\ttraining's l1: 0.0060431\tvalid_1's l1: 0.148964\n",
      "Early stopping, best iteration is:\n",
      "[9965]\ttraining's l1: 0.00608328\tvalid_1's l1: 0.148963\n",
      "--------------------\n",
      "Fold 3\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.314478\tvalid_1's l1: 0.325789\n",
      "[200]\ttraining's l1: 0.220062\tvalid_1's l1: 0.245153\n",
      "[300]\ttraining's l1: 0.17561\tvalid_1's l1: 0.211647\n",
      "[400]\ttraining's l1: 0.150553\tvalid_1's l1: 0.194431\n",
      "[500]\ttraining's l1: 0.133311\tvalid_1's l1: 0.183951\n",
      "[600]\ttraining's l1: 0.12089\tvalid_1's l1: 0.177627\n",
      "[700]\ttraining's l1: 0.110825\tvalid_1's l1: 0.172818\n",
      "[800]\ttraining's l1: 0.102627\tvalid_1's l1: 0.169206\n",
      "[900]\ttraining's l1: 0.0955123\tvalid_1's l1: 0.166344\n",
      "[1000]\ttraining's l1: 0.0893326\tvalid_1's l1: 0.164154\n",
      "[1100]\ttraining's l1: 0.083949\tvalid_1's l1: 0.162475\n",
      "[1200]\ttraining's l1: 0.0792294\tvalid_1's l1: 0.161101\n",
      "[1300]\ttraining's l1: 0.0749022\tvalid_1's l1: 0.159899\n",
      "[1400]\ttraining's l1: 0.0710191\tvalid_1's l1: 0.158845\n",
      "[1500]\ttraining's l1: 0.0674263\tvalid_1's l1: 0.157991\n",
      "[1600]\ttraining's l1: 0.0641703\tvalid_1's l1: 0.157262\n",
      "[1700]\ttraining's l1: 0.061131\tvalid_1's l1: 0.156567\n",
      "[1800]\ttraining's l1: 0.0583635\tvalid_1's l1: 0.155966\n",
      "[1900]\ttraining's l1: 0.0557504\tvalid_1's l1: 0.155517\n",
      "[2000]\ttraining's l1: 0.0532824\tvalid_1's l1: 0.155107\n",
      "[2100]\ttraining's l1: 0.0510557\tvalid_1's l1: 0.154762\n",
      "[2200]\ttraining's l1: 0.0489631\tvalid_1's l1: 0.154411\n",
      "[2300]\ttraining's l1: 0.0470135\tvalid_1's l1: 0.154134\n",
      "[2400]\ttraining's l1: 0.0452113\tvalid_1's l1: 0.153863\n",
      "[2500]\ttraining's l1: 0.0434571\tvalid_1's l1: 0.15359\n",
      "[2600]\ttraining's l1: 0.0418585\tvalid_1's l1: 0.153328\n",
      "[2700]\ttraining's l1: 0.0403111\tvalid_1's l1: 0.153113\n",
      "[2800]\ttraining's l1: 0.0388435\tvalid_1's l1: 0.152889\n",
      "[2900]\ttraining's l1: 0.0374441\tvalid_1's l1: 0.152699\n",
      "[3000]\ttraining's l1: 0.0361522\tvalid_1's l1: 0.152526\n",
      "[3100]\ttraining's l1: 0.0349023\tvalid_1's l1: 0.152376\n",
      "[3200]\ttraining's l1: 0.0337446\tvalid_1's l1: 0.152212\n",
      "[3300]\ttraining's l1: 0.0326216\tvalid_1's l1: 0.152072\n",
      "[3400]\ttraining's l1: 0.0315599\tvalid_1's l1: 0.151936\n",
      "[3500]\ttraining's l1: 0.0305414\tvalid_1's l1: 0.151824\n",
      "[3600]\ttraining's l1: 0.0295699\tvalid_1's l1: 0.151703\n",
      "[3700]\ttraining's l1: 0.0286627\tvalid_1's l1: 0.151601\n",
      "[3800]\ttraining's l1: 0.0277631\tvalid_1's l1: 0.151493\n",
      "[3900]\ttraining's l1: 0.02692\tvalid_1's l1: 0.151405\n",
      "[4000]\ttraining's l1: 0.0261015\tvalid_1's l1: 0.151316\n",
      "[4100]\ttraining's l1: 0.0253338\tvalid_1's l1: 0.151246\n",
      "[4200]\ttraining's l1: 0.024595\tvalid_1's l1: 0.151152\n",
      "[4300]\ttraining's l1: 0.0238678\tvalid_1's l1: 0.15107\n",
      "[4400]\ttraining's l1: 0.0231951\tvalid_1's l1: 0.150985\n",
      "[4500]\ttraining's l1: 0.0225287\tvalid_1's l1: 0.150924\n",
      "[4600]\ttraining's l1: 0.0218918\tvalid_1's l1: 0.150883\n",
      "[4700]\ttraining's l1: 0.0212629\tvalid_1's l1: 0.150831\n",
      "[4800]\ttraining's l1: 0.0206764\tvalid_1's l1: 0.150772\n",
      "[4900]\ttraining's l1: 0.0201006\tvalid_1's l1: 0.150728\n",
      "[5000]\ttraining's l1: 0.0195374\tvalid_1's l1: 0.150679\n",
      "[5100]\ttraining's l1: 0.0190196\tvalid_1's l1: 0.150636\n",
      "[5200]\ttraining's l1: 0.0185052\tvalid_1's l1: 0.150606\n",
      "[5300]\ttraining's l1: 0.0180019\tvalid_1's l1: 0.150571\n",
      "[5400]\ttraining's l1: 0.0175311\tvalid_1's l1: 0.15053\n",
      "[5500]\ttraining's l1: 0.0170719\tvalid_1's l1: 0.150487\n",
      "[5600]\ttraining's l1: 0.0166269\tvalid_1's l1: 0.150444\n",
      "[5700]\ttraining's l1: 0.0161943\tvalid_1's l1: 0.150414\n",
      "[5800]\ttraining's l1: 0.0157719\tvalid_1's l1: 0.150374\n",
      "[5900]\ttraining's l1: 0.0153854\tvalid_1's l1: 0.150338\n",
      "[6000]\ttraining's l1: 0.0150047\tvalid_1's l1: 0.150295\n",
      "[6100]\ttraining's l1: 0.0146289\tvalid_1's l1: 0.150259\n",
      "[6200]\ttraining's l1: 0.0142598\tvalid_1's l1: 0.150223\n",
      "[6300]\ttraining's l1: 0.0138999\tvalid_1's l1: 0.150202\n",
      "[6400]\ttraining's l1: 0.0135614\tvalid_1's l1: 0.150166\n",
      "[6500]\ttraining's l1: 0.0132328\tvalid_1's l1: 0.150129\n",
      "[6600]\ttraining's l1: 0.0129097\tvalid_1's l1: 0.150109\n",
      "[6700]\ttraining's l1: 0.0126101\tvalid_1's l1: 0.15009\n",
      "[6800]\ttraining's l1: 0.0123047\tvalid_1's l1: 0.150064\n",
      "[6900]\ttraining's l1: 0.0120278\tvalid_1's l1: 0.150031\n",
      "[7000]\ttraining's l1: 0.0117551\tvalid_1's l1: 0.150005\n",
      "[7100]\ttraining's l1: 0.0114617\tvalid_1's l1: 0.149986\n",
      "[7200]\ttraining's l1: 0.0112067\tvalid_1's l1: 0.149968\n",
      "[7300]\ttraining's l1: 0.0109516\tvalid_1's l1: 0.149947\n",
      "[7400]\ttraining's l1: 0.0107005\tvalid_1's l1: 0.149932\n",
      "[7500]\ttraining's l1: 0.0104611\tvalid_1's l1: 0.149911\n",
      "[7600]\ttraining's l1: 0.0102258\tvalid_1's l1: 0.149893\n",
      "[7700]\ttraining's l1: 0.00999951\tvalid_1's l1: 0.14988\n",
      "[7800]\ttraining's l1: 0.00977415\tvalid_1's l1: 0.149865\n",
      "[7900]\ttraining's l1: 0.00955584\tvalid_1's l1: 0.149847\n",
      "[8000]\ttraining's l1: 0.00935469\tvalid_1's l1: 0.149834\n",
      "[8100]\ttraining's l1: 0.00916274\tvalid_1's l1: 0.149821\n",
      "[8200]\ttraining's l1: 0.00897375\tvalid_1's l1: 0.149804\n",
      "[8300]\ttraining's l1: 0.00879449\tvalid_1's l1: 0.149789\n",
      "[8400]\ttraining's l1: 0.00860418\tvalid_1's l1: 0.149773\n",
      "[8500]\ttraining's l1: 0.00843115\tvalid_1's l1: 0.149757\n",
      "[8600]\ttraining's l1: 0.00826197\tvalid_1's l1: 0.149742\n",
      "[8700]\ttraining's l1: 0.00808285\tvalid_1's l1: 0.14973\n",
      "[8800]\ttraining's l1: 0.00792401\tvalid_1's l1: 0.149715\n",
      "[8900]\ttraining's l1: 0.00776532\tvalid_1's l1: 0.149707\n",
      "[9000]\ttraining's l1: 0.00760887\tvalid_1's l1: 0.149689\n",
      "[9100]\ttraining's l1: 0.00746131\tvalid_1's l1: 0.149676\n",
      "[9200]\ttraining's l1: 0.00731364\tvalid_1's l1: 0.149664\n",
      "[9300]\ttraining's l1: 0.00717435\tvalid_1's l1: 0.149651\n",
      "[9400]\ttraining's l1: 0.00703726\tvalid_1's l1: 0.149639\n",
      "[9500]\ttraining's l1: 0.00689867\tvalid_1's l1: 0.149635\n",
      "[9600]\ttraining's l1: 0.00675859\tvalid_1's l1: 0.149623\n",
      "[9700]\ttraining's l1: 0.00663154\tvalid_1's l1: 0.149613\n",
      "[9800]\ttraining's l1: 0.00649983\tvalid_1's l1: 0.149605\n",
      "[9900]\ttraining's l1: 0.00638315\tvalid_1's l1: 0.149594\n",
      "[10000]\ttraining's l1: 0.00625977\tvalid_1's l1: 0.149583\n",
      "[10100]\ttraining's l1: 0.00615158\tvalid_1's l1: 0.149575\n",
      "[10200]\ttraining's l1: 0.00604408\tvalid_1's l1: 0.149572\n",
      "[10300]\ttraining's l1: 0.00593693\tvalid_1's l1: 0.149563\n",
      "[10400]\ttraining's l1: 0.00582844\tvalid_1's l1: 0.149556\n",
      "[10500]\ttraining's l1: 0.0057248\tvalid_1's l1: 0.149549\n",
      "[10600]\ttraining's l1: 0.00562628\tvalid_1's l1: 0.149542\n",
      "[10700]\ttraining's l1: 0.00552619\tvalid_1's l1: 0.149535\n",
      "[10800]\ttraining's l1: 0.00543221\tvalid_1's l1: 0.149522\n",
      "[10900]\ttraining's l1: 0.00533979\tvalid_1's l1: 0.149514\n",
      "[11000]\ttraining's l1: 0.00524799\tvalid_1's l1: 0.149503\n",
      "[11100]\ttraining's l1: 0.00515663\tvalid_1's l1: 0.149499\n",
      "[11200]\ttraining's l1: 0.00506387\tvalid_1's l1: 0.14949\n",
      "[11300]\ttraining's l1: 0.00497986\tvalid_1's l1: 0.14948\n",
      "[11400]\ttraining's l1: 0.00489803\tvalid_1's l1: 0.149471\n",
      "[11500]\ttraining's l1: 0.00481931\tvalid_1's l1: 0.149461\n",
      "[11600]\ttraining's l1: 0.00474055\tvalid_1's l1: 0.149454\n",
      "[11700]\ttraining's l1: 0.00465818\tvalid_1's l1: 0.149444\n",
      "[11800]\ttraining's l1: 0.00458355\tvalid_1's l1: 0.149437\n",
      "[11900]\ttraining's l1: 0.00450578\tvalid_1's l1: 0.14943\n",
      "[12000]\ttraining's l1: 0.00443025\tvalid_1's l1: 0.149427\n",
      "[12100]\ttraining's l1: 0.00435918\tvalid_1's l1: 0.149421\n",
      "[12200]\ttraining's l1: 0.00429156\tvalid_1's l1: 0.149416\n",
      "[12300]\ttraining's l1: 0.00422092\tvalid_1's l1: 0.14941\n",
      "[12400]\ttraining's l1: 0.00415355\tvalid_1's l1: 0.149408\n",
      "[12500]\ttraining's l1: 0.00408886\tvalid_1's l1: 0.149402\n",
      "[12600]\ttraining's l1: 0.00402594\tvalid_1's l1: 0.149397\n",
      "[12700]\ttraining's l1: 0.00396247\tvalid_1's l1: 0.14939\n",
      "[12800]\ttraining's l1: 0.00390104\tvalid_1's l1: 0.149385\n",
      "[12900]\ttraining's l1: 0.00384188\tvalid_1's l1: 0.14938\n",
      "[13000]\ttraining's l1: 0.00378093\tvalid_1's l1: 0.149374\n",
      "[13100]\ttraining's l1: 0.0037259\tvalid_1's l1: 0.149371\n",
      "[13200]\ttraining's l1: 0.00366955\tvalid_1's l1: 0.149367\n",
      "[13300]\ttraining's l1: 0.00361728\tvalid_1's l1: 0.149362\n",
      "[13400]\ttraining's l1: 0.00356628\tvalid_1's l1: 0.149359\n",
      "[13500]\ttraining's l1: 0.00351431\tvalid_1's l1: 0.149354\n",
      "[13600]\ttraining's l1: 0.00346243\tvalid_1's l1: 0.149349\n",
      "[13700]\ttraining's l1: 0.00340922\tvalid_1's l1: 0.149343\n",
      "[13800]\ttraining's l1: 0.00336079\tvalid_1's l1: 0.149342\n",
      "[13900]\ttraining's l1: 0.00331044\tvalid_1's l1: 0.149338\n",
      "[14000]\ttraining's l1: 0.00326376\tvalid_1's l1: 0.149335\n",
      "[14100]\ttraining's l1: 0.00321613\tvalid_1's l1: 0.149333\n",
      "[14200]\ttraining's l1: 0.00317094\tvalid_1's l1: 0.149329\n",
      "[14300]\ttraining's l1: 0.00312507\tvalid_1's l1: 0.149327\n",
      "[14400]\ttraining's l1: 0.0030805\tvalid_1's l1: 0.149322\n",
      "[14500]\ttraining's l1: 0.00303888\tvalid_1's l1: 0.149318\n",
      "[14600]\ttraining's l1: 0.00299717\tvalid_1's l1: 0.149315\n",
      "[14700]\ttraining's l1: 0.00295608\tvalid_1's l1: 0.149312\n",
      "[14800]\ttraining's l1: 0.00291551\tvalid_1's l1: 0.14931\n",
      "[14900]\ttraining's l1: 0.00287708\tvalid_1's l1: 0.149307\n",
      "[15000]\ttraining's l1: 0.00283557\tvalid_1's l1: 0.149306\n",
      "[15100]\ttraining's l1: 0.00279723\tvalid_1's l1: 0.149304\n",
      "[15200]\ttraining's l1: 0.00275758\tvalid_1's l1: 0.1493\n",
      "[15300]\ttraining's l1: 0.00272085\tvalid_1's l1: 0.149296\n",
      "[15400]\ttraining's l1: 0.00268395\tvalid_1's l1: 0.149294\n",
      "[15500]\ttraining's l1: 0.00264943\tvalid_1's l1: 0.14929\n",
      "[15600]\ttraining's l1: 0.0026138\tvalid_1's l1: 0.149287\n",
      "[15700]\ttraining's l1: 0.00257637\tvalid_1's l1: 0.149284\n",
      "[15800]\ttraining's l1: 0.0025419\tvalid_1's l1: 0.14928\n",
      "[15900]\ttraining's l1: 0.00250654\tvalid_1's l1: 0.149277\n",
      "[16000]\ttraining's l1: 0.00247148\tvalid_1's l1: 0.149271\n",
      "[16100]\ttraining's l1: 0.00243824\tvalid_1's l1: 0.149268\n",
      "[16200]\ttraining's l1: 0.00240841\tvalid_1's l1: 0.149268\n",
      "[16300]\ttraining's l1: 0.00237808\tvalid_1's l1: 0.149267\n",
      "[16400]\ttraining's l1: 0.00234784\tvalid_1's l1: 0.149263\n",
      "[16500]\ttraining's l1: 0.00231728\tvalid_1's l1: 0.149259\n",
      "[16600]\ttraining's l1: 0.00228838\tvalid_1's l1: 0.149258\n",
      "[16700]\ttraining's l1: 0.00225634\tvalid_1's l1: 0.149256\n",
      "[16800]\ttraining's l1: 0.0022256\tvalid_1's l1: 0.149254\n",
      "[16900]\ttraining's l1: 0.00219545\tvalid_1's l1: 0.149254\n",
      "[17000]\ttraining's l1: 0.00216673\tvalid_1's l1: 0.149251\n",
      "[17100]\ttraining's l1: 0.00214189\tvalid_1's l1: 0.149247\n",
      "[17200]\ttraining's l1: 0.00211614\tvalid_1's l1: 0.149244\n",
      "[17300]\ttraining's l1: 0.00208992\tvalid_1's l1: 0.149245\n",
      "[17400]\ttraining's l1: 0.00206263\tvalid_1's l1: 0.149244\n",
      "[17500]\ttraining's l1: 0.00203735\tvalid_1's l1: 0.149241\n",
      "[17600]\ttraining's l1: 0.0020129\tvalid_1's l1: 0.149239\n",
      "[17700]\ttraining's l1: 0.00198821\tvalid_1's l1: 0.149237\n",
      "[17800]\ttraining's l1: 0.00196515\tvalid_1's l1: 0.149234\n",
      "[17900]\ttraining's l1: 0.00194173\tvalid_1's l1: 0.149233\n",
      "[18000]\ttraining's l1: 0.00191718\tvalid_1's l1: 0.149232\n",
      "[18100]\ttraining's l1: 0.00189365\tvalid_1's l1: 0.149231\n",
      "[18200]\ttraining's l1: 0.00186993\tvalid_1's l1: 0.149228\n",
      "[18300]\ttraining's l1: 0.0018456\tvalid_1's l1: 0.149224\n",
      "[18400]\ttraining's l1: 0.0018245\tvalid_1's l1: 0.149224\n",
      "[18500]\ttraining's l1: 0.00180275\tvalid_1's l1: 0.149221\n",
      "[18600]\ttraining's l1: 0.00178192\tvalid_1's l1: 0.149221\n",
      "[18700]\ttraining's l1: 0.00176168\tvalid_1's l1: 0.149219\n",
      "Early stopping, best iteration is:\n",
      "[18689]\ttraining's l1: 0.00176364\tvalid_1's l1: 0.149218\n",
      "--------------------\n",
      "Fold 4\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.315203\tvalid_1's l1: 0.323432\n",
      "[200]\ttraining's l1: 0.220509\tvalid_1's l1: 0.243274\n",
      "[300]\ttraining's l1: 0.175982\tvalid_1's l1: 0.209917\n",
      "[400]\ttraining's l1: 0.150797\tvalid_1's l1: 0.193409\n",
      "[500]\ttraining's l1: 0.133385\tvalid_1's l1: 0.182887\n",
      "[600]\ttraining's l1: 0.120931\tvalid_1's l1: 0.176314\n",
      "[700]\ttraining's l1: 0.110892\tvalid_1's l1: 0.171611\n",
      "[800]\ttraining's l1: 0.102596\tvalid_1's l1: 0.167943\n",
      "[900]\ttraining's l1: 0.0954719\tvalid_1's l1: 0.16514\n",
      "[1000]\ttraining's l1: 0.089271\tvalid_1's l1: 0.162866\n",
      "[1100]\ttraining's l1: 0.0839182\tvalid_1's l1: 0.161055\n",
      "[1200]\ttraining's l1: 0.0791985\tvalid_1's l1: 0.15955\n",
      "[1300]\ttraining's l1: 0.0748808\tvalid_1's l1: 0.158277\n",
      "[1400]\ttraining's l1: 0.0710126\tvalid_1's l1: 0.157233\n",
      "[1500]\ttraining's l1: 0.0674269\tvalid_1's l1: 0.15626\n",
      "[1600]\ttraining's l1: 0.0641384\tvalid_1's l1: 0.155473\n",
      "[1700]\ttraining's l1: 0.0611618\tvalid_1's l1: 0.154778\n",
      "[1800]\ttraining's l1: 0.0583973\tvalid_1's l1: 0.154194\n",
      "[1900]\ttraining's l1: 0.0557695\tvalid_1's l1: 0.153613\n",
      "[2000]\ttraining's l1: 0.0533206\tvalid_1's l1: 0.153127\n",
      "[2100]\ttraining's l1: 0.051129\tvalid_1's l1: 0.15267\n",
      "[2200]\ttraining's l1: 0.0490141\tvalid_1's l1: 0.152245\n",
      "[2300]\ttraining's l1: 0.0470356\tvalid_1's l1: 0.151871\n",
      "[2400]\ttraining's l1: 0.0452266\tvalid_1's l1: 0.151502\n",
      "[2500]\ttraining's l1: 0.0434462\tvalid_1's l1: 0.151147\n",
      "[2600]\ttraining's l1: 0.0418255\tvalid_1's l1: 0.150871\n",
      "[2700]\ttraining's l1: 0.0402809\tvalid_1's l1: 0.150612\n",
      "[2800]\ttraining's l1: 0.0388063\tvalid_1's l1: 0.150369\n",
      "[2900]\ttraining's l1: 0.0374171\tvalid_1's l1: 0.150158\n",
      "[3000]\ttraining's l1: 0.0361185\tvalid_1's l1: 0.149926\n",
      "[3100]\ttraining's l1: 0.0348599\tvalid_1's l1: 0.149709\n",
      "[3200]\ttraining's l1: 0.0336873\tvalid_1's l1: 0.149526\n",
      "[3300]\ttraining's l1: 0.0325876\tvalid_1's l1: 0.149337\n",
      "[3400]\ttraining's l1: 0.0315071\tvalid_1's l1: 0.149163\n",
      "[3500]\ttraining's l1: 0.0304596\tvalid_1's l1: 0.149018\n",
      "[3600]\ttraining's l1: 0.0294945\tvalid_1's l1: 0.148895\n",
      "[3700]\ttraining's l1: 0.0285831\tvalid_1's l1: 0.148779\n",
      "[3800]\ttraining's l1: 0.0276752\tvalid_1's l1: 0.148661\n",
      "[3900]\ttraining's l1: 0.0268132\tvalid_1's l1: 0.148552\n",
      "[4000]\ttraining's l1: 0.026013\tvalid_1's l1: 0.148436\n",
      "[4100]\ttraining's l1: 0.0252307\tvalid_1's l1: 0.148327\n",
      "[4200]\ttraining's l1: 0.0245005\tvalid_1's l1: 0.14824\n",
      "[4300]\ttraining's l1: 0.0237705\tvalid_1's l1: 0.148148\n",
      "[4400]\ttraining's l1: 0.0231058\tvalid_1's l1: 0.148086\n",
      "[4500]\ttraining's l1: 0.0224174\tvalid_1's l1: 0.147995\n",
      "[4600]\ttraining's l1: 0.0217791\tvalid_1's l1: 0.147929\n",
      "[4700]\ttraining's l1: 0.0211418\tvalid_1's l1: 0.147867\n",
      "[4800]\ttraining's l1: 0.0205462\tvalid_1's l1: 0.147807\n",
      "[4900]\ttraining's l1: 0.0199604\tvalid_1's l1: 0.147751\n",
      "[5000]\ttraining's l1: 0.0193918\tvalid_1's l1: 0.14768\n",
      "[5100]\ttraining's l1: 0.0188748\tvalid_1's l1: 0.147631\n",
      "[5200]\ttraining's l1: 0.0183596\tvalid_1's l1: 0.147577\n",
      "[5300]\ttraining's l1: 0.0178548\tvalid_1's l1: 0.147533\n",
      "[5400]\ttraining's l1: 0.0173761\tvalid_1's l1: 0.147486\n",
      "[5500]\ttraining's l1: 0.0169258\tvalid_1's l1: 0.147441\n",
      "[5600]\ttraining's l1: 0.0164852\tvalid_1's l1: 0.147406\n",
      "[5700]\ttraining's l1: 0.0160497\tvalid_1's l1: 0.147357\n",
      "[5800]\ttraining's l1: 0.0156249\tvalid_1's l1: 0.147317\n",
      "[5900]\ttraining's l1: 0.015232\tvalid_1's l1: 0.147275\n",
      "[6000]\ttraining's l1: 0.014843\tvalid_1's l1: 0.147241\n",
      "[6100]\ttraining's l1: 0.0144696\tvalid_1's l1: 0.147211\n",
      "[6200]\ttraining's l1: 0.014105\tvalid_1's l1: 0.147179\n",
      "[6300]\ttraining's l1: 0.0137472\tvalid_1's l1: 0.147147\n",
      "[6400]\ttraining's l1: 0.0134031\tvalid_1's l1: 0.147125\n",
      "[6500]\ttraining's l1: 0.0130749\tvalid_1's l1: 0.147092\n",
      "[6600]\ttraining's l1: 0.0127495\tvalid_1's l1: 0.147065\n",
      "[6700]\ttraining's l1: 0.0124526\tvalid_1's l1: 0.147048\n",
      "[6800]\ttraining's l1: 0.012145\tvalid_1's l1: 0.147018\n",
      "[6900]\ttraining's l1: 0.0118714\tvalid_1's l1: 0.146998\n",
      "[7000]\ttraining's l1: 0.0116019\tvalid_1's l1: 0.146977\n",
      "[7100]\ttraining's l1: 0.0113204\tvalid_1's l1: 0.146957\n",
      "[7200]\ttraining's l1: 0.0110699\tvalid_1's l1: 0.146933\n",
      "[7300]\ttraining's l1: 0.0108129\tvalid_1's l1: 0.146916\n",
      "[7400]\ttraining's l1: 0.0105605\tvalid_1's l1: 0.146897\n",
      "[7500]\ttraining's l1: 0.0103161\tvalid_1's l1: 0.146879\n",
      "[7600]\ttraining's l1: 0.0100865\tvalid_1's l1: 0.146851\n",
      "[7700]\ttraining's l1: 0.00985438\tvalid_1's l1: 0.14683\n",
      "[7800]\ttraining's l1: 0.00962845\tvalid_1's l1: 0.146811\n",
      "[7900]\ttraining's l1: 0.00941489\tvalid_1's l1: 0.146798\n",
      "[8000]\ttraining's l1: 0.0092143\tvalid_1's l1: 0.146782\n",
      "[8100]\ttraining's l1: 0.00902243\tvalid_1's l1: 0.14677\n",
      "[8200]\ttraining's l1: 0.00883778\tvalid_1's l1: 0.146767\n",
      "[8300]\ttraining's l1: 0.00866066\tvalid_1's l1: 0.146755\n",
      "[8400]\ttraining's l1: 0.00847878\tvalid_1's l1: 0.146739\n",
      "[8500]\ttraining's l1: 0.00830741\tvalid_1's l1: 0.146724\n",
      "[8600]\ttraining's l1: 0.00813673\tvalid_1's l1: 0.146717\n",
      "[8700]\ttraining's l1: 0.00795951\tvalid_1's l1: 0.146705\n",
      "[8800]\ttraining's l1: 0.00779825\tvalid_1's l1: 0.146694\n",
      "[8900]\ttraining's l1: 0.00764285\tvalid_1's l1: 0.146685\n",
      "[9000]\ttraining's l1: 0.00748425\tvalid_1's l1: 0.146671\n",
      "[9100]\ttraining's l1: 0.00733459\tvalid_1's l1: 0.14666\n",
      "[9200]\ttraining's l1: 0.00718682\tvalid_1's l1: 0.146647\n",
      "[9300]\ttraining's l1: 0.00704417\tvalid_1's l1: 0.146641\n",
      "[9400]\ttraining's l1: 0.00690817\tvalid_1's l1: 0.146635\n",
      "[9500]\ttraining's l1: 0.00676876\tvalid_1's l1: 0.146632\n",
      "[9600]\ttraining's l1: 0.0066328\tvalid_1's l1: 0.146621\n",
      "[9700]\ttraining's l1: 0.00650455\tvalid_1's l1: 0.146616\n",
      "[9800]\ttraining's l1: 0.00637177\tvalid_1's l1: 0.146608\n",
      "[9900]\ttraining's l1: 0.00625551\tvalid_1's l1: 0.146601\n",
      "[10000]\ttraining's l1: 0.00613438\tvalid_1's l1: 0.146592\n",
      "[10100]\ttraining's l1: 0.00602824\tvalid_1's l1: 0.146585\n",
      "[10200]\ttraining's l1: 0.00591861\tvalid_1's l1: 0.146576\n",
      "[10300]\ttraining's l1: 0.00581377\tvalid_1's l1: 0.146569\n",
      "[10400]\ttraining's l1: 0.00570783\tvalid_1's l1: 0.14656\n",
      "[10500]\ttraining's l1: 0.00560675\tvalid_1's l1: 0.146558\n",
      "[10600]\ttraining's l1: 0.00550691\tvalid_1's l1: 0.146555\n",
      "[10700]\ttraining's l1: 0.00540582\tvalid_1's l1: 0.146545\n",
      "[10800]\ttraining's l1: 0.00531419\tvalid_1's l1: 0.146541\n",
      "[10900]\ttraining's l1: 0.00522196\tvalid_1's l1: 0.146534\n",
      "[11000]\ttraining's l1: 0.00512995\tvalid_1's l1: 0.146528\n",
      "[11100]\ttraining's l1: 0.00503956\tvalid_1's l1: 0.14652\n",
      "[11200]\ttraining's l1: 0.00495124\tvalid_1's l1: 0.146517\n",
      "[11300]\ttraining's l1: 0.00486921\tvalid_1's l1: 0.146514\n",
      "[11400]\ttraining's l1: 0.00478825\tvalid_1's l1: 0.14651\n",
      "[11500]\ttraining's l1: 0.0047117\tvalid_1's l1: 0.146503\n",
      "[11600]\ttraining's l1: 0.00463379\tvalid_1's l1: 0.146497\n",
      "[11700]\ttraining's l1: 0.00455232\tvalid_1's l1: 0.146493\n",
      "[11800]\ttraining's l1: 0.0044803\tvalid_1's l1: 0.146491\n",
      "[11900]\ttraining's l1: 0.00440609\tvalid_1's l1: 0.146483\n",
      "[12000]\ttraining's l1: 0.00433078\tvalid_1's l1: 0.146477\n",
      "[12100]\ttraining's l1: 0.00426276\tvalid_1's l1: 0.146476\n",
      "[12200]\ttraining's l1: 0.00419653\tvalid_1's l1: 0.146469\n",
      "[12300]\ttraining's l1: 0.00412553\tvalid_1's l1: 0.146464\n",
      "[12400]\ttraining's l1: 0.00405967\tvalid_1's l1: 0.146462\n",
      "[12500]\ttraining's l1: 0.00399608\tvalid_1's l1: 0.146456\n",
      "[12600]\ttraining's l1: 0.0039334\tvalid_1's l1: 0.146453\n",
      "[12700]\ttraining's l1: 0.00387014\tvalid_1's l1: 0.14645\n",
      "[12800]\ttraining's l1: 0.00381036\tvalid_1's l1: 0.146446\n",
      "[12900]\ttraining's l1: 0.00375241\tvalid_1's l1: 0.146441\n",
      "[13000]\ttraining's l1: 0.00369205\tvalid_1's l1: 0.146436\n",
      "[13100]\ttraining's l1: 0.00363768\tvalid_1's l1: 0.146436\n",
      "[13200]\ttraining's l1: 0.00358098\tvalid_1's l1: 0.14643\n",
      "[13300]\ttraining's l1: 0.00352949\tvalid_1's l1: 0.146426\n",
      "[13400]\ttraining's l1: 0.00348036\tvalid_1's l1: 0.146421\n",
      "[13500]\ttraining's l1: 0.00343023\tvalid_1's l1: 0.146419\n",
      "[13600]\ttraining's l1: 0.00337986\tvalid_1's l1: 0.146414\n",
      "[13700]\ttraining's l1: 0.00332966\tvalid_1's l1: 0.146413\n",
      "[13800]\ttraining's l1: 0.00328241\tvalid_1's l1: 0.146412\n",
      "[13900]\ttraining's l1: 0.00323352\tvalid_1's l1: 0.146413\n",
      "Early stopping, best iteration is:\n",
      "[13807]\ttraining's l1: 0.00327808\tvalid_1's l1: 0.146412\n",
      "--------------------\n",
      "Fold 5\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.31238\tvalid_1's l1: 0.326836\n",
      "[200]\ttraining's l1: 0.22319\tvalid_1's l1: 0.25123\n",
      "[300]\ttraining's l1: 0.178682\tvalid_1's l1: 0.217025\n",
      "[400]\ttraining's l1: 0.152779\tvalid_1's l1: 0.199121\n",
      "[500]\ttraining's l1: 0.135001\tvalid_1's l1: 0.188521\n",
      "[600]\ttraining's l1: 0.121671\tvalid_1's l1: 0.181349\n",
      "[700]\ttraining's l1: 0.111392\tvalid_1's l1: 0.176727\n",
      "[800]\ttraining's l1: 0.102973\tvalid_1's l1: 0.173294\n",
      "[900]\ttraining's l1: 0.0959485\tvalid_1's l1: 0.170549\n",
      "[1000]\ttraining's l1: 0.0898196\tvalid_1's l1: 0.168522\n",
      "[1100]\ttraining's l1: 0.0842951\tvalid_1's l1: 0.166686\n",
      "[1200]\ttraining's l1: 0.0793625\tvalid_1's l1: 0.165219\n",
      "[1300]\ttraining's l1: 0.0750613\tvalid_1's l1: 0.164027\n",
      "[1400]\ttraining's l1: 0.0709702\tvalid_1's l1: 0.162841\n",
      "[1500]\ttraining's l1: 0.0673686\tvalid_1's l1: 0.161917\n",
      "[1600]\ttraining's l1: 0.0640492\tvalid_1's l1: 0.161074\n",
      "[1700]\ttraining's l1: 0.0610827\tvalid_1's l1: 0.160316\n",
      "[1800]\ttraining's l1: 0.0583338\tvalid_1's l1: 0.159762\n",
      "[1900]\ttraining's l1: 0.0557417\tvalid_1's l1: 0.159169\n",
      "[2000]\ttraining's l1: 0.0533378\tvalid_1's l1: 0.158694\n",
      "[2100]\ttraining's l1: 0.0510497\tvalid_1's l1: 0.158221\n",
      "[2200]\ttraining's l1: 0.0489408\tvalid_1's l1: 0.157855\n",
      "[2300]\ttraining's l1: 0.0469877\tvalid_1's l1: 0.157481\n",
      "[2400]\ttraining's l1: 0.0451709\tvalid_1's l1: 0.157112\n",
      "[2500]\ttraining's l1: 0.0434089\tvalid_1's l1: 0.156839\n",
      "[2600]\ttraining's l1: 0.041783\tvalid_1's l1: 0.156546\n",
      "[2700]\ttraining's l1: 0.0402633\tvalid_1's l1: 0.156323\n",
      "[2800]\ttraining's l1: 0.0388333\tvalid_1's l1: 0.156067\n",
      "[2900]\ttraining's l1: 0.0374262\tvalid_1's l1: 0.155851\n",
      "[3000]\ttraining's l1: 0.0361638\tvalid_1's l1: 0.155636\n",
      "[3100]\ttraining's l1: 0.0348976\tvalid_1's l1: 0.155463\n",
      "[3200]\ttraining's l1: 0.0337318\tvalid_1's l1: 0.155271\n",
      "[3300]\ttraining's l1: 0.0326281\tvalid_1's l1: 0.155122\n",
      "[3400]\ttraining's l1: 0.0315855\tvalid_1's l1: 0.154982\n",
      "[3500]\ttraining's l1: 0.0305637\tvalid_1's l1: 0.15484\n",
      "[3600]\ttraining's l1: 0.0295826\tvalid_1's l1: 0.154719\n",
      "[3700]\ttraining's l1: 0.0286349\tvalid_1's l1: 0.154605\n",
      "[3800]\ttraining's l1: 0.0277541\tvalid_1's l1: 0.154499\n",
      "[3900]\ttraining's l1: 0.0268912\tvalid_1's l1: 0.154395\n",
      "[4000]\ttraining's l1: 0.0260487\tvalid_1's l1: 0.154298\n",
      "[4100]\ttraining's l1: 0.0252525\tvalid_1's l1: 0.154221\n",
      "[4200]\ttraining's l1: 0.0244992\tvalid_1's l1: 0.154134\n",
      "[4300]\ttraining's l1: 0.0237598\tvalid_1's l1: 0.154046\n",
      "[4400]\ttraining's l1: 0.0230537\tvalid_1's l1: 0.153975\n",
      "[4500]\ttraining's l1: 0.0223659\tvalid_1's l1: 0.153899\n",
      "[4600]\ttraining's l1: 0.021733\tvalid_1's l1: 0.153841\n",
      "[4700]\ttraining's l1: 0.0211257\tvalid_1's l1: 0.153804\n",
      "[4800]\ttraining's l1: 0.0205191\tvalid_1's l1: 0.153741\n",
      "[4900]\ttraining's l1: 0.0199514\tvalid_1's l1: 0.1537\n",
      "[5000]\ttraining's l1: 0.0194138\tvalid_1's l1: 0.153643\n",
      "[5100]\ttraining's l1: 0.0188987\tvalid_1's l1: 0.153586\n",
      "[5200]\ttraining's l1: 0.0183934\tvalid_1's l1: 0.153536\n",
      "[5300]\ttraining's l1: 0.017906\tvalid_1's l1: 0.153487\n",
      "[5400]\ttraining's l1: 0.0174212\tvalid_1's l1: 0.153435\n",
      "[5500]\ttraining's l1: 0.0169721\tvalid_1's l1: 0.153395\n",
      "[5600]\ttraining's l1: 0.016542\tvalid_1's l1: 0.153341\n",
      "[5700]\ttraining's l1: 0.0161386\tvalid_1's l1: 0.153295\n",
      "[5800]\ttraining's l1: 0.0157236\tvalid_1's l1: 0.153256\n",
      "[5900]\ttraining's l1: 0.0153284\tvalid_1's l1: 0.153225\n",
      "[6000]\ttraining's l1: 0.0149443\tvalid_1's l1: 0.153189\n",
      "[6100]\ttraining's l1: 0.0145747\tvalid_1's l1: 0.153151\n",
      "[6200]\ttraining's l1: 0.0142087\tvalid_1's l1: 0.153115\n",
      "[6300]\ttraining's l1: 0.0138526\tvalid_1's l1: 0.153089\n",
      "[6400]\ttraining's l1: 0.0135216\tvalid_1's l1: 0.153062\n",
      "[6500]\ttraining's l1: 0.0131861\tvalid_1's l1: 0.153032\n",
      "[6600]\ttraining's l1: 0.0128712\tvalid_1's l1: 0.152998\n",
      "[6700]\ttraining's l1: 0.0125564\tvalid_1's l1: 0.152964\n",
      "[6800]\ttraining's l1: 0.0122514\tvalid_1's l1: 0.152946\n",
      "[6900]\ttraining's l1: 0.0119819\tvalid_1's l1: 0.15292\n",
      "[7000]\ttraining's l1: 0.0116956\tvalid_1's l1: 0.152898\n",
      "[7100]\ttraining's l1: 0.0114336\tvalid_1's l1: 0.152872\n",
      "[7200]\ttraining's l1: 0.0111772\tvalid_1's l1: 0.152844\n",
      "[7300]\ttraining's l1: 0.0109215\tvalid_1's l1: 0.152828\n",
      "[7400]\ttraining's l1: 0.0106757\tvalid_1's l1: 0.152807\n",
      "[7500]\ttraining's l1: 0.0104346\tvalid_1's l1: 0.152788\n",
      "[7600]\ttraining's l1: 0.0101942\tvalid_1's l1: 0.152766\n",
      "[7700]\ttraining's l1: 0.00996736\tvalid_1's l1: 0.152756\n",
      "[7800]\ttraining's l1: 0.00975729\tvalid_1's l1: 0.152743\n",
      "[7900]\ttraining's l1: 0.00954076\tvalid_1's l1: 0.152724\n",
      "[8000]\ttraining's l1: 0.00932581\tvalid_1's l1: 0.15271\n",
      "[8100]\ttraining's l1: 0.00911633\tvalid_1's l1: 0.15269\n",
      "[8200]\ttraining's l1: 0.00892122\tvalid_1's l1: 0.152674\n",
      "[8300]\ttraining's l1: 0.00873192\tvalid_1's l1: 0.152658\n",
      "[8400]\ttraining's l1: 0.00854972\tvalid_1's l1: 0.152644\n",
      "[8500]\ttraining's l1: 0.00837221\tvalid_1's l1: 0.152634\n",
      "[8600]\ttraining's l1: 0.00820073\tvalid_1's l1: 0.152625\n",
      "[8700]\ttraining's l1: 0.00802962\tvalid_1's l1: 0.152619\n",
      "[8800]\ttraining's l1: 0.00786595\tvalid_1's l1: 0.152609\n",
      "[8900]\ttraining's l1: 0.00769789\tvalid_1's l1: 0.152598\n",
      "[9000]\ttraining's l1: 0.0075346\tvalid_1's l1: 0.152585\n",
      "[9100]\ttraining's l1: 0.00739314\tvalid_1's l1: 0.152573\n",
      "[9200]\ttraining's l1: 0.00724906\tvalid_1's l1: 0.152559\n",
      "[9300]\ttraining's l1: 0.00710752\tvalid_1's l1: 0.152549\n",
      "[9400]\ttraining's l1: 0.00696672\tvalid_1's l1: 0.152538\n",
      "[9500]\ttraining's l1: 0.00682992\tvalid_1's l1: 0.152528\n",
      "[9600]\ttraining's l1: 0.00670584\tvalid_1's l1: 0.152519\n",
      "[9700]\ttraining's l1: 0.00657304\tvalid_1's l1: 0.152507\n",
      "[9800]\ttraining's l1: 0.00645176\tvalid_1's l1: 0.1525\n",
      "[9900]\ttraining's l1: 0.00633217\tvalid_1's l1: 0.152492\n",
      "[10000]\ttraining's l1: 0.00621536\tvalid_1's l1: 0.15249\n",
      "[10100]\ttraining's l1: 0.00609453\tvalid_1's l1: 0.152484\n",
      "[10200]\ttraining's l1: 0.00598838\tvalid_1's l1: 0.152478\n",
      "[10300]\ttraining's l1: 0.00587627\tvalid_1's l1: 0.152473\n",
      "[10400]\ttraining's l1: 0.00576784\tvalid_1's l1: 0.152465\n",
      "[10500]\ttraining's l1: 0.00566391\tvalid_1's l1: 0.152458\n",
      "[10600]\ttraining's l1: 0.00556621\tvalid_1's l1: 0.152446\n",
      "[10700]\ttraining's l1: 0.00547049\tvalid_1's l1: 0.152439\n",
      "[10800]\ttraining's l1: 0.0053689\tvalid_1's l1: 0.152436\n",
      "[10900]\ttraining's l1: 0.00527198\tvalid_1's l1: 0.152436\n",
      "[11000]\ttraining's l1: 0.00518536\tvalid_1's l1: 0.152428\n",
      "[11100]\ttraining's l1: 0.00509383\tvalid_1's l1: 0.152421\n",
      "[11200]\ttraining's l1: 0.00500571\tvalid_1's l1: 0.152415\n",
      "[11300]\ttraining's l1: 0.00492175\tvalid_1's l1: 0.152409\n",
      "[11400]\ttraining's l1: 0.00483947\tvalid_1's l1: 0.152405\n",
      "[11500]\ttraining's l1: 0.00475605\tvalid_1's l1: 0.152401\n",
      "[11600]\ttraining's l1: 0.00467862\tvalid_1's l1: 0.1524\n",
      "[11700]\ttraining's l1: 0.00460138\tvalid_1's l1: 0.152394\n",
      "[11800]\ttraining's l1: 0.00452557\tvalid_1's l1: 0.152391\n",
      "[11900]\ttraining's l1: 0.00444944\tvalid_1's l1: 0.152386\n",
      "[12000]\ttraining's l1: 0.00437969\tvalid_1's l1: 0.152382\n",
      "[12100]\ttraining's l1: 0.0043044\tvalid_1's l1: 0.152374\n",
      "[12200]\ttraining's l1: 0.00423418\tvalid_1's l1: 0.15237\n",
      "[12300]\ttraining's l1: 0.0041658\tvalid_1's l1: 0.152366\n",
      "[12400]\ttraining's l1: 0.00409812\tvalid_1's l1: 0.152363\n",
      "[12500]\ttraining's l1: 0.00403645\tvalid_1's l1: 0.152356\n",
      "[12600]\ttraining's l1: 0.00397474\tvalid_1's l1: 0.152349\n",
      "[12700]\ttraining's l1: 0.00391508\tvalid_1's l1: 0.152347\n",
      "Early stopping, best iteration is:\n",
      "[12676]\ttraining's l1: 0.00392979\tvalid_1's l1: 0.152347\n",
      "--------------------\n",
      "Fold 6\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.31419\tvalid_1's l1: 0.331307\n",
      "[200]\ttraining's l1: 0.219996\tvalid_1's l1: 0.24692\n",
      "[300]\ttraining's l1: 0.175329\tvalid_1's l1: 0.211813\n",
      "[400]\ttraining's l1: 0.150043\tvalid_1's l1: 0.195146\n",
      "[500]\ttraining's l1: 0.132799\tvalid_1's l1: 0.184738\n",
      "[600]\ttraining's l1: 0.120457\tvalid_1's l1: 0.178457\n",
      "[700]\ttraining's l1: 0.110511\tvalid_1's l1: 0.173994\n",
      "[800]\ttraining's l1: 0.102302\tvalid_1's l1: 0.170504\n",
      "[900]\ttraining's l1: 0.0952609\tvalid_1's l1: 0.167732\n",
      "[1000]\ttraining's l1: 0.0890231\tvalid_1's l1: 0.165599\n",
      "[1100]\ttraining's l1: 0.0836487\tvalid_1's l1: 0.163903\n",
      "[1200]\ttraining's l1: 0.0789236\tvalid_1's l1: 0.162468\n",
      "[1300]\ttraining's l1: 0.0745864\tvalid_1's l1: 0.161251\n",
      "[1400]\ttraining's l1: 0.0707238\tvalid_1's l1: 0.160166\n",
      "[1500]\ttraining's l1: 0.0671298\tvalid_1's l1: 0.159283\n",
      "[1600]\ttraining's l1: 0.0638616\tvalid_1's l1: 0.158534\n",
      "[1700]\ttraining's l1: 0.0608916\tvalid_1's l1: 0.157883\n",
      "[1800]\ttraining's l1: 0.0581286\tvalid_1's l1: 0.157316\n",
      "[1900]\ttraining's l1: 0.0555008\tvalid_1's l1: 0.156748\n",
      "[2000]\ttraining's l1: 0.0530501\tvalid_1's l1: 0.156283\n",
      "[2100]\ttraining's l1: 0.0508129\tvalid_1's l1: 0.155865\n",
      "[2200]\ttraining's l1: 0.0487339\tvalid_1's l1: 0.155474\n",
      "[2300]\ttraining's l1: 0.0467654\tvalid_1's l1: 0.155146\n",
      "[2400]\ttraining's l1: 0.0449509\tvalid_1's l1: 0.154827\n",
      "[2500]\ttraining's l1: 0.0431717\tvalid_1's l1: 0.15453\n",
      "[2600]\ttraining's l1: 0.0415806\tvalid_1's l1: 0.154313\n",
      "[2700]\ttraining's l1: 0.04005\tvalid_1's l1: 0.154073\n",
      "[2800]\ttraining's l1: 0.0385875\tvalid_1's l1: 0.153847\n",
      "[2900]\ttraining's l1: 0.0371979\tvalid_1's l1: 0.153617\n",
      "[3000]\ttraining's l1: 0.0359028\tvalid_1's l1: 0.15342\n",
      "[3100]\ttraining's l1: 0.0346402\tvalid_1's l1: 0.153243\n",
      "[3200]\ttraining's l1: 0.0334828\tvalid_1's l1: 0.153089\n",
      "[3300]\ttraining's l1: 0.0323791\tvalid_1's l1: 0.15294\n",
      "[3400]\ttraining's l1: 0.0313133\tvalid_1's l1: 0.15282\n",
      "[3500]\ttraining's l1: 0.0303181\tvalid_1's l1: 0.152685\n",
      "[3600]\ttraining's l1: 0.0293509\tvalid_1's l1: 0.152547\n",
      "[3700]\ttraining's l1: 0.0284424\tvalid_1's l1: 0.152427\n",
      "[3800]\ttraining's l1: 0.0275223\tvalid_1's l1: 0.152325\n",
      "[3900]\ttraining's l1: 0.0266736\tvalid_1's l1: 0.152226\n",
      "[4000]\ttraining's l1: 0.0258494\tvalid_1's l1: 0.152138\n",
      "[4100]\ttraining's l1: 0.0250762\tvalid_1's l1: 0.152072\n",
      "[4200]\ttraining's l1: 0.0243375\tvalid_1's l1: 0.151997\n",
      "[4300]\ttraining's l1: 0.023608\tvalid_1's l1: 0.151898\n",
      "[4400]\ttraining's l1: 0.0229412\tvalid_1's l1: 0.151822\n",
      "[4500]\ttraining's l1: 0.022274\tvalid_1's l1: 0.151745\n",
      "[4600]\ttraining's l1: 0.0216385\tvalid_1's l1: 0.151658\n",
      "[4700]\ttraining's l1: 0.0210193\tvalid_1's l1: 0.151607\n",
      "[4800]\ttraining's l1: 0.0204289\tvalid_1's l1: 0.151555\n",
      "[4900]\ttraining's l1: 0.0198573\tvalid_1's l1: 0.151494\n",
      "[5000]\ttraining's l1: 0.0192902\tvalid_1's l1: 0.151448\n",
      "[5100]\ttraining's l1: 0.0187756\tvalid_1's l1: 0.151397\n",
      "[5200]\ttraining's l1: 0.0182671\tvalid_1's l1: 0.151352\n",
      "[5300]\ttraining's l1: 0.0177719\tvalid_1's l1: 0.151307\n",
      "[5400]\ttraining's l1: 0.0172987\tvalid_1's l1: 0.151252\n",
      "[5500]\ttraining's l1: 0.0168469\tvalid_1's l1: 0.151202\n",
      "[5600]\ttraining's l1: 0.0164091\tvalid_1's l1: 0.151152\n",
      "[5700]\ttraining's l1: 0.015978\tvalid_1's l1: 0.15111\n",
      "[5800]\ttraining's l1: 0.0155513\tvalid_1's l1: 0.15107\n",
      "[5900]\ttraining's l1: 0.0151614\tvalid_1's l1: 0.151035\n",
      "[6000]\ttraining's l1: 0.0147673\tvalid_1's l1: 0.151\n",
      "[6100]\ttraining's l1: 0.0143991\tvalid_1's l1: 0.150978\n",
      "[6200]\ttraining's l1: 0.014037\tvalid_1's l1: 0.150946\n",
      "[6300]\ttraining's l1: 0.0136844\tvalid_1's l1: 0.150906\n",
      "[6400]\ttraining's l1: 0.0133358\tvalid_1's l1: 0.150877\n",
      "[6500]\ttraining's l1: 0.0130075\tvalid_1's l1: 0.150841\n",
      "[6600]\ttraining's l1: 0.012689\tvalid_1's l1: 0.150819\n",
      "[6700]\ttraining's l1: 0.0123915\tvalid_1's l1: 0.150799\n",
      "[6800]\ttraining's l1: 0.0120927\tvalid_1's l1: 0.150782\n",
      "[6900]\ttraining's l1: 0.0118142\tvalid_1's l1: 0.150763\n",
      "[7000]\ttraining's l1: 0.0115425\tvalid_1's l1: 0.150734\n",
      "[7100]\ttraining's l1: 0.0112615\tvalid_1's l1: 0.150717\n",
      "[7200]\ttraining's l1: 0.0110049\tvalid_1's l1: 0.150699\n",
      "[7300]\ttraining's l1: 0.0107457\tvalid_1's l1: 0.150682\n",
      "[7400]\ttraining's l1: 0.0104964\tvalid_1's l1: 0.150661\n",
      "[7500]\ttraining's l1: 0.0102561\tvalid_1's l1: 0.150642\n",
      "[7600]\ttraining's l1: 0.0100293\tvalid_1's l1: 0.150618\n",
      "[7700]\ttraining's l1: 0.00980344\tvalid_1's l1: 0.150597\n",
      "[7800]\ttraining's l1: 0.00957805\tvalid_1's l1: 0.150585\n",
      "[7900]\ttraining's l1: 0.0093685\tvalid_1's l1: 0.15057\n",
      "[8000]\ttraining's l1: 0.00916754\tvalid_1's l1: 0.150557\n",
      "[8100]\ttraining's l1: 0.008977\tvalid_1's l1: 0.150543\n",
      "[8200]\ttraining's l1: 0.00879062\tvalid_1's l1: 0.150529\n",
      "[8300]\ttraining's l1: 0.00861377\tvalid_1's l1: 0.150516\n",
      "[8400]\ttraining's l1: 0.00842996\tvalid_1's l1: 0.150496\n",
      "[8500]\ttraining's l1: 0.00825677\tvalid_1's l1: 0.150483\n",
      "[8600]\ttraining's l1: 0.00808535\tvalid_1's l1: 0.150474\n",
      "[8700]\ttraining's l1: 0.00791066\tvalid_1's l1: 0.150461\n",
      "[8800]\ttraining's l1: 0.0077509\tvalid_1's l1: 0.150449\n",
      "[8900]\ttraining's l1: 0.00759216\tvalid_1's l1: 0.150433\n",
      "[9000]\ttraining's l1: 0.00743407\tvalid_1's l1: 0.15042\n",
      "[9100]\ttraining's l1: 0.00728792\tvalid_1's l1: 0.150417\n",
      "[9200]\ttraining's l1: 0.00714006\tvalid_1's l1: 0.150406\n",
      "[9300]\ttraining's l1: 0.00699703\tvalid_1's l1: 0.150391\n",
      "[9400]\ttraining's l1: 0.0068599\tvalid_1's l1: 0.150384\n",
      "[9500]\ttraining's l1: 0.00672506\tvalid_1's l1: 0.15038\n",
      "[9600]\ttraining's l1: 0.00658549\tvalid_1's l1: 0.150372\n",
      "[9700]\ttraining's l1: 0.00645881\tvalid_1's l1: 0.150361\n",
      "[9800]\ttraining's l1: 0.00632514\tvalid_1's l1: 0.150348\n",
      "[9900]\ttraining's l1: 0.0062085\tvalid_1's l1: 0.150343\n",
      "[10000]\ttraining's l1: 0.00609062\tvalid_1's l1: 0.150334\n",
      "[10100]\ttraining's l1: 0.00598659\tvalid_1's l1: 0.150332\n",
      "[10200]\ttraining's l1: 0.00587911\tvalid_1's l1: 0.15033\n",
      "[10300]\ttraining's l1: 0.00577605\tvalid_1's l1: 0.150323\n",
      "[10400]\ttraining's l1: 0.00566988\tvalid_1's l1: 0.150315\n",
      "[10500]\ttraining's l1: 0.00556942\tvalid_1's l1: 0.150314\n",
      "[10600]\ttraining's l1: 0.0054687\tvalid_1's l1: 0.150304\n",
      "[10700]\ttraining's l1: 0.0053677\tvalid_1's l1: 0.150297\n",
      "[10800]\ttraining's l1: 0.00527216\tvalid_1's l1: 0.150289\n",
      "[10900]\ttraining's l1: 0.00518256\tvalid_1's l1: 0.150287\n",
      "[11000]\ttraining's l1: 0.00508862\tvalid_1's l1: 0.15028\n",
      "[11100]\ttraining's l1: 0.00499627\tvalid_1's l1: 0.150275\n",
      "[11200]\ttraining's l1: 0.00490764\tvalid_1's l1: 0.150268\n",
      "[11300]\ttraining's l1: 0.00482612\tvalid_1's l1: 0.150263\n",
      "[11400]\ttraining's l1: 0.00474492\tvalid_1's l1: 0.150256\n",
      "[11500]\ttraining's l1: 0.00466793\tvalid_1's l1: 0.150251\n",
      "[11600]\ttraining's l1: 0.00458988\tvalid_1's l1: 0.150249\n",
      "[11700]\ttraining's l1: 0.00450991\tvalid_1's l1: 0.150243\n",
      "[11800]\ttraining's l1: 0.00443719\tvalid_1's l1: 0.15024\n",
      "[11900]\ttraining's l1: 0.00436178\tvalid_1's l1: 0.150233\n",
      "[12000]\ttraining's l1: 0.00428563\tvalid_1's l1: 0.150227\n",
      "[12100]\ttraining's l1: 0.00421766\tvalid_1's l1: 0.150222\n",
      "[12200]\ttraining's l1: 0.00414978\tvalid_1's l1: 0.150219\n",
      "[12300]\ttraining's l1: 0.00407916\tvalid_1's l1: 0.150212\n",
      "[12400]\ttraining's l1: 0.00401152\tvalid_1's l1: 0.150206\n",
      "[12500]\ttraining's l1: 0.00394755\tvalid_1's l1: 0.150203\n",
      "[12600]\ttraining's l1: 0.00388362\tvalid_1's l1: 0.1502\n",
      "[12700]\ttraining's l1: 0.00382276\tvalid_1's l1: 0.150198\n",
      "[12800]\ttraining's l1: 0.00376429\tvalid_1's l1: 0.150193\n",
      "[12900]\ttraining's l1: 0.00370658\tvalid_1's l1: 0.150188\n",
      "[13000]\ttraining's l1: 0.00364668\tvalid_1's l1: 0.150181\n",
      "[13100]\ttraining's l1: 0.003592\tvalid_1's l1: 0.150176\n",
      "[13200]\ttraining's l1: 0.003535\tvalid_1's l1: 0.150172\n",
      "[13300]\ttraining's l1: 0.00348332\tvalid_1's l1: 0.150167\n",
      "[13400]\ttraining's l1: 0.00343267\tvalid_1's l1: 0.150163\n",
      "[13500]\ttraining's l1: 0.00338156\tvalid_1's l1: 0.150158\n",
      "[13600]\ttraining's l1: 0.00332982\tvalid_1's l1: 0.150155\n",
      "[13700]\ttraining's l1: 0.00327972\tvalid_1's l1: 0.150152\n",
      "[13800]\ttraining's l1: 0.00323283\tvalid_1's l1: 0.15015\n",
      "[13900]\ttraining's l1: 0.00318458\tvalid_1's l1: 0.150145\n",
      "[14000]\ttraining's l1: 0.00313685\tvalid_1's l1: 0.150142\n",
      "[14100]\ttraining's l1: 0.00309033\tvalid_1's l1: 0.150141\n",
      "[14200]\ttraining's l1: 0.00304584\tvalid_1's l1: 0.150139\n",
      "[14300]\ttraining's l1: 0.00299951\tvalid_1's l1: 0.150133\n",
      "Early stopping, best iteration is:\n",
      "[14257]\ttraining's l1: 0.00301886\tvalid_1's l1: 0.150132\n",
      "--------------------\n",
      "Fold 7\n",
      "--------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l1: 0.312595\tvalid_1's l1: 0.327764\n",
      "[200]\ttraining's l1: 0.22377\tvalid_1's l1: 0.248361\n",
      "[300]\ttraining's l1: 0.179005\tvalid_1's l1: 0.212956\n",
      "[400]\ttraining's l1: 0.152968\tvalid_1's l1: 0.195461\n",
      "[500]\ttraining's l1: 0.135141\tvalid_1's l1: 0.185346\n",
      "[600]\ttraining's l1: 0.121733\tvalid_1's l1: 0.178625\n",
      "[700]\ttraining's l1: 0.111435\tvalid_1's l1: 0.174085\n",
      "[800]\ttraining's l1: 0.102986\tvalid_1's l1: 0.17079\n",
      "[900]\ttraining's l1: 0.0959557\tvalid_1's l1: 0.168361\n",
      "[1000]\ttraining's l1: 0.0898177\tvalid_1's l1: 0.166452\n",
      "[1100]\ttraining's l1: 0.0842338\tvalid_1's l1: 0.164801\n",
      "[1200]\ttraining's l1: 0.0792583\tvalid_1's l1: 0.163294\n",
      "[1300]\ttraining's l1: 0.0749182\tvalid_1's l1: 0.162089\n",
      "[1400]\ttraining's l1: 0.0708409\tvalid_1's l1: 0.160997\n",
      "[1500]\ttraining's l1: 0.0672592\tvalid_1's l1: 0.16011\n",
      "[1600]\ttraining's l1: 0.0639371\tvalid_1's l1: 0.159391\n",
      "[1700]\ttraining's l1: 0.0610106\tvalid_1's l1: 0.158737\n",
      "[1800]\ttraining's l1: 0.0582629\tvalid_1's l1: 0.158105\n",
      "[1900]\ttraining's l1: 0.0556745\tvalid_1's l1: 0.157597\n",
      "[2000]\ttraining's l1: 0.0532577\tvalid_1's l1: 0.157148\n",
      "[2100]\ttraining's l1: 0.0509774\tvalid_1's l1: 0.15672\n",
      "[2200]\ttraining's l1: 0.0488546\tvalid_1's l1: 0.156351\n",
      "[2300]\ttraining's l1: 0.0468891\tvalid_1's l1: 0.155992\n",
      "[2400]\ttraining's l1: 0.0450449\tvalid_1's l1: 0.155731\n",
      "[2500]\ttraining's l1: 0.0432734\tvalid_1's l1: 0.155442\n",
      "[2600]\ttraining's l1: 0.0416611\tvalid_1's l1: 0.155217\n",
      "[2700]\ttraining's l1: 0.0401435\tvalid_1's l1: 0.155003\n",
      "[2800]\ttraining's l1: 0.0387031\tvalid_1's l1: 0.154796\n",
      "[2900]\ttraining's l1: 0.0373125\tvalid_1's l1: 0.154597\n",
      "[3000]\ttraining's l1: 0.0360297\tvalid_1's l1: 0.154421\n",
      "[3100]\ttraining's l1: 0.0347792\tvalid_1's l1: 0.15424\n",
      "[3200]\ttraining's l1: 0.033628\tvalid_1's l1: 0.15408\n",
      "[3300]\ttraining's l1: 0.0325264\tvalid_1's l1: 0.153922\n",
      "[3400]\ttraining's l1: 0.0314884\tvalid_1's l1: 0.153753\n",
      "[3500]\ttraining's l1: 0.0304901\tvalid_1's l1: 0.153633\n",
      "[3600]\ttraining's l1: 0.0295083\tvalid_1's l1: 0.153518\n",
      "[3700]\ttraining's l1: 0.0285706\tvalid_1's l1: 0.1534\n",
      "[3800]\ttraining's l1: 0.0277042\tvalid_1's l1: 0.153312\n",
      "[3900]\ttraining's l1: 0.0268524\tvalid_1's l1: 0.15324\n",
      "[4000]\ttraining's l1: 0.0259938\tvalid_1's l1: 0.153143\n",
      "[4100]\ttraining's l1: 0.025189\tvalid_1's l1: 0.153073\n",
      "[4200]\ttraining's l1: 0.0244299\tvalid_1's l1: 0.153015\n",
      "[4300]\ttraining's l1: 0.0237132\tvalid_1's l1: 0.152945\n",
      "[4400]\ttraining's l1: 0.0230275\tvalid_1's l1: 0.152874\n",
      "[4500]\ttraining's l1: 0.0223645\tvalid_1's l1: 0.152808\n",
      "[4600]\ttraining's l1: 0.021741\tvalid_1's l1: 0.152745\n",
      "[4700]\ttraining's l1: 0.0211287\tvalid_1's l1: 0.152695\n",
      "[4800]\ttraining's l1: 0.0205335\tvalid_1's l1: 0.15264\n",
      "[4900]\ttraining's l1: 0.0199714\tvalid_1's l1: 0.152599\n",
      "[5000]\ttraining's l1: 0.0194207\tvalid_1's l1: 0.152549\n",
      "[5100]\ttraining's l1: 0.0189128\tvalid_1's l1: 0.152502\n",
      "[5200]\ttraining's l1: 0.0184266\tvalid_1's l1: 0.152457\n",
      "[5300]\ttraining's l1: 0.0179322\tvalid_1's l1: 0.152412\n",
      "[5400]\ttraining's l1: 0.0174501\tvalid_1's l1: 0.152383\n",
      "[5500]\ttraining's l1: 0.0169892\tvalid_1's l1: 0.152338\n",
      "[5600]\ttraining's l1: 0.016559\tvalid_1's l1: 0.152319\n",
      "[5700]\ttraining's l1: 0.0161476\tvalid_1's l1: 0.152291\n",
      "[5800]\ttraining's l1: 0.0157234\tvalid_1's l1: 0.152249\n",
      "[5900]\ttraining's l1: 0.0153292\tvalid_1's l1: 0.152222\n",
      "[6000]\ttraining's l1: 0.0149403\tvalid_1's l1: 0.152192\n",
      "[6100]\ttraining's l1: 0.0145707\tvalid_1's l1: 0.152156\n",
      "[6200]\ttraining's l1: 0.0142092\tvalid_1's l1: 0.15214\n",
      "[6300]\ttraining's l1: 0.0138599\tvalid_1's l1: 0.152112\n",
      "[6400]\ttraining's l1: 0.0135239\tvalid_1's l1: 0.15208\n",
      "[6500]\ttraining's l1: 0.0131882\tvalid_1's l1: 0.152054\n",
      "[6600]\ttraining's l1: 0.0128796\tvalid_1's l1: 0.152037\n",
      "[6700]\ttraining's l1: 0.0125632\tvalid_1's l1: 0.152011\n",
      "[6800]\ttraining's l1: 0.012261\tvalid_1's l1: 0.151992\n",
      "[6900]\ttraining's l1: 0.0119903\tvalid_1's l1: 0.151973\n",
      "[7000]\ttraining's l1: 0.0116999\tvalid_1's l1: 0.151943\n",
      "[7100]\ttraining's l1: 0.011438\tvalid_1's l1: 0.151918\n",
      "[7200]\ttraining's l1: 0.0111831\tvalid_1's l1: 0.151889\n",
      "[7300]\ttraining's l1: 0.0109248\tvalid_1's l1: 0.151867\n",
      "[7400]\ttraining's l1: 0.0106843\tvalid_1's l1: 0.15185\n",
      "[7500]\ttraining's l1: 0.0104454\tvalid_1's l1: 0.151832\n",
      "[7600]\ttraining's l1: 0.0102092\tvalid_1's l1: 0.151816\n",
      "[7700]\ttraining's l1: 0.00997122\tvalid_1's l1: 0.1518\n",
      "[7800]\ttraining's l1: 0.00975781\tvalid_1's l1: 0.151784\n",
      "[7900]\ttraining's l1: 0.00955062\tvalid_1's l1: 0.151772\n",
      "[8000]\ttraining's l1: 0.00933111\tvalid_1's l1: 0.151761\n",
      "[8100]\ttraining's l1: 0.00912226\tvalid_1's l1: 0.151745\n",
      "[8200]\ttraining's l1: 0.00893258\tvalid_1's l1: 0.151731\n",
      "[8300]\ttraining's l1: 0.00874786\tvalid_1's l1: 0.151718\n",
      "[8400]\ttraining's l1: 0.00856908\tvalid_1's l1: 0.151701\n",
      "[8500]\ttraining's l1: 0.00839249\tvalid_1's l1: 0.151691\n",
      "[8600]\ttraining's l1: 0.00822141\tvalid_1's l1: 0.151677\n",
      "[8700]\ttraining's l1: 0.00804959\tvalid_1's l1: 0.151667\n",
      "[8800]\ttraining's l1: 0.00789059\tvalid_1's l1: 0.151656\n",
      "[8900]\ttraining's l1: 0.00772469\tvalid_1's l1: 0.151647\n",
      "[9000]\ttraining's l1: 0.00756006\tvalid_1's l1: 0.151628\n",
      "[9100]\ttraining's l1: 0.00742019\tvalid_1's l1: 0.151618\n",
      "[9200]\ttraining's l1: 0.00727629\tvalid_1's l1: 0.151606\n",
      "[9300]\ttraining's l1: 0.00713817\tvalid_1's l1: 0.151598\n",
      "[9400]\ttraining's l1: 0.00700333\tvalid_1's l1: 0.151586\n",
      "[9500]\ttraining's l1: 0.00686722\tvalid_1's l1: 0.151574\n",
      "[9600]\ttraining's l1: 0.00674217\tvalid_1's l1: 0.151564\n",
      "[9700]\ttraining's l1: 0.00661125\tvalid_1's l1: 0.151557\n",
      "[9800]\ttraining's l1: 0.00648695\tvalid_1's l1: 0.151549\n",
      "[9900]\ttraining's l1: 0.00636595\tvalid_1's l1: 0.15154\n",
      "[10000]\ttraining's l1: 0.00625003\tvalid_1's l1: 0.151529\n",
      "[10100]\ttraining's l1: 0.00613389\tvalid_1's l1: 0.151522\n",
      "[10200]\ttraining's l1: 0.00602724\tvalid_1's l1: 0.151515\n",
      "[10300]\ttraining's l1: 0.00591416\tvalid_1's l1: 0.151505\n",
      "[10400]\ttraining's l1: 0.0058046\tvalid_1's l1: 0.151496\n",
      "[10500]\ttraining's l1: 0.00569911\tvalid_1's l1: 0.15149\n",
      "[10600]\ttraining's l1: 0.00560323\tvalid_1's l1: 0.151483\n",
      "[10700]\ttraining's l1: 0.00550717\tvalid_1's l1: 0.151472\n",
      "[10800]\ttraining's l1: 0.00540442\tvalid_1's l1: 0.151464\n",
      "[10900]\ttraining's l1: 0.0053086\tvalid_1's l1: 0.151459\n",
      "[11000]\ttraining's l1: 0.00521998\tvalid_1's l1: 0.151455\n",
      "[11100]\ttraining's l1: 0.00512957\tvalid_1's l1: 0.151449\n",
      "[11200]\ttraining's l1: 0.00504314\tvalid_1's l1: 0.151445\n",
      "[11300]\ttraining's l1: 0.0049583\tvalid_1's l1: 0.151439\n",
      "[11400]\ttraining's l1: 0.00487747\tvalid_1's l1: 0.151438\n",
      "[11500]\ttraining's l1: 0.00479551\tvalid_1's l1: 0.151429\n",
      "[11600]\ttraining's l1: 0.00471781\tvalid_1's l1: 0.151423\n",
      "[11700]\ttraining's l1: 0.00463944\tvalid_1's l1: 0.151415\n",
      "[11800]\ttraining's l1: 0.00456202\tvalid_1's l1: 0.151408\n",
      "[11900]\ttraining's l1: 0.0044861\tvalid_1's l1: 0.151403\n",
      "[12000]\ttraining's l1: 0.00441684\tvalid_1's l1: 0.1514\n",
      "[12100]\ttraining's l1: 0.00434441\tvalid_1's l1: 0.151394\n",
      "[12200]\ttraining's l1: 0.00427551\tvalid_1's l1: 0.151386\n",
      "[12300]\ttraining's l1: 0.0042058\tvalid_1's l1: 0.151379\n",
      "[12400]\ttraining's l1: 0.00413843\tvalid_1's l1: 0.151372\n",
      "[12500]\ttraining's l1: 0.00407664\tvalid_1's l1: 0.151365\n",
      "[12600]\ttraining's l1: 0.00401345\tvalid_1's l1: 0.151363\n",
      "[12700]\ttraining's l1: 0.00395274\tvalid_1's l1: 0.151359\n",
      "[12800]\ttraining's l1: 0.00389538\tvalid_1's l1: 0.151355\n",
      "[12900]\ttraining's l1: 0.00383591\tvalid_1's l1: 0.15135\n",
      "[13000]\ttraining's l1: 0.00377382\tvalid_1's l1: 0.151343\n",
      "[13100]\ttraining's l1: 0.0037152\tvalid_1's l1: 0.151335\n",
      "[13200]\ttraining's l1: 0.00365883\tvalid_1's l1: 0.151331\n",
      "[13300]\ttraining's l1: 0.00360667\tvalid_1's l1: 0.151328\n",
      "[13400]\ttraining's l1: 0.00355121\tvalid_1's l1: 0.151323\n",
      "[13500]\ttraining's l1: 0.0034969\tvalid_1's l1: 0.151321\n",
      "[13600]\ttraining's l1: 0.00344534\tvalid_1's l1: 0.151314\n",
      "[13700]\ttraining's l1: 0.00339836\tvalid_1's l1: 0.15131\n",
      "[13800]\ttraining's l1: 0.00334756\tvalid_1's l1: 0.15131\n",
      "Early stopping, best iteration is:\n",
      "[13743]\ttraining's l1: 0.00337678\tvalid_1's l1: 0.151308\n"
     ]
    }
   ],
   "source": [
    "out_taipei_valid_preds = []\n",
    "out_taipei_test_preds = []\n",
    "kf = KFold(n_splits=7, shuffle=False)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kf.split(out_taipei_X_train)):\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Fold {i+1}\")\n",
    "    print(\"-\" * 20)\n",
    "    train_data = lgb.Dataset(\n",
    "        out_taipei_X_train.iloc[train_index],\n",
    "        label=out_taipei_Y_train.iloc[train_index]\n",
    "    )\n",
    "    valid_data = lgb.Dataset(\n",
    "        out_taipei_X_train.iloc[val_index],\n",
    "        label=out_taipei_Y_train.iloc[val_index],\n",
    "        reference=train_data\n",
    "    )\n",
    "    model = lgb.train(\n",
    "        param_,\n",
    "        train_data,\n",
    "        3000000,\n",
    "        valid_sets=[train_data, valid_data],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    \n",
    "    # Predict valid\n",
    "    valid_pred = np.expand_dims(model.predict(out_taipei_X_train.iloc[val_index], num_iteration=model.best_iteration), -1)\n",
    "    valid_pred = y_scale.inverse_transform(valid_pred)\n",
    "    out_taipei_valid_preds.append(np.expm1(valid_pred))\n",
    "    # Predict test\n",
    "    pred = np.expand_dims(model.predict(out_taipei_X_test, num_iteration=model.best_iteration), -1)\n",
    "    pred = y_scale.inverse_transform(pred)\n",
    "    out_taipei_test_preds.append(np.expm1(pred))\n",
    "        \n",
    "    #Y_valid_predict = model.predict(out_taipei_X_train.iloc[val_index], num_iteration=model.best_iteration)\n",
    "    #Y_valid_predict = np.expm1(y_scale.inverse_transform(np.expand_dims(Y_valid_predict, -1)))\n",
    "    #Y_valid = np.expm1(y_scale.inverse_transform(out_taipei_Y_train.iloc[val_index]))\n",
    "    #metric(Y_valid, Y_valid_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_taipei_y_valid = np.squeeze(np.concatenate(out_taipei_valid_preds, axis=0)) * offset[~train_greater_taipei_bool]\n",
    "out_taipei_y_test = np.squeeze(np.mean(out_taipei_test_preds, axis=0)) * test.loc[~test_greater_taipei_bool, 'building_area'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = np.zeros(len(X_train))\n",
    "y_valid[train_greater_taipei_bool] = in_taipei_y_valid\n",
    "y_valid[~train_greater_taipei_bool] = out_taipei_y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  662192.22415542,  3116298.84052955,  9683504.714471  , ...,\n",
       "       12468510.33563988, 16654874.52168291,  8134810.48408049])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.DataFrame(y_valid, columns=[\"total_price\"])\n",
    "valid_df.to_csv(\"valid_prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.zeros(len(test))\n",
    "y_test[test_greater_taipei_bool] = in_taipei_y_test\n",
    "y_test[~test_greater_taipei_bool] = out_taipei_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10569765.65295199,  3871415.94826811, 10861397.96920879, ...,\n",
       "        1105961.71842607,  3073177.54404006,  2989690.15574406])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"../input/dataset-0510/submit_test.csv\")\n",
    "\n",
    "with open(\"sample_submission.csv\", \"w\") as f:\n",
    "    f.write('building_id,total_price\\n')\n",
    "    for _id, label in zip(submit[\"building_id\"], y_test):\n",
    "        f.write(_id + ',' + str(label) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
