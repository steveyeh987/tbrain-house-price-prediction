{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Input, Embedding, concatenate, Flatten, Activation, Dropout, Lambda, add, multiply\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_null(df):\n",
    "    missing = df.isnull().sum()\n",
    "    print('Show #missing in the columns:')\n",
    "    for i in range(df.shape[1]):\n",
    "        if missing[i]:\n",
    "            print(missing.index[i], ':', missing[i])\n",
    "\n",
    "def metric(truth, pred):\n",
    "    truth = np.array(truth)\n",
    "    pred = np.array(pred)\n",
    "    diff = abs(pred - truth) / truth\n",
    "    print(list(diff <= 0.1).count(True) / len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/dataset-0510/train.csv\")\n",
    "test = pd.read_csv(\"../input/dataset-0510/test.csv\")\n",
    "\n",
    "#train = train[train[\"total_price\"] < 1.5e8]\n",
    "price_sq = train[\"total_price\"] / train[\"building_area\"]\n",
    "train = train[(price_sq<12000000) & (price_sq>60000)]\n",
    "\n",
    "#Y_train = train[[\"total_price\"]]\n",
    "#offset = Y_train.min()\n",
    "#Y_train = Y_train / offset\n",
    "Y_train = train[\"total_price\"] / train[\"building_area\"]\n",
    "Y_train = np.expand_dims(np.log1p(Y_train), -1)\n",
    "y_scale = StandardScaler()\n",
    "Y_train = y_scale.fit_transform(Y_train)\n",
    "\n",
    "offset = train[\"building_area\"].values\n",
    "train_greater_taipei_bool = train['city'].isin([7, 9, 13])\n",
    "test_greater_taipei_bool = test['city'].isin([7, 9, 13])\n",
    "\n",
    "train = train.drop('total_price', 1)\n",
    "data = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show #missing in the columns:\n",
      "parking_area : 66266\n",
      "parking_price : 53672\n",
      "txn_floor : 18455\n",
      "village_income_median : 1317\n"
     ]
    }
   ],
   "source": [
    "num_null(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[data[\"parking_way\"] == 2, 'parking_area'] = data.loc[data[\"parking_way\"] == 2, 'parking_area'].fillna(0.0)\n",
    "data.loc[data[\"parking_way\"] != 2, 'parking_area'] = data.loc[data[\"parking_way\"] != 2, 'parking_area'].fillna(data.loc[data[\"parking_way\"] != 2, 'parking_area'].median())\n",
    "data.loc[data[\"parking_way\"] == 2, 'parking_price'] = data.loc[data[\"parking_way\"] == 2, 'parking_price'].fillna(0.0)\n",
    "data.loc[data[\"parking_way\"] != 2, 'parking_price'] = data.loc[data[\"parking_way\"] != 2, 'parking_price'].fillna(data.loc[data[\"parking_way\"] != 2, 'parking_price'].median())\n",
    "data['txn_floor'] = data['txn_floor'].fillna(1)\n",
    "data['village_income_median'] = data['village_income_median'].fillna(round(data.groupby(['city','town','village'])['village_income_median'].transform('mean')))\n",
    "data['village_income_median'] = data['village_income_median'].fillna(round(data.groupby(['city','town'])['village_income_median'].transform('mean')))\n",
    "data['village_income_median'] = data['village_income_median'].fillna(round(data.groupby(['city'])['village_income_median'].transform('mean')))\n",
    "data[\"floor_ratio\"] = data[\"txn_floor\"] / data[\"total_floor\"]\n",
    "data.loc[data['land_area']==0, 'land_area'] = data['land_area'].median()\n",
    "data[\"floor_area_ratio\"] = data[\"building_area\"] / data[\"land_area\"]\n",
    "data[\"have_parking\"] = (data[\"parking_way\"] != 2) * 1.0\n",
    "data[\"have_parking\"] = data[\"have_parking\"].astype(int)\n",
    "\n",
    "cat_data = data[[\"town\", \"village\", \"txn_floor\", \"building_material\", \"city\", \"building_type\", \"building_use\", \"parking_way\"]].astype(str)\n",
    "cat_data['village'] = cat_data[\"city\"] + \"_\" + cat_data[\"town\"] + \"_\" + cat_data[\"village\"]\n",
    "#cat_data[\"city_town\"] = cat_data[\"city\"] + \"_\" + cat_data[\"town\"]\n",
    "cat_data[\"city_town_building_type_use\"] = cat_data[\"city\"] + \"_\" + cat_data[\"town\"] + \"_\" + cat_data[\"building_type\"] + \"_\" + cat_data[\"building_use\"]\n",
    "#cat_data[\"parking_way_building_type\"] = cat_data[\"parking_way\"] + \"_\" + cat_data[\"building_type\"]\n",
    "cat_data[\"building_material_building_use\"] = cat_data[\"building_material\"] + \"_\" + cat_data[\"building_use\"]\n",
    "#cat_data[\"building_material_parking_way\"] = cat_data[\"building_material\"] + \"_\" + cat_data[\"parking_way\"]\n",
    "\n",
    "#cat_data[\"txn_dt\"] = data[\"txn_dt\"] // 365\n",
    "#cat_data[\"building_complete_dt\"] = data[\"building_complete_dt\"] // 365\n",
    "data[\"txn_duration\"] = (data[\"txn_dt\"] - data[\"building_complete_dt\"]) / 365\n",
    "#cat_data[\"building_type_txn_duration\"] = cat_data[\"building_type\"] + \"_\" + data[\"txn_duration\"].astype(str)\n",
    "#cat_data[\"building_use_txn_duration\"] = cat_data[\"building_use\"] + \"_\" + data[\"txn_duration\"].astype(str) \n",
    "\n",
    "cat_data = cat_data.apply(LabelEncoder().fit_transform)\n",
    "#cat_cols = [col for col in data.columns if data[col].dtype == np.object]\n",
    "#data = data.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show #missing in the columns:\n"
     ]
    }
   ],
   "source": [
    "num_null(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor index in [\\'I\\', \\'II\\', \\'III\\', \\'IV\\', \\'V\\', \\'VI\\', \\'VII\\',\\'VIII\\',\\'IX\\',\\'X\\', \\'XI\\', \\'XII\\', \\'XIII\\', \\'XIV\\']:\\n    data[\\'{}_index_100\\'.format(index)] = np.sign(data[\\'{}_100\\'.format(index)])\\ncorr_features = [\\'I_index_100\\', \\'II_index_100\\', \\'III_index_100\\', \\'IV_index_100\\', \\'V_index_100\\', \\'VI_index_100\\', \\'VII_index_100\\', \\'VIII_index_100\\',\\n                \\'IX_index_100\\', \\'X_index_100\\', \\'XI_index_100\\', \\'XII_index_100\\', \\'XIII_index_100\\', \\'XIV_index_100\\']\\npoly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\\ndata_poly = poly.fit_transform(data[corr_features])\\ndata_poly_df = pd.DataFrame(data_poly, columns=poly.get_feature_names(corr_features))\\ndata_poly_df.columns = data_poly_df.columns.str.replace(\" \", \"_\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for index in ['I', 'II', 'III', 'IV', 'V', 'VI', 'VII','VIII','IX','X', 'XI', 'XII', 'XIII', 'XIV']:\n",
    "    data['{}_index_100'.format(index)] = np.sign(data['{}_100'.format(index)])\n",
    "corr_features = ['I_index_100', 'II_index_100', 'III_index_100', 'IV_index_100', 'V_index_100', 'VI_index_100', 'VII_index_100', 'VIII_index_100',\n",
    "                'IX_index_100', 'X_index_100', 'XI_index_100', 'XII_index_100', 'XIII_index_100', 'XIV_index_100']\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "data_poly = poly.fit_transform(data[corr_features])\n",
    "data_poly_df = pd.DataFrame(data_poly, columns=poly.get_feature_names(corr_features))\n",
    "data_poly_df.columns = data_poly_df.columns.str.replace(\" \", \"_\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "town                               214\n",
       "village                           4314\n",
       "txn_floor                           28\n",
       "building_material                    9\n",
       "city                                11\n",
       "building_type                        5\n",
       "building_use                        10\n",
       "parking_way                          3\n",
       "city_town_building_type_use       2082\n",
       "building_material_building_use      48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 skewed numerical features to log transform\n"
     ]
    }
   ],
   "source": [
    "#dummy_columns = ['txn_floor', 'building_material', 'city', 'building_type', 'building_use', 'parking_way', 'building_material_building_use']\n",
    "#dummy = pd.get_dummies(cat_data[dummy_columns], columns=dummy_columns)\n",
    "#cat_data = cat_data.drop(dummy_columns, 1)\n",
    "\n",
    "cont_data = data.drop([\"building_id\", \n",
    "                       \"town\", \"village\", \"txn_floor\", \"building_material\", \"city\", \"building_type\", \"building_use\", \"parking_way\"], 1)\n",
    "\n",
    "#cont_data = pd.concat([cont_data, dummy], axis=1, join_axes=[cont_data.index])\n",
    "\n",
    "skewness = cont_data.apply(lambda x: skew(x))\n",
    "skewness = skewness[abs(skewness) > 1.5]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n",
    "\n",
    "skewed_features = skewness.index\n",
    "cont_data[skewed_features] = np.log1p(cont_data[skewed_features])\n",
    "\n",
    "scale = StandardScaler()\n",
    "cont_data = pd.DataFrame(scale.fit_transform(cont_data.values), columns=cont_data.columns, index=cont_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "town                               214\n",
       "village                           4314\n",
       "txn_floor                           28\n",
       "building_material                    9\n",
       "city                                11\n",
       "building_type                        5\n",
       "building_use                        10\n",
       "parking_way                          3\n",
       "city_town_building_type_use       2082\n",
       "building_material_building_use      48\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features = ['IX_1000', 'I_1000', 'IV_500', 'XI_1000', 'txn_dt', 'I_5000', 'V_10000', 'VII_500', 'XII_10000', 'lat', 'VI_MIN', 'VIII_1000', 'V_500', 'IV_1000', 'II_250', 'XIV_10000', 'VII_MIN', 'XI_250', 'XII_1000', 'X_MIN', 'jobschool_rate', 'XIV_100', 'floor_ratio', 'VII_5000', 'VI_5000', 'III_5000', 'X_500', 'X_250', 'VI_10000', 'village_income_median', 'VIII_10000', 'II_MIN', 'IX_10000', 'parking_price', 'XII_MIN', 'master_rate', 'lon', 'IV_10000', 'VII_10000', 'VII_1000', 'X_10000', 'II_10000', 'txn_duration', 'town_population_density', 'XIV_MIN', 'V_5000', 'IX_5000', 'VIII_100', 'XIV_250', 'XIII_5000', 'building_area', 'XIV_1000', 'floor_area_ratio', 'town_population', 'IX_MIN', 'parking_area', 'II_1000', 'III_1000', 'XII_5000', 'III_10000', 'III_500', 'II_500', 'IV_MIN', 'XI_MIN', 'I_MIN', 'town_area', 'XIII_500', 'V_250', 'XI_10000', 'total_floor', 'bachelor_rate', 'X_5000', 'IX_500', 'V_MIN', 'VIII_5000', 'I_500', 'IX_250', 'II_5000', 'XIII_1000', 'XI_500', 'doc_rate', 'III_250', 'VIII_250', 'I_10000', 'XII_250', 'X_1000', 'XIII_MIN', 'VII_250', 'VIII_MIN', 'XIV_5000', 'III_MIN', 'XIII_10000', 'V_1000', 'VIII_500', 'IV_5000', 'building_complete_dt', 'land_area', 'XI_5000', 'VI_1000', 'XIV_500', 'XII_500', 'XII_100', 'N_50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cont_train = cont_data[selected_features].iloc[:-10000].values\n",
    "cat_train = cat_data.iloc[:-10000].values\n",
    "cont_test = cont_data[selected_features].iloc[-10000:].values\n",
    "cat_test = cat_data.iloc[-10000:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Latent Cross**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dnn_model():\n",
    "    # create model\n",
    "    cont_inputs = Input(shape=(cont_train.shape[1],))\n",
    "\n",
    "    cat_inputs = []\n",
    "    cat_embeds = []\n",
    "    for i in range(cat_train.shape[1]):\n",
    "        input_i = Input(shape=(1,))\n",
    "        dim = len(set(cat_data.iloc[:, i]))\n",
    "        embed_i = Embedding(dim, 512, input_length=1, embeddings_initializer='glorot_normal')(input_i)\n",
    "        flatten_i = Flatten()(embed_i)\n",
    "        cat_inputs.append(input_i)\n",
    "        cat_embeds.append(flatten_i)\n",
    "\n",
    "    cont_dense = Dense(512, use_bias=False)(cont_inputs)\n",
    "    cat_dense = add(cat_embeds)\n",
    "    cat_dense = Lambda(lambda x: x + 1)(cat_dense)\n",
    "    inputs = multiply([cat_dense, cont_dense])\n",
    "    #inputs = concatenate([cont_inputs] + cat_embeds)\n",
    "    #inputs = Dropout(0.2)(inputs)\n",
    "    x = Dense(4096)(inputs)\n",
    "    x = PReLU()(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "    x = Dense(2048)(x)\n",
    "    x = PReLU()(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "    x = Dense(1024)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = PReLU()(x)\n",
    "    x = Dense(256)(x)\n",
    "    x = PReLU()(x)\n",
    "    #x = Dropout(0.3)(x)\n",
    "    #x = concatenate([x, cat_embeds[5], cat_embeds[6]])\n",
    "    predictions = Dense(1)(x)\n",
    "    model = Model(inputs=[cont_inputs] + cat_inputs, outputs=predictions)\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cont_X_train, cont_X_valid, cat_X_train, cat_X_valid, y_train, y_valid = train_test_split(cont_train[~train_greater_taipei_bool.values], \n",
    "#                                                                                          cat_train[~train_greater_taipei_bool.values], \n",
    "#                                                                                          Y_train[~train_greater_taipei_bool.values], test_size = 0.2, random_state = 42)\n",
    "#X_train = [cont_X_train] + [np.expand_dims(cat_X_train[:, i], -1)  for i in range(cat_train.shape[1])]\n",
    "#X_valid = [cont_X_valid] + [np.expand_dims(cat_X_valid[:, i], -1)  for i in range(cat_train.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_taipei_cont_train = cont_train[train_greater_taipei_bool.values]\n",
    "in_taipei_cat_train = cat_train[train_greater_taipei_bool.values]\n",
    "in_taipei_Y_train = Y_train[train_greater_taipei_bool.values]\n",
    "\n",
    "in_taipei_cont_test = cont_test[test_greater_taipei_bool.values]\n",
    "in_taipei_cat_test = cat_test[test_greater_taipei_bool.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Fold 1\n",
      "--------------------\n",
      "Train on 26982 samples, validate on 4498 samples\n",
      "Epoch 1/200000\n",
      "26982/26982 [==============================] - 8s 285us/step - loss: 0.2208 - mean_squared_error: 0.0934 - val_loss: 0.1843 - val_mean_squared_error: 0.0649\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18431, saving model to model.h5\n",
      "Epoch 2/200000\n",
      "26982/26982 [==============================] - 4s 136us/step - loss: 0.1682 - mean_squared_error: 0.0565 - val_loss: 0.1710 - val_mean_squared_error: 0.0579\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18431 to 0.17101, saving model to model.h5\n",
      "Epoch 3/200000\n",
      "26982/26982 [==============================] - 4s 144us/step - loss: 0.1470 - mean_squared_error: 0.0451 - val_loss: 0.1491 - val_mean_squared_error: 0.0468\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.17101 to 0.14911, saving model to model.h5\n",
      "Epoch 4/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.1337 - mean_squared_error: 0.0391 - val_loss: 0.1402 - val_mean_squared_error: 0.0425\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.14911 to 0.14018, saving model to model.h5\n",
      "Epoch 5/200000\n",
      "26982/26982 [==============================] - 4s 142us/step - loss: 0.1271 - mean_squared_error: 0.0358 - val_loss: 0.1585 - val_mean_squared_error: 0.0518\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.14018\n",
      "Epoch 6/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.1181 - mean_squared_error: 0.0318 - val_loss: 0.1375 - val_mean_squared_error: 0.0405\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14018 to 0.13751, saving model to model.h5\n",
      "Epoch 7/200000\n",
      "26982/26982 [==============================] - 4s 131us/step - loss: 0.1152 - mean_squared_error: 0.0303 - val_loss: 0.1427 - val_mean_squared_error: 0.0423\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13751\n",
      "Epoch 8/200000\n",
      "26982/26982 [==============================] - 4s 143us/step - loss: 0.1103 - mean_squared_error: 0.0283 - val_loss: 0.1324 - val_mean_squared_error: 0.0382\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.13751 to 0.13243, saving model to model.h5\n",
      "Epoch 9/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.1067 - mean_squared_error: 0.0267 - val_loss: 0.1424 - val_mean_squared_error: 0.0406\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13243\n",
      "Epoch 10/200000\n",
      "26982/26982 [==============================] - 4s 140us/step - loss: 0.1026 - mean_squared_error: 0.0251 - val_loss: 0.1281 - val_mean_squared_error: 0.0359\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.13243 to 0.12815, saving model to model.h5\n",
      "Epoch 11/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0962 - mean_squared_error: 0.0221 - val_loss: 0.1281 - val_mean_squared_error: 0.0359\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.12815 to 0.12808, saving model to model.h5\n",
      "Epoch 12/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0950 - mean_squared_error: 0.0219 - val_loss: 0.1249 - val_mean_squared_error: 0.0340\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.12808 to 0.12494, saving model to model.h5\n",
      "Epoch 13/200000\n",
      "26982/26982 [==============================] - 4s 149us/step - loss: 0.0903 - mean_squared_error: 0.0203 - val_loss: 0.1253 - val_mean_squared_error: 0.0340\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.12494\n",
      "Epoch 14/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0876 - mean_squared_error: 0.0191 - val_loss: 0.1230 - val_mean_squared_error: 0.0338\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.12494 to 0.12301, saving model to model.h5\n",
      "Epoch 15/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0841 - mean_squared_error: 0.0178 - val_loss: 0.1242 - val_mean_squared_error: 0.0341\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.12301\n",
      "Epoch 16/200000\n",
      "26982/26982 [==============================] - 4s 142us/step - loss: 0.0820 - mean_squared_error: 0.0170 - val_loss: 0.1254 - val_mean_squared_error: 0.0347\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.12301\n",
      "Epoch 17/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0785 - mean_squared_error: 0.0159 - val_loss: 0.1256 - val_mean_squared_error: 0.0343\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.12301\n",
      "Epoch 18/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0773 - mean_squared_error: 0.0153 - val_loss: 0.1224 - val_mean_squared_error: 0.0325\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.12301 to 0.12235, saving model to model.h5\n",
      "Epoch 19/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0752 - mean_squared_error: 0.0148 - val_loss: 0.1211 - val_mean_squared_error: 0.0321\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.12235 to 0.12107, saving model to model.h5\n",
      "Epoch 20/200000\n",
      "26982/26982 [==============================] - 4s 143us/step - loss: 0.0736 - mean_squared_error: 0.0141 - val_loss: 0.1228 - val_mean_squared_error: 0.0330\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.12107\n",
      "Epoch 21/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0712 - mean_squared_error: 0.0133 - val_loss: 0.1202 - val_mean_squared_error: 0.0321\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.12107 to 0.12020, saving model to model.h5\n",
      "Epoch 22/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0685 - mean_squared_error: 0.0124 - val_loss: 0.1185 - val_mean_squared_error: 0.0317\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.12020 to 0.11847, saving model to model.h5\n",
      "Epoch 23/200000\n",
      "26982/26982 [==============================] - 4s 142us/step - loss: 0.0683 - mean_squared_error: 0.0123 - val_loss: 0.1195 - val_mean_squared_error: 0.0316\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.11847\n",
      "Epoch 24/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0668 - mean_squared_error: 0.0118 - val_loss: 0.1182 - val_mean_squared_error: 0.0309\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.11847 to 0.11819, saving model to model.h5\n",
      "Epoch 25/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0649 - mean_squared_error: 0.0113 - val_loss: 0.1245 - val_mean_squared_error: 0.0340\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.11819\n",
      "Epoch 26/200000\n",
      "26982/26982 [==============================] - 4s 143us/step - loss: 0.0626 - mean_squared_error: 0.0106 - val_loss: 0.1165 - val_mean_squared_error: 0.0307\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.11819 to 0.11652, saving model to model.h5\n",
      "Epoch 27/200000\n",
      "26982/26982 [==============================] - 4s 137us/step - loss: 0.0616 - mean_squared_error: 0.0103 - val_loss: 0.1186 - val_mean_squared_error: 0.0311\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.11652\n",
      "Epoch 28/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0601 - mean_squared_error: 0.0099 - val_loss: 0.1166 - val_mean_squared_error: 0.0306\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.11652\n",
      "Epoch 29/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0584 - mean_squared_error: 0.0095 - val_loss: 0.1167 - val_mean_squared_error: 0.0306\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.11652\n",
      "Epoch 30/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0580 - mean_squared_error: 0.0092 - val_loss: 0.1168 - val_mean_squared_error: 0.0308\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.11652\n",
      "Epoch 31/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0552 - mean_squared_error: 0.0087 - val_loss: 0.1151 - val_mean_squared_error: 0.0302\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.11652 to 0.11508, saving model to model.h5\n",
      "Epoch 32/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0550 - mean_squared_error: 0.0085 - val_loss: 0.1173 - val_mean_squared_error: 0.0304\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.11508\n",
      "Epoch 33/200000\n",
      "26982/26982 [==============================] - 4s 145us/step - loss: 0.0546 - mean_squared_error: 0.0083 - val_loss: 0.1146 - val_mean_squared_error: 0.0297\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.11508 to 0.11457, saving model to model.h5\n",
      "Epoch 34/200000\n",
      "26982/26982 [==============================] - 4s 144us/step - loss: 0.0537 - mean_squared_error: 0.0081 - val_loss: 0.1174 - val_mean_squared_error: 0.0305\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.11457\n",
      "Epoch 35/200000\n",
      "26982/26982 [==============================] - 4s 156us/step - loss: 0.0530 - mean_squared_error: 0.0078 - val_loss: 0.1144 - val_mean_squared_error: 0.0297\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.11457 to 0.11441, saving model to model.h5\n",
      "Epoch 36/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0517 - mean_squared_error: 0.0075 - val_loss: 0.1154 - val_mean_squared_error: 0.0300\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11441\n",
      "Epoch 37/200000\n",
      "26982/26982 [==============================] - 4s 144us/step - loss: 0.0503 - mean_squared_error: 0.0072 - val_loss: 0.1160 - val_mean_squared_error: 0.0308\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11441\n",
      "Epoch 38/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0500 - mean_squared_error: 0.0071 - val_loss: 0.1137 - val_mean_squared_error: 0.0291\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.11441 to 0.11374, saving model to model.h5\n",
      "Epoch 39/200000\n",
      "26982/26982 [==============================] - 4s 137us/step - loss: 0.0488 - mean_squared_error: 0.0068 - val_loss: 0.1143 - val_mean_squared_error: 0.0298\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11374\n",
      "Epoch 40/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0493 - mean_squared_error: 0.0069 - val_loss: 0.1154 - val_mean_squared_error: 0.0306\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11374\n",
      "Epoch 41/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0478 - mean_squared_error: 0.0064 - val_loss: 0.1141 - val_mean_squared_error: 0.0304\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.11374\n",
      "Epoch 42/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0464 - mean_squared_error: 0.0062 - val_loss: 0.1138 - val_mean_squared_error: 0.0294\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.11374\n",
      "Epoch 43/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0463 - mean_squared_error: 0.0062 - val_loss: 0.1143 - val_mean_squared_error: 0.0300\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.11374\n",
      "Epoch 44/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0454 - mean_squared_error: 0.0059 - val_loss: 0.1150 - val_mean_squared_error: 0.0297\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.11374\n",
      "Epoch 45/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0463 - mean_squared_error: 0.0060 - val_loss: 0.1140 - val_mean_squared_error: 0.0295\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.11374\n",
      "Epoch 46/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0455 - mean_squared_error: 0.0058 - val_loss: 0.1134 - val_mean_squared_error: 0.0295\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.11374 to 0.11341, saving model to model.h5\n",
      "Epoch 47/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0446 - mean_squared_error: 0.0056 - val_loss: 0.1143 - val_mean_squared_error: 0.0301\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.11341\n",
      "Epoch 48/200000\n",
      "26982/26982 [==============================] - 4s 144us/step - loss: 0.0431 - mean_squared_error: 0.0054 - val_loss: 0.1139 - val_mean_squared_error: 0.0295\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.11341\n",
      "Epoch 49/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0425 - mean_squared_error: 0.0052 - val_loss: 0.1134 - val_mean_squared_error: 0.0291\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.11341 to 0.11336, saving model to model.h5\n",
      "Epoch 50/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0442 - mean_squared_error: 0.0055 - val_loss: 0.1143 - val_mean_squared_error: 0.0300\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.11336\n",
      "Epoch 51/200000\n",
      "26982/26982 [==============================] - 4s 144us/step - loss: 0.0431 - mean_squared_error: 0.0052 - val_loss: 0.1142 - val_mean_squared_error: 0.0302\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.11336\n",
      "Epoch 52/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0436 - mean_squared_error: 0.0053 - val_loss: 0.1132 - val_mean_squared_error: 0.0294\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.11336 to 0.11315, saving model to model.h5\n",
      "Epoch 53/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0411 - mean_squared_error: 0.0049 - val_loss: 0.1121 - val_mean_squared_error: 0.0291\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.11315 to 0.11205, saving model to model.h5\n",
      "Epoch 54/200000\n",
      "26982/26982 [==============================] - 4s 144us/step - loss: 0.0406 - mean_squared_error: 0.0047 - val_loss: 0.1130 - val_mean_squared_error: 0.0295\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.11205\n",
      "Epoch 55/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0401 - mean_squared_error: 0.0046 - val_loss: 0.1149 - val_mean_squared_error: 0.0302\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.11205\n",
      "Epoch 56/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0392 - mean_squared_error: 0.0045 - val_loss: 0.1122 - val_mean_squared_error: 0.0289\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.11205\n",
      "Epoch 57/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0398 - mean_squared_error: 0.0045 - val_loss: 0.1127 - val_mean_squared_error: 0.0294\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.11205\n",
      "Epoch 58/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0385 - mean_squared_error: 0.0043 - val_loss: 0.1140 - val_mean_squared_error: 0.0299\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.11205\n",
      "Epoch 59/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0375 - mean_squared_error: 0.0041 - val_loss: 0.1134 - val_mean_squared_error: 0.0294\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.11205\n",
      "Epoch 60/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0385 - mean_squared_error: 0.0042 - val_loss: 0.1119 - val_mean_squared_error: 0.0287\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.11205 to 0.11186, saving model to model.h5\n",
      "Epoch 61/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0391 - mean_squared_error: 0.0042 - val_loss: 0.1123 - val_mean_squared_error: 0.0292\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.11186\n",
      "Epoch 62/200000\n",
      "26982/26982 [==============================] - 4s 142us/step - loss: 0.0372 - mean_squared_error: 0.0039 - val_loss: 0.1122 - val_mean_squared_error: 0.0292\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.11186\n",
      "Epoch 63/200000\n",
      "26982/26982 [==============================] - 4s 131us/step - loss: 0.0364 - mean_squared_error: 0.0038 - val_loss: 0.1130 - val_mean_squared_error: 0.0296\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.11186\n",
      "Epoch 64/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0365 - mean_squared_error: 0.0039 - val_loss: 0.1117 - val_mean_squared_error: 0.0290\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.11186 to 0.11173, saving model to model.h5\n",
      "Epoch 65/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0361 - mean_squared_error: 0.0037 - val_loss: 0.1198 - val_mean_squared_error: 0.0315\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.11173\n",
      "Epoch 66/200000\n",
      "26982/26982 [==============================] - 4s 143us/step - loss: 0.0361 - mean_squared_error: 0.0037 - val_loss: 0.1132 - val_mean_squared_error: 0.0299\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.11173\n",
      "Epoch 67/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0361 - mean_squared_error: 0.0037 - val_loss: 0.1124 - val_mean_squared_error: 0.0292\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.11173\n",
      "Epoch 68/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0357 - mean_squared_error: 0.0036 - val_loss: 0.1117 - val_mean_squared_error: 0.0286\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.11173\n",
      "Epoch 69/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0361 - mean_squared_error: 0.0036 - val_loss: 0.1116 - val_mean_squared_error: 0.0287\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.11173 to 0.11156, saving model to model.h5\n",
      "Epoch 70/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0356 - mean_squared_error: 0.0035 - val_loss: 0.1154 - val_mean_squared_error: 0.0301\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.11156\n",
      "Epoch 71/200000\n",
      "26982/26982 [==============================] - 4s 141us/step - loss: 0.0346 - mean_squared_error: 0.0034 - val_loss: 0.1123 - val_mean_squared_error: 0.0287\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.11156\n",
      "Epoch 72/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0343 - mean_squared_error: 0.0033 - val_loss: 0.1130 - val_mean_squared_error: 0.0294\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.11156\n",
      "Epoch 73/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0350 - mean_squared_error: 0.0033 - val_loss: 0.1142 - val_mean_squared_error: 0.0305\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.11156\n",
      "Epoch 74/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0337 - mean_squared_error: 0.0032 - val_loss: 0.1121 - val_mean_squared_error: 0.0296\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.11156\n",
      "Epoch 75/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0337 - mean_squared_error: 0.0032 - val_loss: 0.1119 - val_mean_squared_error: 0.0291\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.11156\n",
      "Epoch 76/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0332 - mean_squared_error: 0.0031 - val_loss: 0.1123 - val_mean_squared_error: 0.0293\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.11156\n",
      "Epoch 77/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0333 - mean_squared_error: 0.0031 - val_loss: 0.1107 - val_mean_squared_error: 0.0291\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.11156 to 0.11074, saving model to model.h5\n",
      "Epoch 78/200000\n",
      "26982/26982 [==============================] - 4s 140us/step - loss: 0.0334 - mean_squared_error: 0.0031 - val_loss: 0.1117 - val_mean_squared_error: 0.0292\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.11074\n",
      "Epoch 79/200000\n",
      "26982/26982 [==============================] - 4s 136us/step - loss: 0.0324 - mean_squared_error: 0.0030 - val_loss: 0.1132 - val_mean_squared_error: 0.0293\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.11074\n",
      "Epoch 80/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0324 - mean_squared_error: 0.0029 - val_loss: 0.1136 - val_mean_squared_error: 0.0297\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.11074\n",
      "Epoch 81/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0319 - mean_squared_error: 0.0029 - val_loss: 0.1121 - val_mean_squared_error: 0.0292\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.11074\n",
      "Epoch 82/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0321 - mean_squared_error: 0.0028 - val_loss: 0.1125 - val_mean_squared_error: 0.0294\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.11074\n",
      "Epoch 83/200000\n",
      "26982/26982 [==============================] - 4s 136us/step - loss: 0.0315 - mean_squared_error: 0.0028 - val_loss: 0.1120 - val_mean_squared_error: 0.0292\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.11074\n",
      "Epoch 84/200000\n",
      "26982/26982 [==============================] - 4s 135us/step - loss: 0.0316 - mean_squared_error: 0.0028 - val_loss: 0.1112 - val_mean_squared_error: 0.0292\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.11074\n",
      "Epoch 85/200000\n",
      "26982/26982 [==============================] - 4s 134us/step - loss: 0.0314 - mean_squared_error: 0.0027 - val_loss: 0.1118 - val_mean_squared_error: 0.0289\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.11074\n",
      "Epoch 86/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0311 - mean_squared_error: 0.0027 - val_loss: 0.1108 - val_mean_squared_error: 0.0291\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.11074\n",
      "Epoch 87/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0317 - mean_squared_error: 0.0027 - val_loss: 0.1111 - val_mean_squared_error: 0.0288\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.11074\n",
      "Epoch 88/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0308 - mean_squared_error: 0.0026 - val_loss: 0.1113 - val_mean_squared_error: 0.0290\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.11074\n",
      "Epoch 89/200000\n",
      "26982/26982 [==============================] - 4s 131us/step - loss: 0.0303 - mean_squared_error: 0.0025 - val_loss: 0.1107 - val_mean_squared_error: 0.0287\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.11074 to 0.11066, saving model to model.h5\n",
      "Epoch 90/200000\n",
      "26982/26982 [==============================] - 4s 133us/step - loss: 0.0298 - mean_squared_error: 0.0025 - val_loss: 0.1112 - val_mean_squared_error: 0.0289\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.11066\n",
      "Epoch 91/200000\n",
      "26982/26982 [==============================] - 4s 141us/step - loss: 0.0296 - mean_squared_error: 0.0024 - val_loss: 0.1101 - val_mean_squared_error: 0.0288\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.11066 to 0.11013, saving model to model.h5\n",
      "Epoch 92/200000\n",
      "26982/26982 [==============================] - 4s 132us/step - loss: 0.0297 - mean_squared_error: 0.0024 - val_loss: 0.1100 - val_mean_squared_error: 0.0288\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.11013 to 0.10995, saving model to model.h5\n",
      "Epoch 93/200000\n",
      "26982/26982 [==============================] - 4s 140us/step - loss: 0.0298 - mean_squared_error: 0.0024 - val_loss: 0.1098 - val_mean_squared_error: 0.0284\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.10995 to 0.10980, saving model to model.h5\n",
      "Epoch 94/200000\n",
      " 7808/26982 [=======>......................] - ETA: 2s - loss: 0.0285 - mean_squared_error: 0.0020"
     ]
    }
   ],
   "source": [
    "in_taipei_valid_preds = []\n",
    "in_taipei_test_preds = []\n",
    "kf = KFold(n_splits=7, shuffle=False)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kf.split(in_taipei_cont_train)):\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Fold {i+1}\")\n",
    "    print(\"-\" * 20)\n",
    "    X_train = [in_taipei_cont_train[train_index]] + [np.expand_dims(in_taipei_cat_train[train_index, i], -1)  for i in range(cat_train.shape[1])]\n",
    "    y_train = in_taipei_Y_train[train_index]\n",
    "    X_valid = [in_taipei_cont_train[val_index]] + [np.expand_dims(in_taipei_cat_train[val_index, i], -1)  for i in range(cat_train.shape[1])]\n",
    "    y_valid = in_taipei_Y_train[val_index]\n",
    "\n",
    "    model = dnn_model()\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizers.Adam(0.0001), metrics=['mse'])\n",
    "    # checkpoint\n",
    "    filepath=\"model.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=2)\n",
    "    callbacks_list = [checkpoint, early_stopping]\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=200000, batch_size=128, validation_data=(X_valid, y_valid), callbacks=callbacks_list)\n",
    "    # Load best model\n",
    "    K.clear_session()\n",
    "    best_model = load_model(\"model.h5\")\n",
    "    # Predict valid\n",
    "    valid_pred = best_model.predict(X_valid)\n",
    "    valid_pred = y_scale.inverse_transform(valid_pred)\n",
    "    in_taipei_valid_preds.append(np.expm1(valid_pred))\n",
    "    # Predict test\n",
    "    pred = best_model.predict([in_taipei_cont_test] + [np.expand_dims(in_taipei_cat_test[:, i], -1)  for i in range(cat_train.shape[1])])\n",
    "    pred = y_scale.inverse_transform(pred)\n",
    "    in_taipei_test_preds.append(np.expm1(pred))\n",
    "\n",
    "    #Y_valid_predict = best_model.predict(X_valid)\n",
    "    #Y_valid_predict = np.floor(np.expm1(y_scale.inverse_transform(Y_valid_predict)))\n",
    "    #Y_valid = np.floor(np.expm1(y_scale.inverse_transform(y_valid)))\n",
    "    #metric(Y_valid, Y_valid_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_taipei_y_valid = np.squeeze(np.concatenate(in_taipei_valid_preds, axis=0)) * offset[train_greater_taipei_bool]\n",
    "in_taipei_y_test = np.squeeze(np.mean(in_taipei_test_preds, axis=0)) * test.loc[test_greater_taipei_bool, 'building_area'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_taipei_cont_train = cont_train[~train_greater_taipei_bool.values]\n",
    "out_taipei_cat_train = cat_train[~train_greater_taipei_bool.values]\n",
    "out_taipei_Y_train = Y_train[~train_greater_taipei_bool.values]\n",
    "\n",
    "out_taipei_cont_test = cont_test[~test_greater_taipei_bool.values]\n",
    "out_taipei_cat_test = cat_test[~test_greater_taipei_bool.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Fold 1\n",
      "--------------------\n",
      "Train on 24332 samples, validate on 4056 samples\n",
      "Epoch 1/200000\n",
      "24332/24332 [==============================] - 5s 217us/step - loss: 0.2764 - mean_squared_error: 0.1441 - val_loss: 0.2339 - val_mean_squared_error: 0.1028\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23385, saving model to model.h5\n",
      "Epoch 2/200000\n",
      "24332/24332 [==============================] - 3s 137us/step - loss: 0.2146 - mean_squared_error: 0.0855 - val_loss: 0.2063 - val_mean_squared_error: 0.0812\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23385 to 0.20631, saving model to model.h5\n",
      "Epoch 3/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.1924 - mean_squared_error: 0.0712 - val_loss: 0.1946 - val_mean_squared_error: 0.0737\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20631 to 0.19459, saving model to model.h5\n",
      "Epoch 4/200000\n",
      "24332/24332 [==============================] - 3s 141us/step - loss: 0.1782 - mean_squared_error: 0.0625 - val_loss: 0.2106 - val_mean_squared_error: 0.0829\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.19459\n",
      "Epoch 5/200000\n",
      "24332/24332 [==============================] - 3s 137us/step - loss: 0.1679 - mean_squared_error: 0.0564 - val_loss: 0.2013 - val_mean_squared_error: 0.0771\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.19459\n",
      "Epoch 6/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.1611 - mean_squared_error: 0.0521 - val_loss: 0.1879 - val_mean_squared_error: 0.0702\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19459 to 0.18791, saving model to model.h5\n",
      "Epoch 7/200000\n",
      "24332/24332 [==============================] - 3s 137us/step - loss: 0.1491 - mean_squared_error: 0.0458 - val_loss: 0.1930 - val_mean_squared_error: 0.0717\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.18791\n",
      "Epoch 8/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.1429 - mean_squared_error: 0.0423 - val_loss: 0.1900 - val_mean_squared_error: 0.0714\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.18791\n",
      "Epoch 9/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.1360 - mean_squared_error: 0.0388 - val_loss: 0.1842 - val_mean_squared_error: 0.0674\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.18791 to 0.18415, saving model to model.h5\n",
      "Epoch 10/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.1308 - mean_squared_error: 0.0360 - val_loss: 0.1823 - val_mean_squared_error: 0.0658\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.18415 to 0.18229, saving model to model.h5\n",
      "Epoch 11/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.1254 - mean_squared_error: 0.0332 - val_loss: 0.1808 - val_mean_squared_error: 0.0645\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.18229 to 0.18084, saving model to model.h5\n",
      "Epoch 12/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.1184 - mean_squared_error: 0.0305 - val_loss: 0.1751 - val_mean_squared_error: 0.0623\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18084 to 0.17510, saving model to model.h5\n",
      "Epoch 13/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.1156 - mean_squared_error: 0.0287 - val_loss: 0.1798 - val_mean_squared_error: 0.0629\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.17510\n",
      "Epoch 14/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.1110 - mean_squared_error: 0.0266 - val_loss: 0.1805 - val_mean_squared_error: 0.0642\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.17510\n",
      "Epoch 15/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.1057 - mean_squared_error: 0.0243 - val_loss: 0.1711 - val_mean_squared_error: 0.0604\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17510 to 0.17108, saving model to model.h5\n",
      "Epoch 16/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.1014 - mean_squared_error: 0.0224 - val_loss: 0.1739 - val_mean_squared_error: 0.0608\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.17108\n",
      "Epoch 17/200000\n",
      "24332/24332 [==============================] - 3s 142us/step - loss: 0.0980 - mean_squared_error: 0.0212 - val_loss: 0.1716 - val_mean_squared_error: 0.0601\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.17108\n",
      "Epoch 18/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0938 - mean_squared_error: 0.0194 - val_loss: 0.1724 - val_mean_squared_error: 0.0613\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.17108\n",
      "Epoch 19/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0917 - mean_squared_error: 0.0186 - val_loss: 0.1735 - val_mean_squared_error: 0.0608\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.17108\n",
      "Epoch 20/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0888 - mean_squared_error: 0.0175 - val_loss: 0.1746 - val_mean_squared_error: 0.0620\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.17108\n",
      "Epoch 21/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0865 - mean_squared_error: 0.0166 - val_loss: 0.1794 - val_mean_squared_error: 0.0646\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.17108\n",
      "Epoch 22/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0850 - mean_squared_error: 0.0159 - val_loss: 0.2027 - val_mean_squared_error: 0.0775\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.17108\n",
      "Epoch 23/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0858 - mean_squared_error: 0.0159 - val_loss: 0.1763 - val_mean_squared_error: 0.0625\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.17108\n",
      "Epoch 24/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0799 - mean_squared_error: 0.0141 - val_loss: 0.1693 - val_mean_squared_error: 0.0585\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.17108 to 0.16928, saving model to model.h5\n",
      "Epoch 25/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0775 - mean_squared_error: 0.0132 - val_loss: 0.1761 - val_mean_squared_error: 0.0635\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16928\n",
      "Epoch 26/200000\n",
      "24332/24332 [==============================] - 4s 144us/step - loss: 0.0752 - mean_squared_error: 0.0124 - val_loss: 0.1750 - val_mean_squared_error: 0.0627\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.16928\n",
      "Epoch 27/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0743 - mean_squared_error: 0.0120 - val_loss: 0.1697 - val_mean_squared_error: 0.0586\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.16928\n",
      "Epoch 28/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0737 - mean_squared_error: 0.0117 - val_loss: 0.1684 - val_mean_squared_error: 0.0584\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.16928 to 0.16845, saving model to model.h5\n",
      "Epoch 29/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0694 - mean_squared_error: 0.0106 - val_loss: 0.1687 - val_mean_squared_error: 0.0586\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.16845\n",
      "Epoch 30/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.0702 - mean_squared_error: 0.0106 - val_loss: 0.1688 - val_mean_squared_error: 0.0592\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.16845\n",
      "Epoch 31/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0673 - mean_squared_error: 0.0098 - val_loss: 0.1732 - val_mean_squared_error: 0.0619\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.16845\n",
      "Epoch 32/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0656 - mean_squared_error: 0.0095 - val_loss: 0.1730 - val_mean_squared_error: 0.0610\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.16845\n",
      "Epoch 33/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0657 - mean_squared_error: 0.0093 - val_loss: 0.1691 - val_mean_squared_error: 0.0587\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.16845\n",
      "Epoch 34/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0641 - mean_squared_error: 0.0088 - val_loss: 0.1716 - val_mean_squared_error: 0.0604\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.16845\n",
      "Epoch 35/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0619 - mean_squared_error: 0.0083 - val_loss: 0.1673 - val_mean_squared_error: 0.0584\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.16845 to 0.16734, saving model to model.h5\n",
      "Epoch 36/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0599 - mean_squared_error: 0.0077 - val_loss: 0.1692 - val_mean_squared_error: 0.0598\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.16734\n",
      "Epoch 37/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.0596 - mean_squared_error: 0.0076 - val_loss: 0.1699 - val_mean_squared_error: 0.0600\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.16734\n",
      "Epoch 38/200000\n",
      "24332/24332 [==============================] - 4s 162us/step - loss: 0.0592 - mean_squared_error: 0.0075 - val_loss: 0.1715 - val_mean_squared_error: 0.0615\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.16734\n",
      "Epoch 39/200000\n",
      "24332/24332 [==============================] - 3s 137us/step - loss: 0.0580 - mean_squared_error: 0.0072 - val_loss: 0.1732 - val_mean_squared_error: 0.0614\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.16734\n",
      "Epoch 40/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0587 - mean_squared_error: 0.0073 - val_loss: 0.1672 - val_mean_squared_error: 0.0585\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.16734 to 0.16721, saving model to model.h5\n",
      "Epoch 41/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0582 - mean_squared_error: 0.0071 - val_loss: 0.1697 - val_mean_squared_error: 0.0604\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.16721\n",
      "Epoch 42/200000\n",
      "24332/24332 [==============================] - 3s 141us/step - loss: 0.0574 - mean_squared_error: 0.0069 - val_loss: 0.1683 - val_mean_squared_error: 0.0594\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.16721\n",
      "Epoch 43/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0558 - mean_squared_error: 0.0066 - val_loss: 0.1677 - val_mean_squared_error: 0.0588\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.16721\n",
      "Epoch 44/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0549 - mean_squared_error: 0.0063 - val_loss: 0.1680 - val_mean_squared_error: 0.0586\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.16721\n",
      "Epoch 45/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0525 - mean_squared_error: 0.0058 - val_loss: 0.1677 - val_mean_squared_error: 0.0586\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.16721\n",
      "Epoch 46/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0547 - mean_squared_error: 0.0062 - val_loss: 0.1740 - val_mean_squared_error: 0.0619\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.16721\n",
      "Epoch 47/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0527 - mean_squared_error: 0.0059 - val_loss: 0.1669 - val_mean_squared_error: 0.0580\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.16721 to 0.16690, saving model to model.h5\n",
      "Epoch 48/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0510 - mean_squared_error: 0.0055 - val_loss: 0.1673 - val_mean_squared_error: 0.0582\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.16690\n",
      "Epoch 49/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.0507 - mean_squared_error: 0.0054 - val_loss: 0.1681 - val_mean_squared_error: 0.0592\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.16690\n",
      "Epoch 50/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0503 - mean_squared_error: 0.0053 - val_loss: 0.1669 - val_mean_squared_error: 0.0588\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.16690\n",
      "Epoch 51/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0507 - mean_squared_error: 0.0053 - val_loss: 0.1651 - val_mean_squared_error: 0.0579\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.16690 to 0.16507, saving model to model.h5\n",
      "Epoch 52/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0483 - mean_squared_error: 0.0049 - val_loss: 0.1684 - val_mean_squared_error: 0.0601\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.16507\n",
      "Epoch 53/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.0506 - mean_squared_error: 0.0053 - val_loss: 0.1713 - val_mean_squared_error: 0.0602\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.16507\n",
      "Epoch 54/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0492 - mean_squared_error: 0.0050 - val_loss: 0.1652 - val_mean_squared_error: 0.0575\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.16507\n",
      "Epoch 55/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0465 - mean_squared_error: 0.0046 - val_loss: 0.1675 - val_mean_squared_error: 0.0590\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.16507\n",
      "Epoch 56/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0471 - mean_squared_error: 0.0046 - val_loss: 0.1668 - val_mean_squared_error: 0.0586\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.16507\n",
      "Epoch 57/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0456 - mean_squared_error: 0.0043 - val_loss: 0.1673 - val_mean_squared_error: 0.0591\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.16507\n",
      "Epoch 58/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0471 - mean_squared_error: 0.0045 - val_loss: 0.1688 - val_mean_squared_error: 0.0593\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.16507\n",
      "Epoch 59/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0456 - mean_squared_error: 0.0043 - val_loss: 0.1694 - val_mean_squared_error: 0.0594\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.16507\n",
      "Epoch 60/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0465 - mean_squared_error: 0.0044 - val_loss: 0.1687 - val_mean_squared_error: 0.0589\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.16507\n",
      "Epoch 61/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0460 - mean_squared_error: 0.0043 - val_loss: 0.1657 - val_mean_squared_error: 0.0577\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.16507\n",
      "Epoch 62/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0449 - mean_squared_error: 0.0041 - val_loss: 0.1671 - val_mean_squared_error: 0.0592\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.16507\n",
      "Epoch 63/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0440 - mean_squared_error: 0.0040 - val_loss: 0.1720 - val_mean_squared_error: 0.0607\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.16507\n",
      "Epoch 64/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0451 - mean_squared_error: 0.0041 - val_loss: 0.1644 - val_mean_squared_error: 0.0576\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.16507 to 0.16436, saving model to model.h5\n",
      "Epoch 65/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0419 - mean_squared_error: 0.0036 - val_loss: 0.1667 - val_mean_squared_error: 0.0586\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.16436\n",
      "Epoch 66/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.0438 - mean_squared_error: 0.0039 - val_loss: 0.1656 - val_mean_squared_error: 0.0585\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.16436\n",
      "Epoch 67/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0427 - mean_squared_error: 0.0037 - val_loss: 0.1687 - val_mean_squared_error: 0.0594\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.16436\n",
      "Epoch 68/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0418 - mean_squared_error: 0.0035 - val_loss: 0.1655 - val_mean_squared_error: 0.0583\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.16436\n",
      "Epoch 69/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0420 - mean_squared_error: 0.0036 - val_loss: 0.1674 - val_mean_squared_error: 0.0593\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.16436\n",
      "Epoch 70/200000\n",
      "24332/24332 [==============================] - 3s 133us/step - loss: 0.0409 - mean_squared_error: 0.0034 - val_loss: 0.1648 - val_mean_squared_error: 0.0580\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.16436\n",
      "Epoch 71/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0407 - mean_squared_error: 0.0034 - val_loss: 0.1690 - val_mean_squared_error: 0.0592\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.16436\n",
      "Epoch 72/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0419 - mean_squared_error: 0.0036 - val_loss: 0.1674 - val_mean_squared_error: 0.0596\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.16436\n",
      "Epoch 73/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0393 - mean_squared_error: 0.0032 - val_loss: 0.1652 - val_mean_squared_error: 0.0576\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.16436\n",
      "Epoch 74/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0402 - mean_squared_error: 0.0033 - val_loss: 0.1648 - val_mean_squared_error: 0.0580\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.16436\n",
      "Epoch 75/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0395 - mean_squared_error: 0.0031 - val_loss: 0.1656 - val_mean_squared_error: 0.0582\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.16436\n",
      "Epoch 76/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0387 - mean_squared_error: 0.0030 - val_loss: 0.1666 - val_mean_squared_error: 0.0594\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.16436\n",
      "Epoch 77/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0398 - mean_squared_error: 0.0032 - val_loss: 0.1690 - val_mean_squared_error: 0.0601\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.16436\n",
      "Epoch 78/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0396 - mean_squared_error: 0.0031 - val_loss: 0.1635 - val_mean_squared_error: 0.0577\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.16436 to 0.16355, saving model to model.h5\n",
      "Epoch 79/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0381 - mean_squared_error: 0.0030 - val_loss: 0.1644 - val_mean_squared_error: 0.0575\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.16355\n",
      "Epoch 80/200000\n",
      "24332/24332 [==============================] - 3s 141us/step - loss: 0.0396 - mean_squared_error: 0.0031 - val_loss: 0.1654 - val_mean_squared_error: 0.0582\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.16355\n",
      "Epoch 81/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0395 - mean_squared_error: 0.0031 - val_loss: 0.1634 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.16355 to 0.16338, saving model to model.h5\n",
      "Epoch 82/200000\n",
      "24332/24332 [==============================] - 3s 138us/step - loss: 0.0369 - mean_squared_error: 0.0027 - val_loss: 0.1642 - val_mean_squared_error: 0.0578\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.16338\n",
      "Epoch 83/200000\n",
      "24332/24332 [==============================] - 4s 146us/step - loss: 0.0380 - mean_squared_error: 0.0029 - val_loss: 0.1676 - val_mean_squared_error: 0.0592\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.16338\n",
      "Epoch 84/200000\n",
      "24332/24332 [==============================] - 3s 137us/step - loss: 0.0384 - mean_squared_error: 0.0030 - val_loss: 0.1665 - val_mean_squared_error: 0.0587\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.16338\n",
      "Epoch 85/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0373 - mean_squared_error: 0.0028 - val_loss: 0.1629 - val_mean_squared_error: 0.0577\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.16338 to 0.16289, saving model to model.h5\n",
      "Epoch 86/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0354 - mean_squared_error: 0.0026 - val_loss: 0.1653 - val_mean_squared_error: 0.0583\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.16289\n",
      "Epoch 87/200000\n",
      "24332/24332 [==============================] - 3s 140us/step - loss: 0.0364 - mean_squared_error: 0.0027 - val_loss: 0.1650 - val_mean_squared_error: 0.0575\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.16289\n",
      "Epoch 88/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0364 - mean_squared_error: 0.0026 - val_loss: 0.1668 - val_mean_squared_error: 0.0586\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.16289\n",
      "Epoch 89/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0359 - mean_squared_error: 0.0026 - val_loss: 0.1648 - val_mean_squared_error: 0.0581\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.16289\n",
      "Epoch 90/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0363 - mean_squared_error: 0.0026 - val_loss: 0.1700 - val_mean_squared_error: 0.0601\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.16289\n",
      "Epoch 91/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0361 - mean_squared_error: 0.0026 - val_loss: 0.1645 - val_mean_squared_error: 0.0584\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.16289\n",
      "Epoch 92/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0354 - mean_squared_error: 0.0025 - val_loss: 0.1647 - val_mean_squared_error: 0.0586\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.16289\n",
      "Epoch 93/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0356 - mean_squared_error: 0.0025 - val_loss: 0.1648 - val_mean_squared_error: 0.0582\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.16289\n",
      "Epoch 94/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0348 - mean_squared_error: 0.0024 - val_loss: 0.1651 - val_mean_squared_error: 0.0583\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.16289\n",
      "Epoch 95/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0341 - mean_squared_error: 0.0023 - val_loss: 0.1630 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.16289\n",
      "Epoch 96/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0347 - mean_squared_error: 0.0024 - val_loss: 0.1657 - val_mean_squared_error: 0.0588\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.16289\n",
      "Epoch 97/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0352 - mean_squared_error: 0.0025 - val_loss: 0.1626 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.16289 to 0.16261, saving model to model.h5\n",
      "Epoch 98/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0343 - mean_squared_error: 0.0023 - val_loss: 0.1643 - val_mean_squared_error: 0.0583\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.16261\n",
      "Epoch 99/200000\n",
      "24332/24332 [==============================] - 3s 141us/step - loss: 0.0330 - mean_squared_error: 0.0022 - val_loss: 0.1630 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.16261\n",
      "Epoch 100/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0333 - mean_squared_error: 0.0022 - val_loss: 0.1641 - val_mean_squared_error: 0.0576\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.16261\n",
      "Epoch 101/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0334 - mean_squared_error: 0.0022 - val_loss: 0.1662 - val_mean_squared_error: 0.0587\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.16261\n",
      "Epoch 102/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0344 - mean_squared_error: 0.0023 - val_loss: 0.1634 - val_mean_squared_error: 0.0575\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.16261\n",
      "Epoch 103/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0334 - mean_squared_error: 0.0022 - val_loss: 0.1646 - val_mean_squared_error: 0.0580\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.16261\n",
      "Epoch 104/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0327 - mean_squared_error: 0.0021 - val_loss: 0.1629 - val_mean_squared_error: 0.0573\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.16261\n",
      "Epoch 105/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0327 - mean_squared_error: 0.0021 - val_loss: 0.1637 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.16261\n",
      "Epoch 106/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0331 - mean_squared_error: 0.0022 - val_loss: 0.1629 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.16261\n",
      "Epoch 107/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0324 - mean_squared_error: 0.0021 - val_loss: 0.1626 - val_mean_squared_error: 0.0570\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.16261 to 0.16256, saving model to model.h5\n",
      "Epoch 108/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0313 - mean_squared_error: 0.0020 - val_loss: 0.1635 - val_mean_squared_error: 0.0577\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.16256\n",
      "Epoch 109/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.0310 - mean_squared_error: 0.0019 - val_loss: 0.1637 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.16256\n",
      "Epoch 110/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0313 - mean_squared_error: 0.0020 - val_loss: 0.1624 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.16256 to 0.16237, saving model to model.h5\n",
      "Epoch 111/200000\n",
      "24332/24332 [==============================] - 3s 133us/step - loss: 0.0314 - mean_squared_error: 0.0020 - val_loss: 0.1629 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.16237\n",
      "Epoch 112/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.0320 - mean_squared_error: 0.0020 - val_loss: 0.1639 - val_mean_squared_error: 0.0578\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.16237\n",
      "Epoch 113/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0318 - mean_squared_error: 0.0020 - val_loss: 0.1638 - val_mean_squared_error: 0.0577\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.16237\n",
      "Epoch 114/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0306 - mean_squared_error: 0.0018 - val_loss: 0.1613 - val_mean_squared_error: 0.0566\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.16237 to 0.16130, saving model to model.h5\n",
      "Epoch 115/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0299 - mean_squared_error: 0.0018 - val_loss: 0.1649 - val_mean_squared_error: 0.0583\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.16130\n",
      "Epoch 116/200000\n",
      "24332/24332 [==============================] - 3s 144us/step - loss: 0.0320 - mean_squared_error: 0.0020 - val_loss: 0.1626 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.16130\n",
      "Epoch 117/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0307 - mean_squared_error: 0.0019 - val_loss: 0.1639 - val_mean_squared_error: 0.0577\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.16130\n",
      "Epoch 118/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0307 - mean_squared_error: 0.0018 - val_loss: 0.1628 - val_mean_squared_error: 0.0575\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.16130\n",
      "Epoch 119/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0297 - mean_squared_error: 0.0019 - val_loss: 0.1624 - val_mean_squared_error: 0.0570\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.16130\n",
      "Epoch 120/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0306 - mean_squared_error: 0.0019 - val_loss: 0.1639 - val_mean_squared_error: 0.0582\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.16130\n",
      "Epoch 121/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0293 - mean_squared_error: 0.0017 - val_loss: 0.1636 - val_mean_squared_error: 0.0575\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.16130\n",
      "Epoch 122/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0296 - mean_squared_error: 0.0017 - val_loss: 0.1619 - val_mean_squared_error: 0.0567\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.16130\n",
      "Epoch 123/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0293 - mean_squared_error: 0.0017 - val_loss: 0.1627 - val_mean_squared_error: 0.0575\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.16130\n",
      "Epoch 124/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0283 - mean_squared_error: 0.0016 - val_loss: 0.1641 - val_mean_squared_error: 0.0583\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.16130\n",
      "Epoch 125/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0301 - mean_squared_error: 0.0018 - val_loss: 0.1619 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.16130\n",
      "Epoch 126/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0295 - mean_squared_error: 0.0017 - val_loss: 0.1615 - val_mean_squared_error: 0.0566\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.16130\n",
      "Epoch 127/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0291 - mean_squared_error: 0.0016 - val_loss: 0.1631 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.16130\n",
      "Epoch 128/200000\n",
      "24332/24332 [==============================] - 4s 157us/step - loss: 0.0284 - mean_squared_error: 0.0016 - val_loss: 0.1621 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.16130\n",
      "Epoch 129/200000\n",
      "24332/24332 [==============================] - 3s 139us/step - loss: 0.0287 - mean_squared_error: 0.0016 - val_loss: 0.1640 - val_mean_squared_error: 0.0575\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.16130\n",
      "Epoch 130/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0289 - mean_squared_error: 0.0017 - val_loss: 0.1635 - val_mean_squared_error: 0.0578\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.16130\n",
      "Epoch 131/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0285 - mean_squared_error: 0.0016 - val_loss: 0.1619 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.16130\n",
      "Epoch 132/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0279 - mean_squared_error: 0.0016 - val_loss: 0.1620 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.16130\n",
      "Epoch 133/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0276 - mean_squared_error: 0.0015 - val_loss: 0.1615 - val_mean_squared_error: 0.0567\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.16130\n",
      "Epoch 134/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0275 - mean_squared_error: 0.0015 - val_loss: 0.1616 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.16130\n",
      "Epoch 135/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0275 - mean_squared_error: 0.0015 - val_loss: 0.1614 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.16130\n",
      "Epoch 136/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0269 - mean_squared_error: 0.0015 - val_loss: 0.1629 - val_mean_squared_error: 0.0578\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.16130\n",
      "Epoch 137/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0277 - mean_squared_error: 0.0015 - val_loss: 0.1620 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.16130\n",
      "Epoch 138/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0268 - mean_squared_error: 0.0015 - val_loss: 0.1608 - val_mean_squared_error: 0.0567\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.16130 to 0.16080, saving model to model.h5\n",
      "Epoch 139/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0270 - mean_squared_error: 0.0015 - val_loss: 0.1610 - val_mean_squared_error: 0.0567\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.16080\n",
      "Epoch 140/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.0272 - mean_squared_error: 0.0015 - val_loss: 0.1615 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.16080\n",
      "Epoch 141/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0264 - mean_squared_error: 0.0014 - val_loss: 0.1619 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.16080\n",
      "Epoch 142/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0273 - mean_squared_error: 0.0015 - val_loss: 0.1613 - val_mean_squared_error: 0.0567\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.16080\n",
      "Epoch 143/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0261 - mean_squared_error: 0.0013 - val_loss: 0.1618 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.16080\n",
      "Epoch 144/200000\n",
      "24332/24332 [==============================] - 3s 133us/step - loss: 0.0264 - mean_squared_error: 0.0014 - val_loss: 0.1617 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.16080\n",
      "Epoch 145/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0260 - mean_squared_error: 0.0014 - val_loss: 0.1635 - val_mean_squared_error: 0.0575\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.16080\n",
      "Epoch 146/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0262 - mean_squared_error: 0.0014 - val_loss: 0.1616 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.16080\n",
      "Epoch 147/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0261 - mean_squared_error: 0.0013 - val_loss: 0.1618 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.16080\n",
      "Epoch 148/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0266 - mean_squared_error: 0.0014 - val_loss: 0.1637 - val_mean_squared_error: 0.0576\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.16080\n",
      "Epoch 149/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0262 - mean_squared_error: 0.0014 - val_loss: 0.1626 - val_mean_squared_error: 0.0573\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.16080\n",
      "Epoch 150/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0256 - mean_squared_error: 0.0013 - val_loss: 0.1606 - val_mean_squared_error: 0.0565\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.16080 to 0.16060, saving model to model.h5\n",
      "Epoch 151/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0261 - mean_squared_error: 0.0013 - val_loss: 0.1634 - val_mean_squared_error: 0.0579\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.16060\n",
      "Epoch 152/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.0263 - mean_squared_error: 0.0014 - val_loss: 0.1623 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.16060\n",
      "Epoch 153/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0259 - mean_squared_error: 0.0013 - val_loss: 0.1621 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.16060\n",
      "Epoch 154/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0260 - mean_squared_error: 0.0013 - val_loss: 0.1635 - val_mean_squared_error: 0.0579\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.16060\n",
      "Epoch 155/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0248 - mean_squared_error: 0.0012 - val_loss: 0.1613 - val_mean_squared_error: 0.0565\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.16060\n",
      "Epoch 156/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0257 - mean_squared_error: 0.0013 - val_loss: 0.1619 - val_mean_squared_error: 0.0571\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.16060\n",
      "Epoch 157/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0252 - mean_squared_error: 0.0013 - val_loss: 0.1617 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.16060\n",
      "Epoch 158/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0251 - mean_squared_error: 0.0013 - val_loss: 0.1625 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.16060\n",
      "Epoch 159/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0247 - mean_squared_error: 0.0013 - val_loss: 0.1617 - val_mean_squared_error: 0.0573\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.16060\n",
      "Epoch 160/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0248 - mean_squared_error: 0.0012 - val_loss: 0.1623 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.16060\n",
      "Epoch 161/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0245 - mean_squared_error: 0.0012 - val_loss: 0.1616 - val_mean_squared_error: 0.0573\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.16060\n",
      "Epoch 162/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0239 - mean_squared_error: 0.0012 - val_loss: 0.1624 - val_mean_squared_error: 0.0579\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.16060\n",
      "Epoch 163/200000\n",
      "24332/24332 [==============================] - 3s 133us/step - loss: 0.0244 - mean_squared_error: 0.0012 - val_loss: 0.1612 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.16060\n",
      "Epoch 164/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0243 - mean_squared_error: 0.0012 - val_loss: 0.1634 - val_mean_squared_error: 0.0576\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.16060\n",
      "Epoch 165/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0245 - mean_squared_error: 0.0012 - val_loss: 0.1636 - val_mean_squared_error: 0.0577\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.16060\n",
      "Epoch 166/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0250 - mean_squared_error: 0.0013 - val_loss: 0.1618 - val_mean_squared_error: 0.0571\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.16060\n",
      "Epoch 167/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0242 - mean_squared_error: 0.0012 - val_loss: 0.1613 - val_mean_squared_error: 0.0567\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.16060\n",
      "Epoch 168/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0242 - mean_squared_error: 0.0012 - val_loss: 0.1619 - val_mean_squared_error: 0.0570\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.16060\n",
      "Epoch 169/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0236 - mean_squared_error: 0.0011 - val_loss: 0.1622 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.16060\n",
      "Epoch 170/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0237 - mean_squared_error: 0.0011 - val_loss: 0.1619 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.16060\n",
      "Epoch 171/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0239 - mean_squared_error: 0.0012 - val_loss: 0.1614 - val_mean_squared_error: 0.0566\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.16060\n",
      "Epoch 172/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0232 - mean_squared_error: 0.0011 - val_loss: 0.1613 - val_mean_squared_error: 0.0570\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.16060\n",
      "Epoch 173/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0236 - mean_squared_error: 0.0011 - val_loss: 0.1608 - val_mean_squared_error: 0.0565\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.16060\n",
      "Epoch 174/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0236 - mean_squared_error: 0.0011 - val_loss: 0.1614 - val_mean_squared_error: 0.0570\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.16060\n",
      "Epoch 175/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0238 - mean_squared_error: 0.0011 - val_loss: 0.1628 - val_mean_squared_error: 0.0579\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.16060\n",
      "Epoch 176/200000\n",
      "24332/24332 [==============================] - 3s 137us/step - loss: 0.0229 - mean_squared_error: 0.0011 - val_loss: 0.1622 - val_mean_squared_error: 0.0571\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.16060\n",
      "Epoch 177/200000\n",
      "24332/24332 [==============================] - 3s 138us/step - loss: 0.0229 - mean_squared_error: 0.0011 - val_loss: 0.1612 - val_mean_squared_error: 0.0571\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.16060\n",
      "Epoch 178/200000\n",
      "24332/24332 [==============================] - 3s 137us/step - loss: 0.0232 - mean_squared_error: 0.0011 - val_loss: 0.1612 - val_mean_squared_error: 0.0566\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.16060\n",
      "Epoch 179/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0228 - mean_squared_error: 0.0011 - val_loss: 0.1627 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.16060\n",
      "Epoch 180/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0230 - mean_squared_error: 0.0011 - val_loss: 0.1607 - val_mean_squared_error: 0.0565\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.16060\n",
      "Epoch 181/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0233 - mean_squared_error: 0.0011 - val_loss: 0.1613 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.16060\n",
      "Epoch 182/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0229 - mean_squared_error: 0.0011 - val_loss: 0.1612 - val_mean_squared_error: 0.0565\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.16060\n",
      "Epoch 183/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0225 - mean_squared_error: 0.0010 - val_loss: 0.1617 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.16060\n",
      "Epoch 184/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0227 - mean_squared_error: 0.0011 - val_loss: 0.1618 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.16060\n",
      "Epoch 185/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0222 - mean_squared_error: 9.9895e-04 - val_loss: 0.1616 - val_mean_squared_error: 0.0570\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.16060\n",
      "Epoch 186/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0226 - mean_squared_error: 0.0010 - val_loss: 0.1616 - val_mean_squared_error: 0.0573\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.16060\n",
      "Epoch 187/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0227 - mean_squared_error: 0.0011 - val_loss: 0.1615 - val_mean_squared_error: 0.0573\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.16060\n",
      "Epoch 188/200000\n",
      "24332/24332 [==============================] - 3s 133us/step - loss: 0.0216 - mean_squared_error: 9.7954e-04 - val_loss: 0.1612 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.16060\n",
      "Epoch 189/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0217 - mean_squared_error: 9.8973e-04 - val_loss: 0.1624 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.16060\n",
      "Epoch 190/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0222 - mean_squared_error: 0.0010 - val_loss: 0.1616 - val_mean_squared_error: 0.0570\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.16060\n",
      "Epoch 191/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0216 - mean_squared_error: 9.4672e-04 - val_loss: 0.1616 - val_mean_squared_error: 0.0570\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.16060\n",
      "Epoch 192/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0217 - mean_squared_error: 9.6216e-04 - val_loss: 0.1612 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.16060\n",
      "Epoch 193/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0221 - mean_squared_error: 9.9740e-04 - val_loss: 0.1605 - val_mean_squared_error: 0.0566\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.16060 to 0.16055, saving model to model.h5\n",
      "Epoch 194/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0223 - mean_squared_error: 0.0010 - val_loss: 0.1623 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.16055\n",
      "Epoch 195/200000\n",
      "24332/24332 [==============================] - 3s 143us/step - loss: 0.0223 - mean_squared_error: 0.0010 - val_loss: 0.1608 - val_mean_squared_error: 0.0566\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.16055\n",
      "Epoch 196/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0216 - mean_squared_error: 9.5610e-04 - val_loss: 0.1613 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.16055\n",
      "Epoch 197/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0216 - mean_squared_error: 9.8889e-04 - val_loss: 0.1614 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.16055\n",
      "Epoch 198/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0213 - mean_squared_error: 9.5046e-04 - val_loss: 0.1621 - val_mean_squared_error: 0.0574\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.16055\n",
      "Epoch 199/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0220 - mean_squared_error: 9.9921e-04 - val_loss: 0.1607 - val_mean_squared_error: 0.0564\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.16055\n",
      "Epoch 200/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0215 - mean_squared_error: 9.6596e-04 - val_loss: 0.1626 - val_mean_squared_error: 0.0575\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.16055\n",
      "Epoch 201/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0215 - mean_squared_error: 9.6010e-04 - val_loss: 0.1610 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.16055\n",
      "Epoch 202/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0213 - mean_squared_error: 9.3940e-04 - val_loss: 0.1623 - val_mean_squared_error: 0.0570\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.16055\n",
      "Epoch 203/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0219 - mean_squared_error: 0.0010 - val_loss: 0.1613 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.16055\n",
      "Epoch 204/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0217 - mean_squared_error: 9.8275e-04 - val_loss: 0.1615 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.16055\n",
      "Epoch 205/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0206 - mean_squared_error: 8.8827e-04 - val_loss: 0.1612 - val_mean_squared_error: 0.0569\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.16055\n",
      "Epoch 206/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0207 - mean_squared_error: 9.1294e-04 - val_loss: 0.1623 - val_mean_squared_error: 0.0578\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.16055\n",
      "Epoch 207/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0219 - mean_squared_error: 9.9735e-04 - val_loss: 0.1614 - val_mean_squared_error: 0.0571\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.16055\n",
      "Epoch 208/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0212 - mean_squared_error: 9.6481e-04 - val_loss: 0.1609 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.16055\n",
      "Epoch 209/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0201 - mean_squared_error: 8.5498e-04 - val_loss: 0.1612 - val_mean_squared_error: 0.0568\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.16055\n",
      "Epoch 210/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0202 - mean_squared_error: 8.5724e-04 - val_loss: 0.1617 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.16055\n",
      "Epoch 211/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0212 - mean_squared_error: 9.3780e-04 - val_loss: 0.1621 - val_mean_squared_error: 0.0572\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.16055\n",
      "Epoch 212/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0204 - mean_squared_error: 8.8307e-04 - val_loss: 0.1614 - val_mean_squared_error: 0.0571\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.16055\n",
      "Epoch 213/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0201 - mean_squared_error: 8.6365e-04 - val_loss: 0.1607 - val_mean_squared_error: 0.0565\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.16055\n",
      "Epoch 214/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0204 - mean_squared_error: 8.6216e-04 - val_loss: 0.1602 - val_mean_squared_error: 0.0564\n",
      "\n",
      "Epoch 00214: val_loss improved from 0.16055 to 0.16018, saving model to model.h5\n",
      "Epoch 215/200000\n",
      "24332/24332 [==============================] - 3s 135us/step - loss: 0.0208 - mean_squared_error: 8.9229e-04 - val_loss: 0.1606 - val_mean_squared_error: 0.0571\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.16018\n",
      "Epoch 216/200000\n",
      "24332/24332 [==============================] - 3s 142us/step - loss: 0.0202 - mean_squared_error: 8.5713e-04 - val_loss: 0.1601 - val_mean_squared_error: 0.0565\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.16018 to 0.16009, saving model to model.h5\n",
      "Epoch 217/200000\n",
      "24332/24332 [==============================] - 3s 134us/step - loss: 0.0196 - mean_squared_error: 7.9850e-04 - val_loss: 0.1627 - val_mean_squared_error: 0.0573\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.16009\n",
      "Epoch 218/200000\n",
      "24332/24332 [==============================] - 3s 142us/step - loss: 0.0195 - mean_squared_error: 8.0521e-04 - val_loss: 0.1619 - val_mean_squared_error: 0.0573\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.16009\n",
      "Epoch 219/200000\n",
      "24332/24332 [==============================] - 4s 155us/step - loss: 0.0198 - mean_squared_error: 8.1713e-04 - val_loss: 0.1610 - val_mean_squared_error: 0.0571\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.16009\n",
      "Epoch 220/200000\n",
      "24332/24332 [==============================] - 3s 140us/step - loss: 0.0197 - mean_squared_error: 8.2552e-04 - val_loss: 0.1607 - val_mean_squared_error: 0.0566\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.16009\n",
      "Epoch 221/200000\n",
      "24332/24332 [==============================] - 3s 137us/step - loss: 0.0207 - mean_squared_error: 8.9598e-04 - val_loss: 0.1610 - val_mean_squared_error: 0.0571\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.16009\n",
      "Epoch 222/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0203 - mean_squared_error: 8.6726e-04 - val_loss: 0.1607 - val_mean_squared_error: 0.0566\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.16009\n",
      "Epoch 223/200000\n",
      "24332/24332 [==============================] - 3s 136us/step - loss: 0.0199 - mean_squared_error: 8.2897e-04 - val_loss: 0.1606 - val_mean_squared_error: 0.0562\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.16009\n",
      "Epoch 224/200000\n",
      " 7552/24332 [========>.....................] - ETA: 2s - loss: 0.0204 - mean_squared_error: 7.9480e-04"
     ]
    }
   ],
   "source": [
    "out_taipei_valid_preds = []\n",
    "out_taipei_test_preds = []\n",
    "kf = KFold(n_splits=7, shuffle=False)\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(kf.split(out_taipei_cont_train)):\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Fold {i+1}\")\n",
    "    print(\"-\" * 20)\n",
    "    X_train = [out_taipei_cont_train[train_index]] + [np.expand_dims(out_taipei_cat_train[train_index, i], -1)  for i in range(cat_train.shape[1])]\n",
    "    y_train = out_taipei_Y_train[train_index]\n",
    "    X_valid = [out_taipei_cont_train[val_index]] + [np.expand_dims(out_taipei_cat_train[val_index, i], -1)  for i in range(cat_train.shape[1])]\n",
    "    y_valid = out_taipei_Y_train[val_index]\n",
    "\n",
    "    model = dnn_model()\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizers.Adam(0.0001), metrics=['mse'])\n",
    "    # checkpoint\n",
    "    filepath=\"model.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=2)\n",
    "    callbacks_list = [checkpoint, early_stopping]\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=200000, batch_size=128, validation_data=(X_valid, y_valid), callbacks=callbacks_list)\n",
    "    # Load best modelout_taipei_\n",
    "    K.clear_session()\n",
    "    best_model = load_model(\"model.h5\")\n",
    "    # Predict valid\n",
    "    valid_pred = best_model.predict(X_valid)\n",
    "    valid_pred = y_scale.inverse_transform(valid_pred)\n",
    "    out_taipei_valid_preds.append(np.expm1(valid_pred))\n",
    "    # Predict test\n",
    "    pred = best_model.predict([out_taipei_cont_test] + [np.expand_dims(out_taipei_cat_test[:, i], -1)  for i in range(cat_train.shape[1])])\n",
    "    pred = y_scale.inverse_transform(pred)\n",
    "    out_taipei_test_preds.append(np.expm1(pred))\n",
    "\n",
    "    #Y_valid_predict = best_model.predict(X_valid)\n",
    "    #Y_valid_predict = np.floor(np.expm1(y_scale.inverse_transform(Y_valid_predict)))\n",
    "    #Y_valid = np.floor(np.expm1(y_scale.inverse_transform(y_valid)))\n",
    "    #metric(Y_valid, Y_valid_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_taipei_y_valid = np.squeeze(np.concatenate(out_taipei_valid_preds, axis=0)) * offset[~train_greater_taipei_bool]\n",
    "out_taipei_y_test = np.squeeze(np.mean(out_taipei_test_preds, axis=0)) * test.loc[~test_greater_taipei_bool, 'building_area'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_valid = np.zeros(len(cont_train))\n",
    "y_valid[train_greater_taipei_bool] = in_taipei_y_valid\n",
    "y_valid[~train_greater_taipei_bool] = out_taipei_y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  705712.15497045,  2943522.62512413,  9485504.91882316, ...,\n",
       "       12440902.37730765, 19240969.71950816,  8409342.63559498])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_df = pd.DataFrame(y_valid, columns=[\"total_price\"])\n",
    "valid_df.to_csv(\"valid_prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = np.zeros(len(test))\n",
    "y_test[test_greater_taipei_bool] = in_taipei_y_test\n",
    "y_test[~test_greater_taipei_bool] = out_taipei_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14354232.54925925,  3893668.91815371, 12840578.66261289, ...,\n",
       "        1161379.37050462,  3004094.31468554,  3009364.16235374])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv(\"../input/dataset-0510/submit_test.csv\")\n",
    "\n",
    "with open(\"sample_submission.csv\", \"w\") as f:\n",
    "    f.write('building_id,total_price\\n')\n",
    "    for _id, label in zip(submit[\"building_id\"], y_test):\n",
    "        f.write(_id + ',' + str(label) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
